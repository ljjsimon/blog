[{"title":"b站API","url":"/posts/1651545089/","content":"# 用户\n## 用户信息\nGET https://api.bilibili.com/x/space/acc/info?mid=5818410\n参数 | 意义 | 备注\n-|-|-\nmid | 用户id | \n\n## 用户状态信息\nGET https://api.bilibili.com/x/relation/stat?vmid=5818410\n参数 | 意义 | 备注\n-|-|-\nvmid | 用户id | \n\n```json\n{\n \"data\":{\n        \"mid\":5818410,\n        \"following\":164, // 关注数\n        \"whisper\":0,\n        \"black\":0,\n        \"follower\":1365298 // 粉丝数\n    }\n}\n```\n\n## 粉丝列表\nGET https://api.bilibili.com/x/relation/followers?vmid=50995243&pn=1&ps=20&order=desc\n\n参数 | 意义 | 备注\n-|-|-\nvmid | 用户id | \nps | 页数 | 最大5\nps | 取结果的条数 | 默认为20，最大为50\n\n## 关注列表\nGET https://api.bilibili.com/x/relation/followings?vmid=5818410&pn=2&ps=20&order=desc\n\n参数 | 意义 | 备注\n-|-|-\nvmid | 用户id | \nps | 页数 | 最大5\nps | 取结果的条数 | 默认为20，最大为50\n\n","tags":["数据"]},{"title":"FFmpeg备忘录","url":"/posts/1645589539/","content":"# FFmpeg备忘单\n\n> [FFmpeg](https://ffmpeg.org)中常见视频处理操作的备忘单\n\n## 操作\n\n*如果文件已存在，使用 `-y` 标记来覆盖*\n\n### 音频-视频 同步\n\n> [参考](https://superuser.com/questions/982342/in-ffmpeg-how-to-delay-only-the-audio-of-a-mp4-video-without-converting-the-au)\n\n```sh\n# 音频延后 3 秒\n$ ffmpeg -i input.mov -itsoffset 3 -i input.mov -map 0:v -map 1:a -codec:a copy -codec:v copy output.mov\n\n# 视频延后 3 秒 (即音频提前 3 秒)\n$ ffmpeg -i input.mov -itsoffset 3 -i input.mov -map 1:v -map 0:a -codec:a copy -codec:v copy output.mov\n```\n\n- 第二个 `-i` 标记必须 *紧跟着* `-itsoffset` 标记后面。\n\n### 裁剪\n\n> [参考](https://ffmpeg.org/ffmpeg-filters.html#crop)\n\n```sh\n# 裁剪到 360 宽, 640 高\n$ ffmpeg -i input.mov -filter:v 'crop=360:640:0:0' -codec:a copy output.mov\n\n# 裁剪到 360 宽,  640 高, 从坐标 (10, 20) 开始\n$ ffmpeg -i input.mov -filter:v 'crop=360:640:10:20' -codec:a copy output.mov\n```\n\n### 格式\n\n> [参考](https://stackoverflow.com/questions/8075992/using-ffmpeg-convert-a-file-from-one-output)\n\n```sh\n# 转换到 GIF\n$ ffmpeg -i input.mov output.gif\n\n# 从 GIF 转换\n$ ffmpeg -i input.gif output.mov\n\n# 两个非-GIF 文件转换\n$ ffmpeg -i input.mov -codec:v copy -codec:a copy output.mp4\n```\n\n### 帧率\n\n> [参考](https://trac.ffmpeg.org/wiki/ChangingFrameRate)\n\n```sh\n# 调整帧率到 12\n$ ffmpeg -i input.mov -filter:v 'fps=fps=12' -codec:a copy output.mov\n```\n\n### 剥离音频\n\n> [参考](https://superuser.com/questions/268985/remove-audio-from-video-file-with-ffmpeg)\n\n```sh\n# 移除音频\n$ ffmpeg -i input.mov -codec:v copy -an output.mov\n```\n\n### 调整大小\n\n> [Reference](https://trac.ffmpeg.org/wiki/Scaling)\n\n```sh\n# 调整到 360 宽,  640 高\n$ ffmpeg -i input.mov -filter:v 'scale=360:640' -codec:a copy output.mov\n\n# 调整为 360 宽，保持长宽比\n$ ffmpeg -i input.mov -filter:v 'scale=360:-1' -codec:a copy output.mov\n\n# 调整到 640 高, 保持长宽比\n$ ffmpeg -i input.mov -filter:v 'scale=-1:640' -codec:a copy output.mov\n```\n\n- 设置 `width` 或 `height` 任意一个到 `-1` 来保持长宽比。\n\n### 倒放\n\n> [参考](https://video.stackexchange.com/questions/17738/how-to-use-ffmpeg-command-for-reverse-video)\n\n```sh\n# 倒放\n$ ffmpeg -i input.mov -filter:v 'reverse' -filter:a 'areverse' output.mov\n```\n\n### 旋转\n\n> [参考](https://stackoverflow.com/questions/3937387/rotating-videos-with-ffmpeg)\n\n```sh\n# 顺时针旋转90度\n$ ffmpeg -i input.mov -filter:v 'transpose=1' -codec:a copy output.mov\n\n# 逆时针旋转90度\n$ ffmpeg -i input.mov -filter:v 'transpose=2' -codec:a copy output.mov\n\n# 旋转180度\n$ ffmpeg -i input.mov -filter:v 'transpose=1,transpose=1' -codec:a copy output.mov\n```\n\n### 速度\n\n> [参考](https://trac.ffmpeg.org/wiki/How%20to%20speed%20up%20/%20slow%20down%20a%20video)\n\n```sh\n# 四分之一的速度\n$ ffmpeg -i input.mov -filter:v 'setpts=4*PTS' -filter:a 'atempo=0.5,atempo=0.5' output.mov\n\n# 速度减半\n$ ffmpeg -i input.mov -filter:v 'setpts=2*PTS' -filter:a 'atempo=0.5' output.mov\n\n# 速度加倍\n$ ffmpeg -i input.mov -filter:v 'setpts=0.5*PTS' -filter:a 'atempo=2' output.mov\n\n# 四倍的速度\n$ ffmpeg -i input.mov -filter:v 'setpts=0.25*PTS' -filter:a 'atempo=2,atempo=2' output.mov\n```\n\n- 使用共识 `1 ÷ speed` 来计算 `setpts` 的值。\n  - 速度减半: `setpts=2*PTS` 因为 `1 ÷ 0.5 = 2`。\n  - 速度加倍: `setpts=0.5*PTS` 因为 `1 ÷ 2 = 0.5`。\n\n- 每个 `atempo` 选项必须介于 0.5 和 2。\n  - 四分之一的速度: `atempo=0.5,atempo=0.5` 因为 `0.5 × 0.5 = 0.25`.\n  - 四倍的速度: `atempo=2,atempo=2` 因为 `2 × 2 = 4`.\n\n### 字幕\n\n> [参考](https://stackoverflow.com/questions/57869367/ffmpeg-subtitles-alignment-and-position)\n\n```sh\n# 字幕写入视频\n$ ffmpeg -i input.mov -filter:v 'subtitles=subtitles.srt' -codec:a copy output.mov\n\n# 字幕写入视频, 使用自定义样式\n$ ffmpeg -i input.mov -filter:v \"subtitles=subtitles.srt:force_style='FontName=Menlo Bold,Fontsize=18'\" -codec:a copy output.mov\n```\n\n### 修剪\n\n> [参考](https://trac.ffmpeg.org/wiki/Seeking#Cuttingsmallsections)\n\n```sh\n# 剪去 0:05 到 0:10\n$ ffmpeg -ss 0:05 -to 0:10 -i input.mov -codec:v copy -codec:a copy output.mov\n\n# 减去 0:05 到视频结束\n$ ffmpeg -ss 0:05 -i input.mov -codec:v copy -codec:a copy output.mov\n```\n\n-  `-ss` 和 `-to` 标签必须放在  `-i` 标签 *前面*。\n\n### 音量\n\n> [参考](https://trac.ffmpeg.org/wiki/AudioVolume)\n\n```sh\n# 音量减半\n$ ffmpeg -i input.mov -codec:v copy -filter:a 'volume=0.5' output.mov\n\n# 音量加倍\n$ ffmpeg -i input.mov -codec:v copy -filter:a 'volume=2' output.mov\n```\n\n## 相关命令行标签\n\n> [参考](https://ffmpeg.org/ffmpeg.html)\n\n```\nffmpeg\n  -an\n  -ss <timestamp>\n  -to <timestamp>\n  -itsoffset <offset>\n  -i <input>\n  -map <stream>\n  -codec:a <codec>\n  -codec:v <codec>\n  -filter:a <filtergraph>\n  -filter:v <filtergraph>\n  -y\n  <output>\n```\n\n## 另见\n\n- [vdx](https://github.com/yuanqing/vdx)\n\n\n-----------------------------------\n[转自](https://github.com/ljjsimon/ffmpeg-cheatsheet)","tags":["ffmpeg"]},{"title":"redis内存淘汰策略","url":"/posts/1637828084/","content":"# 过期策略\n## 定期删除\nredis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定期遍历这个字典来删除到期的 key。\n\nRedis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。\n\n1.从过期字典中随机 20 个 key；\n\n2.删除这 20 个 key 中已经过期的 key；\n\n3.如果过期的 key 比率超过 1/4，那就重复步骤 1；\n\nredis默认是每隔 100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载。\n\n## 惰性删除\n所谓惰性策略就是在客户端访问这个key的时候，redis对key的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。\n\n定期删除可能会导致很多过期key到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，即当你主动去查过期的key时,如果发现key过期了,就立即进行删除,不返回任何东西.\n\n总结：定期删除是集中处理，惰性删除是零散处理。\n\n# 内存淘汰策略\n1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键\n\n2. allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键\n\n3. volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键\n\n4. allkeys-random：加入键的时候如果过限，从所有key随机删除\n\n5. volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐\n\n6. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键\n\n7. volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键\n\n8. allkeys-lfu：从所有键中驱逐使用频率最少的键\n\n## 标准LRU\n1. 新增key value的时候首先在链表结尾添加Node节点，如果超过LRU设置的阈值就淘汰队头的节点并删除掉HashMap中对应的节点。\n\n2. 修改key对应的值的时候先修改对应的Node中的值，然后把Node节点移动队尾。\n\n3. 访问key对应的值的时候把访问的Node节点移动到队尾即可。\n\n## Redis的近似LRU实现\nRedis维护了一个24位时钟，可以简单理解为当前系统的时间戳，每隔一定时间会更新这个时钟。每个key对象内部同样维护了一个24位的时钟，当新增key对象的时候会把系统的时钟赋值到这个内部对象时钟。比如我现在要进行LRU，那么首先拿到当前的全局时钟，然后再找到内部时钟与全局时钟距离时间最久的（差最大）进行淘汰，这里值得注意的是全局时钟只有24位，按秒为单位来表示才能存储194天，所以可能会出现key的时钟大于全局时钟的情况，如果这种情况出现那么就两个相加而不是相减来求最久的key。\n```\nstruct redisServer {\n       pid_t pid; \n       char *configfile; \n       //全局时钟\n       unsigned lruclock:LRU_BITS; \n       ...\n};\ntypedef struct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    /* key对象内部时钟 */\n    unsigned lru:LRU_BITS;\n    int refcount;\n    void *ptr;\n} robj;\n```\nRedis中的LRU与常规的LRU实现并不相同，常规LRU会准确的淘汰掉队头的元素，但是Redis的LRU并不维护队列，只是根据配置的策略要么从所有的key中随机选择N个（N可以配置）要么从所有的设置了过期时间的key中选出N个键，然后再从这N个键中选出最久没有使用的一个key进行淘汰。\n\n## LFU\nLFU是在Redis4.0后出现的，LRU的最近最少使用实际上并不精确，考虑下面的情况，如果在|处删除，那么A距离的时间最久，但实际上A的使用频率要比B频繁，所以合理的淘汰策略应该是淘汰B。LFU就是为应对这种情况而生的。\n\nA~~A~~A~~A~~A~~A~~A~~A~~A~~A~~~|\n\nB~~~~~B~~~~~B~~~~~B~~~~~~~~~~~~B|\n\nLFU把原来的key对象的内部时钟的24位分成两部分，前16位还代表时钟，后8位代表一个计数器。16位的情况下如果还按照秒为单位就会导致不够用，所以一般这里以时钟为单位。而后8位表示当前key对象的访问频率，8位只能代表255，但是redis并没有采用线性上升的方式，而是通过一个复杂的公式，通过配置如下两个参数来调整数据的递增速度。\n\nlfu-log-factor 可以调整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。\n\nlfu-decay-time 是一个以分钟为单位的数值，可以调整counter的减少速度。\n\n所以这两个因素就对应到了LFU的Counter减少策略和增长策略，它们实现逻辑分别如下。\n\n---------------------------\n转自（部分）：https://zhuanlan.zhihu.com/p/105587132\n","tags":["redis"]},{"title":"composer版本规范与测试包发布","url":"/posts/1636944786/","content":"# composer 包版本规范\n|  名称   | 实例  | 描述 |\n|  ----  | ----  | --- |\n| 确切的版本号  | 1.0.2 | 你可以指定包的确切版本。|\n| 范围  | `>=1.0` ; `>=1.0,<2.0` ; `>=1.0,<1.1&#124;>=1.2` | 通过使用比较操作符可以指定有效的版本范围。有效的运算符：`>`、`>=`、`<`、`<=`、`!=`。你可以定义多个范围，用逗号隔开，这将被视为一个逻辑AND处理。一个管道符号`&#124;`将作为逻辑OR处理。AND 的优先级高于 OR。|\n| 通配符 | 1.0.* | 你可以使用通配符*来指定一种模式。1.0.*与>=1.0,<1.1是等效的。|\n| 赋值运算符 | ~1.2 | 这对于遵循语义化版本号的项目非常有用。~1.2相当于>=1.2,<2.0。想要了解更多，请阅读下一小节。|\n\n~1.2 相当于 >=1.2,<2.0  \n~1.2.3 相当于 >=1.2.3,<1.3  \n^1.2 相当于 >=1.2\n\n# 测试版包\n通过标签（tag）定义版本，可以使用的后缀有 alpha, beta, RC, p\n```\n1.0.0\nv1.0.0\n1.10.5-RC1\nv4.4.4beta2\nv2.0.0-alpha\nv2.0.4-p1\n```\n所有提交到 Github 的分支代码默认被当作 dev 版\n\n## 项目中规定最低稳定性版本\n```\n\"minimum-stability\": \"stable\", // 表示最低安装版本为稳定版\n```\n\n## 项目中测试自己的分支\n比如依赖项目为 ljj/lib，分支为：feature-ljj\ncomposer.json 中 require 添加\n```\n\"ljj/lib\": \"dev-feature-ljj@dev\",\n```\n开头的 dev- 前缀表示是一个分支（开发）版，后面的 @dev 后缀表示稳定性是 dev。这样在执行\n```\ncomposer update\n```\n后就可以看到已经安装了该分支的代码\n\n---------------------\n参考：  \nhttps://www.jianshu.com/p/fd65d2f30e77  \nhttps://igor.io/2013/02/07/composer-stability-flags.html  \nhttps://docs.phpcomposer.com/04-schema.html","tags":["php"]},{"title":"Hello World","url":"/posts/1528164216/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","tags":["hexo"]},{"title":"一次简单的jvm内存使用排查","url":"/posts/1628930496/","content":"# 起因\n本地服务起来之后没有请求，但是通过\n```\njconsole\n```\n查看 Eden 区，内存一直稳步升高，达到阈值后被 ygc 回收，不会触发 fgc。但是不正常要弄清楚原因，于是开始排查。\n\n# 经过\n## 首\n先想到的是 jconsole 对服务的请求导致，于是关闭 jconsole，使用\n```sh\n$ jps # 查看 pid\n97424 \n45479 JConsole\n45833 AppServiceApplication\n45290 GradleDaemon\n47467 Jps\n45787 GradleDaemon\n41086 GradleDaemon\n\n$ jstat -gc pid\n S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   \n36864.0 37376.0  0.0    0.0   624128.0 125440.3  194560.0   56782.3   113612.0 108595.5 14848.0 14025.1     28    0.539   6      1.551    2.090\n```\n再过一段时间\n```\n$ jstat -gc pid\n S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   \n36864.0 37376.0  0.0    0.0   624128.0 169705.6  194560.0   56782.3   113612.0 108595.5 14848.0 14025.1     28    0.539   6      1.551    2.090\n```\n发现内存增长较大，排除 jconsole jstat 等工具调用\n\n然后关闭 zk, mq 依赖，发现还是有，排除 zk, mq 心跳\n\n## 然\n后使用\n```\njmap -dump:format=b,file=aaa.hprof pid\n```\n导出内存，再在 mat 里分析，发现内存泄露非常少，而且没有增加。即增加在 Eden 的内存不属于泄露。\n\n## 然\n后使用\n```sh\njmap -histo pid > all.txt # 导出堆区所有内存对象\njmap -histo:live pid > gc.txt # 先执行 gc，然后导出堆区所有内存对象\n```\n发现 all.txt 是\n```\n num     #instances         #bytes  class name\n----------------------------------------------\n   1:        830787       66800632  [C\n   2:         97630       26007600  [I\n   3:        116249       15713024  [B\n   4:        540884       12981216  java.lang.String\n   5:        253263       12591912  [Ljava.lang.Object;\n```\ngc.txt 是\n```\n num     #instances         #bytes  class name\n----------------------------------------------\n   1:        131103       17091664  [C\n   2:        129867        3116808  java.lang.String\n   3:         32805        2886840  java.lang.reflect.Method\n   4:         84468        2702976  java.util.concurrent.ConcurrentHashMap$Node\n   5:         22404        2476608  java.lang.Class\n   6:         10266        2240408  [B\n   7:         25721        1992728  [Ljava.lang.Object;\n```\n其中 java.lang.String 减少非常多，立即想到不是输入，是不是输出。查看本地服务输出，果然一直有内容在输出。对那个依赖修改，不再输出后，查看 jconsole，果然内存不再增长了。\n\n# 结果\n通过这次排查，找到了本地服务内存占用一直升高的原因，并且做了修复，由于线上没有出现同样的问题，不需要修复。同时了解到，日志输出产生的 String 只能等到 gc 的时候被清理。\n\n# 附录\n## 打印gc日志\n-XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps\n\n## 频繁GC问题或内存溢出问题\n一、使用jps查看线程ID\n\n二、使用jstat -gc 3331 250 20 查看gc情况，一般比较关注PERM区的情况，查看GC的增长情况。\n\n三、使用jstat -gccause：额外输出上次GC原因\n\n四、使用jmap -dump:format=b,file=heapDump 3331生成堆转储文件\n\n五、使用jhat或者可视化工具（Eclipse Memory Analyzer 、IBM HeapAnalyzer）分析堆情况。\n\n六、结合代码解决内存溢出或泄露问题。\n\n## 死锁问题\n一、使用jps查看线程ID\n\n二、使用jstack 3331：查看线程情况\n","tags":["java"]},{"title":"jstat命令基本用法","url":"/posts/1628930173/","content":"诊断程序性能问题，或者OOM问题需要查看程序运行的一些统计信息，jstat为我们提供了很多虚拟机运行时的状态信息，它可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、JIT编译等信息。\n\n# 基本用法\n\n我的jdk是1.8.0_191\n\n```\nD:。。。。\\dir1>jstat -help\nUsage: jstat -help|-options\n       jstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]\n\nDefinitions:\n  <option>      An option reported by the -options option\n  <vmid>        Virtual Machine Identifier. A vmid takes the following form:\n                     <lvmid>[@<hostname>[:<port>]]\n                Where <lvmid> is the local vm identifier for the target\n                Java virtual machine, typically a process id; <hostname> is\n                the name of the host running the target Java virtual machine;\n                and <port> is the port number for the rmiregistry on the\n                target host. See the jvmstat documentation for a more complete\n                description of the Virtual Machine Identifier.\n  <lines>       Number of samples between header lines.\n  <interval>    Sampling interval. The following forms are allowed:\n                    <n>[\"ms\"|\"s\"]\n                Where <n> is an integer and the suffix specifies the units as\n                milliseconds(\"ms\") or seconds(\"s\"). The default units are \"ms\".\n  <count>       Number of samples to take before terminating.\n  -J<flag>      Pass <flag> directly to the runtime system.\n```\n\n也就是\njstat 选项 进程id 间隔时间 采集次数\n\n其中，选项有多个，例如， -gc， gcnew等等。 间隔时间和次数不是必须的。如果没有间隔时间和次数表示只采集一次。\n\n```\nE:\\dir1\\aaa>jstat  -options\n-class\n-compiler\n-gc\n-gccapacity\n-gccause\n-gcmetacapacity\n-gcnew\n-gcnewcapacity\n-gcold\n-gcoldcapacity\n-gcutil\n-printcompilation\n```\n\n# 具体使用\n## 加载统计：\n```\njstat -class 7\nLoaded Bytes Unloaded Bytes Time\n19138 34432.8 36 34.1 13.90\n\nLoaded:加载class的数量\nBytes：所占用空间大小\nUnloaded：卸载的class数量\nBytes:卸载释放的空间\nTime：加载和卸载耗费的时间\n```\n\n## JIT编译统计\n```\nE:>jstat -compiler 16596\nCompiled Failed Invalid Time FailedType FailedMethod\n8455 3 0 35.63 1 java/util/concurrent/ConcurrentHashMap transfer\n\nCompiled：编译数量。\nFailed：失败数量\nInvalid：不可用数量\nTime：时间\nFailedType：失败类型\nFailedMethod：失败的方法\n```\n\n## 堆信息统计\n```\nE:>jstat -gc 16596\nS0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT\n2560.0 24064.0 2080.0 0.0 407040.0 296932.8 225792.0 28917.2 60568.0 57891.2 8096.0 7581.1 18 0.535 3 0.293 0.828\n\nS0C：第一个幸存区的大小\nS1C：第二个幸存区的大小\nS0U：第一个幸存区的使用大小\nS1U：第二个幸存区的使用大小\nEC：伊甸园区的大小\nEU：伊甸园区的使用大小\nOC：老年代大小\nOU：老年代使用大小\nMC：方法区大小\nMU：方法区使用大小\nCCSC:压缩类空间大小\nCCSU:压缩类空间使用大小\nYGC：年轻代垃圾回收次数\nYGCT：年轻代垃圾回收消耗时间\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n```\n\n## 堆信息统计2\n```\n与-gc基本相同，主要关注堆各个区域使用到的最大最小空间\njstat -gccapacity 7\nNGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC\n174592.0 349184.0 313856.0 44544.0 26112.0 224768.0 349696.0 699392.0 499200.0 499200.0 0.0 1140736.0 105496.0 0.0 1048576.0 13616.0 57 4\n\nNGCMN：新生代最小容量\nNGCMX：新生代最大容量\nNGC：当前新生代容量\nS0C：第一个幸存区大小\nS1C：第二个幸存区的大小\nEC：伊甸园区的大小\nOGCMN：老年代最小容量\nOGCMX：老年代最大容量\nOGC：当前老年代大小\nOC:当前老年代大小\nMCMN:最小元数据容量\nMCMX：最大元数据容量\nMC：当前元数据空间大小\nCCSMN：最小压缩类空间大小\nCCSMX：最大压缩类空间大小\nCCSC：当前压缩类空间大小\nYGC：年轻代gc次数\nFGC：老年代GC次数\n```\n\n## 新生代垃圾回收统计\n```\nE:>jstat -gcnew 16596\nS0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT\n2560.0 24064.0 2080.0 0.0 6 15 24064.0 407040.0 301968.7 18 0.535\n\nS0C：第一个幸存区大小\nS1C：第二个幸存区的大小\nS0U：第一个幸存区的使用大小\nS1U：第二个幸存区的使用大小\nTT:对象在新生代存活的次数\nMTT:对象在新生代存活的最大次数\nDSS:期望的幸存区大小\nEC：伊甸园区的大小\nEU：伊甸园区的使用大小\nYGC：年轻代垃圾回收次数\nYGCT：年轻代垃圾回收消耗时间\n```\n\n## 新生代内存统计\n```\nE:>jstat -gcnewcapacity 16596\nNGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC\n86528.0 1384448.0 527872.0 461312.0 2560.0 461312.0 24064.0 1383424.0 407040.0 18 3\n\nNGCMN：新生代最小容量\nNGCMX：新生代最大容量\nNGC：当前新生代容量\nS0CMX：最大幸存1区大小\nS0C：当前幸存1区大小\nS1CMX：最大幸存2区大小\nS1C：当前幸存2区大小\nECMX：最大伊甸园区大小\nEC：当前伊甸园区大小\nYGC：年轻代垃圾回收次数\nFGC：Full GC次数\n```\n\n## 老年代垃圾回收统计\n```\nE:>jstat -gcold 16596\nMC MU CCSC CCSU OC OU YGC FGC FGCT GCT\n60568.0 57891.2 8096.0 7581.1 225792.0 28917.2 18 3 0.293 0.828\n\nMC：方法区大小\nMU：方法区使用大小\nCCSC:压缩类空间大小\nCCSU:压缩类空间使用大小\nOC：老年代大小\nOU：老年代使用大小\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n```\n\n## 老年代内存统计\n```\nE:>jstat -gcoldcapacity 16596\nOGCMN OGCMX OGC OC YGC FGC FGCT GCT\n173568.0 2768896.0 225792.0 225792.0 18 3 0.293 0.828\n\nOGCMN：老年代最小容量\nOGCMX：老年代最大容量\nOGC：当前老年代大小\nOC：老年代大小\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n```\n\n## 元数据空间统计\n```\nD:\\dir1>jstat -gcmetacapacity 16596\nMCMN MCMX MC CCSMN CCSMX CCSC YGC FGC FGCT GCT\n0.0 1101824.0 60568.0 0.0 1048576.0 8096.0 18 3 0.293 0.828\n\nMCMN:最小元数据容量\nMCMX：最大元数据容量\nMC：当前元数据空间大小\nCCSMN：最小压缩类空间大小\nCCSMX：最大压缩类空间大小\nCCSC：当前压缩类空间大小\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n```\n\n## 总结垃圾回收统计\n```\n与-gc基本相同，主要关注已使用空间站总空间比例\nD:\\dir1>jstat -gcutil 16596\nS0 S1 E O M CCS YGC YGCT FGC FGCT GCT\n81.25 0.00 70.12 12.81 95.58 93.64 18 0.535 3 0.293 0.828\n\nS0：Survivor0区当前使用比例\nS1：Survivor1区当前使用比例\nE：伊甸园区使用比例\nO：老年代使用比例\nM：元数据区使用比例\nCCS：压缩使用比例\nYGC：年轻代垃圾回收次数， 18次\nYGCT：年轻代垃圾回收总耗时， 0.535秒， 也就是平均每次耗时 0.535/18=0.0297秒\nFGC：老年代垃圾回收次数 3次\nFGCT：老年代垃圾回收消耗时间 0.293秒\nGCT：垃圾回收消耗总时间\n```\n\n## JIT编译方法统计\n```\nD:\\dir1>jstat -printcompilation 16596\nCompiled Size Type Method\n8444 75 1 com/sun/jersey/core/util/StringIgnoreCaseKeyComparator hash\n\nCompiled：最近编译方法的数量\nSize：最近编译方法的字节码数量\nType：最近编译方法的编译类型。\nMethod：方法名标识。\n```\n\n----------------\n原文链接：https://blog.csdn.net/russle/article/details/99702149","tags":["java"]},{"title":"用jmeter压测","url":"/posts/1621326369/","content":"# jMeter 操作\n1. 使用 jmeter 要先安装 JDK，安装好后打开软件。可以在菜单栏 Options, Choose Language 里选择中文。\n2. 现在左边只有一个 Test Plan，把名称改为「ljj测试」。\n3. 然后在「ljj测试」右击，添加，线程，线程组，把名称改为「模拟用户请求」，线程数，时间，循环次数都用默认的。\n4. 在「模拟用户请求」右击，添加，取样器，「HTTP请求」，然后修改相应的服务器地址，请求类型，参数等\n5. 如果要修改 HTTP header 和 cookie，则在「模拟用户请求」右击，添加，配置元件，「HTTP信息头管理器」和「HTTP COOKIE 管理器」\n6. 在「模拟用户请求」右击，添加，监听器，「查看结果树」和「聚合报告」。如果监听器加在「HTTP请求」下面，则只显示这个请求的信息\n7. 现在可以点击上面绿色的运行，然后在「查看结果树」里查看请求是否正确返回，然后在「聚合报告」里查看吞吐量信息\n\n# 报告解读\n- 样本：总测试数量\n- 平均值：单个请求的平均响应时间\n- 中位数：50%用户的响应时间（qps）\n- 90%百分位：90%用户的响应时间\n- 95%百分位：95%用户的响应时间\n- 99%百分位：99%用户的响应时间\n- 最小值：最小的响应时间\n- 最大值：最大的响应时间\n- 异常%：请求异常所占百分比\n- 吞吐量：每秒完成的请求数，吞吐量=请求数/总时间\n- 接受：每秒从服务器段接受到的数据量\n- 发送：每秒从客户段发送的请求数量\n\n还可以用下面公式计算吞吐量\n吞吐量 = ( 1000 / 响应时间 ms) × 并发数\n\n# Spinach\nSpinach 是开源的测试平台。\n1. 创建项目\n2. 创建用例，上传刚才保存的 JMX 文件，点击确定保存\n3. 先点击运行，总线程数1，1分钟进行压测\n4. 等完成后再点击运行，总线程数2，1分钟进行压测\n\n可以看到线程数增加一倍后 tps 增加了也增加了一倍，平均响应时间增加了一点，但是最高响应时间增加了非常多。\n\n# 调用javascript\n新建 test.js 文件，写入\n```\nfunction testJS(input1, input2) {\n    return input1 * input2\n}\n```\n\n1. 在线程组右击添加 Debug Sampler\n2. 在线程组右击添加 JSR223 PreProcessor, Language 选择 javascript\n在 Script 写入\n```\nload(\"test.js\")\n\nvar jm = testJS(${value1}, ${value2})\nvars.put(\"key\",jm)\n```\n这里的 ${value1}, ${value2} 定义在最外层的「ljj测试」，key 定义在「HTTP请求」中的 ${key}\n\n## 内置函数\n1. log：用来记录日志文件，写入到jmeber.log文件，使用方法：\n    1. log.info(“Test ABC!”)；\n2. vars：操作jmeter变量，提供读取/写入访问变量的方法，常用方法：\n    1. vars.get(String key)：从jmeter中获得变量值；\n    2. vars.put(String key，String value)：数据存到jmeter变量中；\n    3. vars.putObject(“OBJ1”,new Object())；\n\n# 完整内容\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<jmeterTestPlan version=\"1.2\" properties=\"5.0\" jmeter=\"5.4.3\">\n  <hashTree>\n    <TestPlan guiclass=\"TestPlanGui\" testclass=\"TestPlan\" testname=\"ljj测试\" enabled=\"true\">\n      <stringProp name=\"TestPlan.comments\"></stringProp>\n      <boolProp name=\"TestPlan.functional_mode\">false</boolProp>\n      <boolProp name=\"TestPlan.tearDown_on_shutdown\">true</boolProp>\n      <boolProp name=\"TestPlan.serialize_threadgroups\">false</boolProp>\n      <elementProp name=\"TestPlan.user_defined_variables\" elementType=\"Arguments\" guiclass=\"ArgumentsPanel\" testclass=\"Arguments\" testname=\"User Defined Variables\" enabled=\"true\">\n        <collectionProp name=\"Arguments.arguments\">\n          <elementProp name=\"value1\" elementType=\"Argument\">\n            <stringProp name=\"Argument.name\">value1</stringProp>\n            <stringProp name=\"Argument.value\">2</stringProp>\n            <stringProp name=\"Argument.metadata\">=</stringProp>\n          </elementProp>\n          <elementProp name=\"value2\" elementType=\"Argument\">\n            <stringProp name=\"Argument.name\">value2</stringProp>\n            <stringProp name=\"Argument.value\">3</stringProp>\n            <stringProp name=\"Argument.metadata\">=</stringProp>\n          </elementProp>\n        </collectionProp>\n      </elementProp>\n      <stringProp name=\"TestPlan.user_define_classpath\"></stringProp>\n    </TestPlan>\n    <hashTree>\n      <ThreadGroup guiclass=\"ThreadGroupGui\" testclass=\"ThreadGroup\" testname=\"模拟用户请求\" enabled=\"true\">\n        <stringProp name=\"ThreadGroup.on_sample_error\">continue</stringProp>\n        <elementProp name=\"ThreadGroup.main_controller\" elementType=\"LoopController\" guiclass=\"LoopControlPanel\" testclass=\"LoopController\" testname=\"Loop Controller\" enabled=\"true\">\n          <boolProp name=\"LoopController.continue_forever\">false</boolProp>\n          <stringProp name=\"LoopController.loops\">1</stringProp>\n        </elementProp>\n        <stringProp name=\"ThreadGroup.num_threads\">1</stringProp>\n        <stringProp name=\"ThreadGroup.ramp_time\">1</stringProp>\n        <boolProp name=\"ThreadGroup.scheduler\">false</boolProp>\n        <stringProp name=\"ThreadGroup.duration\"></stringProp>\n        <stringProp name=\"ThreadGroup.delay\"></stringProp>\n        <boolProp name=\"ThreadGroup.same_user_on_next_iteration\">true</boolProp>\n      </ThreadGroup>\n      <hashTree>\n        <HTTPSamplerProxy guiclass=\"HttpTestSampleGui\" testclass=\"HTTPSamplerProxy\" testname=\"HTTP Request\" enabled=\"true\">\n          <elementProp name=\"HTTPsampler.Arguments\" elementType=\"Arguments\" guiclass=\"HTTPArgumentsPanel\" testclass=\"Arguments\" testname=\"User Defined Variables\" enabled=\"true\">\n            <collectionProp name=\"Arguments.arguments\">\n              <elementProp name=\"key\" elementType=\"HTTPArgument\">\n                <boolProp name=\"HTTPArgument.always_encode\">false</boolProp>\n                <stringProp name=\"Argument.value\">${key}</stringProp>\n                <stringProp name=\"Argument.metadata\">=</stringProp>\n                <boolProp name=\"HTTPArgument.use_equals\">true</boolProp>\n                <stringProp name=\"Argument.name\">key</stringProp>\n              </elementProp>\n            </collectionProp>\n          </elementProp>\n          <stringProp name=\"HTTPSampler.domain\">www.baidu.com</stringProp>\n          <stringProp name=\"HTTPSampler.port\"></stringProp>\n          <stringProp name=\"HTTPSampler.protocol\">http</stringProp>\n          <stringProp name=\"HTTPSampler.contentEncoding\"></stringProp>\n          <stringProp name=\"HTTPSampler.path\"></stringProp>\n          <stringProp name=\"HTTPSampler.method\">GET</stringProp>\n          <boolProp name=\"HTTPSampler.follow_redirects\">true</boolProp>\n          <boolProp name=\"HTTPSampler.auto_redirects\">false</boolProp>\n          <boolProp name=\"HTTPSampler.use_keepalive\">true</boolProp>\n          <boolProp name=\"HTTPSampler.DO_MULTIPART_POST\">false</boolProp>\n          <stringProp name=\"HTTPSampler.embedded_url_re\"></stringProp>\n          <stringProp name=\"HTTPSampler.connect_timeout\"></stringProp>\n          <stringProp name=\"HTTPSampler.response_timeout\"></stringProp>\n        </HTTPSamplerProxy>\n        <hashTree/>\n        <DebugSampler guiclass=\"TestBeanGUI\" testclass=\"DebugSampler\" testname=\"调试取样器\" enabled=\"true\">\n          <boolProp name=\"displayJMeterProperties\">false</boolProp>\n          <boolProp name=\"displayJMeterVariables\">true</boolProp>\n          <boolProp name=\"displaySystemProperties\">false</boolProp>\n        </DebugSampler>\n        <hashTree/>\n        <ResultCollector guiclass=\"ViewResultsFullVisualizer\" testclass=\"ResultCollector\" testname=\"察看结果树\" enabled=\"true\">\n          <boolProp name=\"ResultCollector.error_logging\">false</boolProp>\n          <objProp>\n            <name>saveConfig</name>\n            <value class=\"SampleSaveConfiguration\">\n              <time>true</time>\n              <latency>true</latency>\n              <timestamp>true</timestamp>\n              <success>true</success>\n              <label>true</label>\n              <code>true</code>\n              <message>true</message>\n              <threadName>true</threadName>\n              <dataType>true</dataType>\n              <encoding>false</encoding>\n              <assertions>true</assertions>\n              <subresults>true</subresults>\n              <responseData>false</responseData>\n              <samplerData>false</samplerData>\n              <xml>false</xml>\n              <fieldNames>true</fieldNames>\n              <responseHeaders>false</responseHeaders>\n              <requestHeaders>false</requestHeaders>\n              <responseDataOnError>false</responseDataOnError>\n              <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>\n              <assertionsResultsToSave>0</assertionsResultsToSave>\n              <bytes>true</bytes>\n              <sentBytes>true</sentBytes>\n              <url>true</url>\n              <threadCounts>true</threadCounts>\n              <idleTime>true</idleTime>\n              <connectTime>true</connectTime>\n            </value>\n          </objProp>\n          <stringProp name=\"filename\"></stringProp>\n        </ResultCollector>\n        <hashTree/>\n        <ResultCollector guiclass=\"StatVisualizer\" testclass=\"ResultCollector\" testname=\"聚合报告\" enabled=\"true\">\n          <boolProp name=\"ResultCollector.error_logging\">false</boolProp>\n          <objProp>\n            <name>saveConfig</name>\n            <value class=\"SampleSaveConfiguration\">\n              <time>true</time>\n              <latency>true</latency>\n              <timestamp>true</timestamp>\n              <success>true</success>\n              <label>true</label>\n              <code>true</code>\n              <message>true</message>\n              <threadName>true</threadName>\n              <dataType>true</dataType>\n              <encoding>false</encoding>\n              <assertions>true</assertions>\n              <subresults>true</subresults>\n              <responseData>false</responseData>\n              <samplerData>false</samplerData>\n              <xml>false</xml>\n              <fieldNames>true</fieldNames>\n              <responseHeaders>false</responseHeaders>\n              <requestHeaders>false</requestHeaders>\n              <responseDataOnError>false</responseDataOnError>\n              <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>\n              <assertionsResultsToSave>0</assertionsResultsToSave>\n              <bytes>true</bytes>\n              <sentBytes>true</sentBytes>\n              <url>true</url>\n              <threadCounts>true</threadCounts>\n              <idleTime>true</idleTime>\n              <connectTime>true</connectTime>\n            </value>\n          </objProp>\n          <stringProp name=\"filename\"></stringProp>\n        </ResultCollector>\n        <hashTree/>\n        <JSR223PreProcessor guiclass=\"TestBeanGUI\" testclass=\"JSR223PreProcessor\" testname=\"JSR223 预处理程序\" enabled=\"true\">\n          <stringProp name=\"cacheKey\">true</stringProp>\n          <stringProp name=\"filename\"></stringProp>\n          <stringProp name=\"parameters\"></stringProp>\n          <stringProp name=\"script\">load(&quot;test.js&quot;)\n\nvar jm = testJS(${value1}, ${value2})\nvars.put(&quot;key&quot;,jm)</stringProp>\n          <stringProp name=\"scriptLanguage\">javascript</stringProp>\n        </JSR223PreProcessor>\n        <hashTree/>\n      </hashTree>\n    </hashTree>\n  </hashTree>\n</jmeterTestPlan>\n```\n-------------------------\n参考  \nhttps://www.cnblogs.com/fnng/p/5827577.html  \nhttps://www.cnblogs.com/imyalost/p/5916625.html  \nhttps://cloud.tencent.com/developer/news/721609  \nhttps://blog.csdn.net/weixin_38648597/article/details/95066326","tags":["运维"]},{"title":"简单哈希id","url":"/posts/1611284449/","content":"在这篇[「分布式系统的ID」](/posts/1553830839)里介绍了哈希ID的终极方案UUID和将数字ID转哈希ID的方案[hashid](https://hashids.org/)。这篇文章介绍简单的随机ID生成方案。\n\n# 常见的错误方案\n## 预备知识\n随机数分为\n- 真随机数\n- 不可预测：不是真的随机，但是不能被预测，是安全的随机数生成方案\n- 不规则：常见的语言重的随机数生成方案，如果 seed 和 salt 一样，就能生成一样的随机数。不安全\n\n## random()\n很多语言的随机数算法——就是上面说的第三种随机数——是伪随机的，即可以被破解。同时性能也不比硬件随机数生成算法好，因此不推荐使用。不可预测随机数可以用很多方法生成。linux 环境可以用\n```sh\nhead /dev/urandom|cksum\n```\n\njs可以用\n```js\nNumber.parseInt(crypto.randomBytes(1).toString('hex'),16)\n```\n\n## 错误的取模运算\n```js\nlet chars = '0-9a-z'\nlet randomNum = Number.parseInt(crypto.randomBytes(1).toString('hex'),16)//1个字节\nlet randomCharacter = chars.charAt(randomNum % 36);\n```\n这个方案通过获得随机数 Math.random()，来获得随机字符 randomCharacter，循环后组成随机字符串。因为1个字节有256种可能，所以得到随机字符可能性：\n- 0-35入住 0-35。\n- 36-71变为 0-35。\n- 72-107变为 0-35。\n- 108-143变为 0-35。\n- 144-179变为 0-35。\n- 180-215变为 0-35。\n- 216-251变为 0-35。\n- 252-255变为0-3。\n\n可以看到 0-3的可能性大于其他数字。要避免这种情况，要合理配置第一步生成的随机数和被除数。\n\n\n\n-------------------------------------\n参考：  \nhttps://gist.github.com/joepie91/7105003c3b26e65efcea63f3db82dfba","tags":["算法"]},{"title":"nodejs使用最佳实践","url":"/posts/1610023607/","content":"# 选择国内镜像\n```sh\n$ npm i -g nrm\n$ nrm ls # 列出所有镜像\n$ nrm use cnpm # 使用 cnpm \b镜像 \n```\n\n# 升级 nodejs\n```sh\n$ npm i -g n\n$ n lts # 升级到最新 lts 版\n$ n stable # 升级到最新 stable\n$ n latest # 升级到最新版\n```\n\n# 升级 package.json 里的依赖\n```sh\n$ npm i -g npm-check-updates\n$ ncu # 查看所有依赖的最新版\n$ ncu -u # 更新 package.json 依赖版本到最新版\n$ npm i\n```","tags":["最佳实践","javascript"]},{"title":"awesome frontend framework","url":"/posts/1608437030/","content":"# 自适应\n[bootstrap](https://github.com/twbs/bootstrap) - 推特的框架，生态最好，但最重  \n[ChatUI](https://github.com/alibaba/ChatUI) - 聊天框架，基于react  \n\n# PC\n[AdminLTE](https://github.com/ColorlibHQ/AdminLTE) - 基于 bootstrap，为后台专门优化  \n[element](https://github.com/ElemeFE/element) - 饿了么基于 VUE 的框架  \n[vue-element-admin](https://github.com/PanJiaChen/vue-element-admin) - 基于 element 的后台框架，自带 iframe  \n[iview](https://github.com/iview/iview) - 基于 VUE 的框架  \n[iview-admin](https://github.com/iview/iview-admin) - 基于 iview 的后台框架，自带 iframe  \n[layui](https://github.com/sentsin/layui/) - 不基于任何js框架，可购买 iframe 后台，聊天界面  \n[naive-ui](https://github.com/TuSimple/naive-ui) - 基于vue3，自带深色模式  \n[vue-vben-admin](https://github.com/vbenjs/vue-vben-admin) - 后台模版\n\n# mobile\n[vant](https://github.com/youzan/vant) - 有赞的框架，适合电商场景（VUE）  \n[mand-mobile](https://github.com/didi/mand-mobile) - 滴滴基于 vue 的框架，适用金融场景  \n[weui](https://github.com/Tencent/weui) - 微信的框架  \n[cube-ui](https://github.com/didi/cube-ui) - 滴滴基于 vue 的框架  \n[ionic-framework](https://github.com/ionic-team/ionic-framework) - 排名最高的框架，中文文档落后\n\n# excel\n[x-spreadsheet](https://github.com/myliang/x-spreadsheet) - 接近excel  \n[Luckysheet](https://github.com/mengshukeji/Luckysheet) - 接近excel  \n[sheetjs](https://github.com/sheetjs/sheetjs) - 基本的表格功能  \n[antv_s2](https://github.com/antvis/s2) - 蚂蚁出的，没有编辑功能\n\n"},{"title":"用xhprof监控php函数性能和调用链","url":"/posts/1607587289/","content":"# 安装\n## 安装扩展\n下载安装 xhprof 扩展，在php.ini里添加extension=php_xhprof.co\n\n## 安装web工具\n下载地址[https://github.com/facebook/xhprof]\n运行http://localhost/xhprof/examples/sample.php 生成测试数据\n访问http://localhost/xhprof/xhprof_html/ 查看数据列表\n点击[View Full Callgraph] 报错需要安装Graphviz\n\n## 安装Graphviz\n从graphviz官网下载 [http://www.graphviz.org/Download.php]\n配置环境变量\n\n这是会生成报告\n- 红色的矩形部分就是性能开销大，需要优化的函数，\n- 白色的矩形部分就是性能开销正常，不需要优化的函数，\n- 黄色的矩形部分相对于白色矩形稍微有一些性能开销，但是没有红色矩形那么大，也就是性能开销在白色矩形和红色矩形之间\n\n# XHProf报告字段含义\nFunction Name：方法名称。\nCalls：方法被调用的次数。\nCalls%：方法调用次数在同级方法总数调用次数中所占的百分比。\nIncl.Wall Time(microsec)：函数运行时间（包括子函数）。（单位：微秒）\nIWall%：方法执行花费的时间百分比。\nExcl. Wall Time(microsec)：函数运行时间（不包括子函数）。（单位：微秒）\nEWall%：方法本身执行花费的时间百分比。\nIncl. CPU(microsecs)：函数运行CPU（包括子函数）。（单位：微秒）\nICpu%：方法执行花费的CPU时间百分比。\nExcl. CPU(microsec)：函数运行CPU（不包括子函数）。（单位：微秒）\nECPU%：方法本身执行花费的CPU时间百分比。\nIncl.MemUse(bytes)：函数运行消耗内存（包括子函数）。（单位：字节）\nIMemUse%：方法执行占用的内存百分比。\nExcl.MemUse(bytes)：函数运行消耗内存（不包括子函数）。（单位：字节）\nEMemUse%：方法本身执行占用的内存百分比。\nIncl.PeakMemUse(bytes)：Incl.MemUse峰值。（单位：字节）\nIPeakMemUse%：Incl.MemUse峰值百分比。\nExcl.PeakMemUse(bytes)：Excl.MemUse峰值。单位：（字节）\nEPeakMemUse%：Excl.MemUse峰值百分比。","tags":["php"]},{"title":"中国共享软件如何进军国际市场完全指导手册","url":"/posts/1599615193/","content":"# 转载前言\n这是一篇网络考古，文章写于2000年，里面提到的很多网站现在已经不能访问了。下面是原文\n\n# 原文\n--------------------------\n\n前言：西哥特人消灭了罗马帝国， 也谈共享软件\n当匈奴大军把西哥特人赶得没有地方去的时候， 他们只好逃往罗马， 结果消灭了罗马帝国我想说的是， 在国内做软件很难得到大发展的时候， 我们不妨试试做国外的市场，外面的世界很精彩， 做做英文版的软件卖给老外， 投资回报率比做中文软件要高。当年， 日本和台湾就是因为本土市场太小， 不得不去做海外市场， 结果他们成功了，而我们总认为国内市场大， 没必要做海外市场， 别的行业也许是， 可对于通用软件行业， 由于盗版的现实状况，国内的市场真的那么大吗? 中国人做软件向来是最好的，凭什么就不能在国际市场上扬眉吐气？\n\n鼎鼎大名的ICQ是以色列人做的，鼎鼎大名的HOTMAIL是印度人做的，他们赚了数以亿计的美钞，而我们搞一个红色风暴就沾沾自喜，我们应该向日本人，台湾同胞，印度人，以色列人学习，收起民族主义的醋坛子，放下书生的臭架子，勇敢的面向世界，放眼国外的市场。中国的程序员向来是最棒的。我们不要老是停留在抱怨国内的盗版猖獗上，这是政府的事，指望马上改变很难，但避开这个障碍，走海外市场是很现实的一个方法。咱们搞软件的没有必要把自己变成盗版的牺牲品，犯不着。还是那句话，外面的世界很精彩。台湾的友立资讯出的系列图像和视频软件就在美国市场取得了很好的成绩，我希望大陆也能出一些这样的公司。我有一个倡议，成立一个论坛或News Letter，专门交流软件企业做海外市场，尤其是共享软件的新得，欧洲就有这样的组织:http://www.euro-share.com 。它为欧洲的广大共享软件开发者提供了相互取经的场所，本人也加入了他们的讨论组，获益匪浅，回过头来看看国内讨论中文共享软件开发者们的资料，除了悲壮的民族情结，似乎讨论如何赚大钱的务实讨论少了一些，实在很遗憾.其实本人经历整整一年的海外共享软件市场钻营，从第一个月挣900美元到现在一个月挣近40000美元，发现其中还是大有门道的。例如，如何设计界面，如何写文档，如何组织网页，如何让更多用户访问你的网页，如何增加下载数量，如何促使顾客掏钱购买，如何在网上收信用卡，那家信用卡服务商更好，如何让用户在用关键词在搜索引擎上搜索时，你的网页出现在前10名(大家可以到AltaVista网站 www.av.com 上用mp3 to cd做关键词查，我的网站 www.zy2000.com 保证在前10名)；针对美国的用户，应使用什么样的英语，什么样的英语要绝对避免使用，怎样让国外的IT专业报刊介绍你的软件，那些机构专门提供此类服务，这些都是很实际的学问，却没有人讨论，要知道，海外的市场真的很大啊，我的成绩简直微不足道，更不用说和WinZip等比了，他们都是千万级的人物啊，你们不想赚一千万美金吗? 我想，做梦都想，来吧，咱们团结起来，一起研究海外市场，别让印度人和以色列人把便宜都占了。\n\n第一篇:共享软件怎样收钱\n做共享软件是有利可图的，这是真的，1999年3月以前我还不信，可是经过一年多的研究和实践下来，我已经每月能赚4万多美金了，比某些大公司总裁还多。但是，我敢说，80%以上的共享软件作者并不成功，实际上，他们远远没有赚到他们本来可以赚到的收入。\n\n软件共享发行销售（先试后买）是一种市场营销手段，和其他所有市场营销手段一样，是有学问的，要想通过软件共享发行获得成功，就必须掌握这些学问。\n\n今天，我贴上第一篇技术文章，收钱的办法。\n\n在几年以前，Internet还没有流行的时候，共享软件的作者只能靠从邮件中收到用户的支票和现金的方法来赚钱，而用户寄出支票后，还要等上一周或更多的时间得到来自作者的注册码。注意，当以下几种情况发生时，软件作者的生意就做不成了： l 用户的支票本刚好用完，等他买回新支票本时，消费冲动已经没有了。\n\nl 用户的邮票刚好用完，他还不得不去一趟邮局买邮票，转念一想，这软件我也不是非买不可，算了。\n\nl 用户无法忍受要等好多天才能拿到注册码。一句话，太不方便了。\n\n现在好了，有了Internet，有了电子商务，用户可以在最想买你的软件的一刹那间，迅速的用他的信用卡在网上买下你的软件，连后悔的时间都没有，共享软件发财的日子到来了。那么，如何在网上收取信用卡呢？如果你拥有一个公司，在美国银行有信用卡商号账户，又购买了银行的GATEWAY软件，在自己的网站上开发了信用卡收费系统当然很好，但对于广大共享软件作者来说，这很不现实。有简单的办法，就是找一家信用卡收款代理公司，让他们替你收款，你只要每个月等他们给你寄一张总额的支票(他们会提取一定比例的佣金)就行了。这样的代理公司网站有：\n\nWWW.QWERKS.COM 提成 15-20% （服务极好，是我的服务商）\n\nWWW.Shareit.COM\n\nWWW.REGNOW.COM\n\nWWW.REGSOFT.COM\n\nWWW.Kagi.com\n\n对于咱们国内的共享软件作者，还要做的一件事就是去中国银行开个户头（北京中行的活期一本通就很好用），如果你打算让信用卡公司把钱电汇给你，你还要知道银行的英文名字，地址，账户名，账号，转账的SWIFT Code(可以从银行职员那里问到)到信用卡代理公司的网站上开户非常简单，通常确认它们的一个在线协议，填入一些个人信息和产品信息，几分钟就OK了。这里面有一个值得注意的地方，就是，当用户付了款后，注册码怎么给的问题，你可以选择由你来给（每收到一份订单，他们会给你发一封email，包含用户资料和email），由你生成注册码email给用户，也可以把注册码生成代码给信用卡公司，让他们编到他们的系统里去，用户来了订单后自动发出注册码，也可以由你一次性生成几百个注册码给他们，他们每收到一份订单时用掉一个注册码。\n\n我个人的意见是，这几个信用卡服务商信誉都非常好，一次给他们几百个注册码是最简单的办法，对服务商来说操作简单，对用户来说快，交完钱马上就得到注册码了当你完成作者和产品在信用卡服务商那里的登记后，就会得到一个URL连接，你把这个连接加到你的主页上面，标上一个“Buy Now”，用户点这里就可以用信用卡付款了，当然，你也可以把这个连接做到你的软件界面里去，这样用户在试用你的软件时，随时想买都可以点击这个连接上网购买。具体实例可以参考我的网站和软件http://www.zy2000.com MP3 CD Maker。\n\n对于一些Internet软件，如断点续传的下载软件，还有另外一种赚钱方法，就是对用户免费，而在软件界面上登一个banner广告赚取广告费。最有名的广告代理商是www.radiate.com，他的广告付费是每CPM 2-5美元，也就是说，如果一天里有10万个用户使用了你的软件一次的话，你就得到200-500美元。这家公司声称，著名的下载工具软件Gozilla！落户Radiate后，每月从Radiate那里赚到22万美元，我们著名的NetAnts是不是该赶快行动了？\n\n我们也不反对用户用支票和现金购买软件。事实上，信用卡服务商都提供支票和现金收款业务，我们可以在网页中提供信用卡服务商的地址和服务热线电话，具体例子可以参考我的网页中FAQ一页的内容。\n\n第二篇:慎重初战\n好了，现在你手上已经有了一个满不错的共享软件作品，你是不是打算来一个“XX正版风暴”，在3个月内迅速卖他100万套呢？我劝你最好不要做这种打算，的确有的软件在第一版推出时就一炮打响了，但大多数软件不是，你的也未必是，我的就不是（我的软件第一个月只卖了900美元）。要做好打持久战的思想准备，既要有信心，更要有耐心。孙子兵法曰，慎重初战。Internet营销绝不意味着烧钱，一定要量入而出，精打细算。绝大多数共享作者开始时和我一样，没什么钱，因此我们要尽可能要节省。\n\n首先，找一家信誉不错的虚拟主机供应商，申请一个.com的国际域名和至少10M空间（我在99年初时申请.com外加30M空间不到3000元，现在应该更便宜），至少附带两个email信箱，以我的网站为例，www.zy2000.com 外加Sales@zy2000.com ， Support@zy2000.com，是不是像一个正经的公司？\n\n其次，设计自己产品的网页。要点：\n\n1） 简单\n\n网站结构简单（下载，购买，技术支持...），没有过多的图像，动画，java script，整个页面下载速度快。\n\n2） 明白\n\n网站文字内容清晰易懂（以15岁的孩子能看懂为准则），当一个用户到你的网上浏览时，他能很快知道你的产品是什么，是干什么用的，在那里下载，点那里可以购买。\n\n此外，共享软件网站上What's new和 FAQ也是经常需要的。如果自己设计网页水平不高，可以请一个水平高的帮你设计，设计一个过的去的共享软件网页花费应在1000元以内，总之，3000-4000元钱下来，你有了自己的网站，有了信用卡服务商，有了可以下载试用的共享软件，你就可以开工了关于网页设计的技巧和提示，我还会在以后的文章中讨论。\n\n下一步，就是怎么让大家知道你的软件，下载你的软件，买你的软件了。我知道，你没有钱，不可能像一些网络公司那样烧钱打广告(那是一种很可笑的营销手段)，但只要你投入时间，你一样能获得惊人的访问量。\n\n具体可以实施的方法有：\n\nl 把软件上传到各大共享软件下载站点，最著名的有\n\nWWW.DOWNLOAD.COM\n\nWWW.HOTFILES.COM\n\nWWW.SOFTSEEK.COM\n\nWWW.WINFILES.COM\n\nWWW.SIMTEL.NET\n\nWWW.TUCOWS.COM\n\n更多的软件下载站点可以在 www.euro-share.com 上找到，当然还会有更多的站点，这就需要你在网上找了。最好争取在这些站点上得到一个好评价，如5颗星，5头牛等（关于这一点，我会在以后讨论） l 把网站提交给搜索引擎，最著名的有\n\nwww.yahoo.com\n\nwww.altavista.com\n\nwww.lycos.com\n\nwww.aol.com\n\nwww.msn.com\n\nwww.excite.com\n\nwww.hotbot.com\n\nwww.northernlight.com\n\nwww.infoseek.com\n\nwww.goto.com\n\nwww.snap.com\n\nwww.looksmart.com\n\nwww.google.com\n\n关于搜索引擎营销，我会在以后进一步讨论\n\nl 如果你的软件是解决某些人的问题的，在新闻组中找找谁问了这些问题，然后回答他们的问题。著名的新闻组搜索引擎是\n\nwww.deja.com\n\n以我的软件为例，我的软件解决的问题是如何把MP3歌曲录制成普通的音乐CD，那么我进入www.deja.com，进入discussion搜索，选择Power Search，选择关键词为mp3 cd，选择时间范围为最近3天，搜索，会得到一些人问\"mp3 to cd\"，\"convert mp3 to cd\"的问题，然后我就回答他们\"Download MP3 CD Maker at http://www.zy2000.com to help you.\"\n\nl 寻找同类（非竞争）网站，同站长商量在他的网站上介绍你的软件和网站，或者交换连接\n\n所有这几样工作不会花费你一分钱，但那么多人下载并试用你的软件，当你得到了来自用户使用你的软件的反馈后，你就会得到你的软件该怎么走的清晰的图画了。 第三篇：软件界面的重要性\n在我的软件早期版本发行的时候，可以说没有什么界面，就是一个基于对话框的应用程序。软件上传到Download.com和HOTFiles.com时，什么好评价也没有得到，Tucows.com甚至不肯收录我的软件。一位用户给我来的一份email说，\"A good interface will lead you to a wonder\"(一个好的用户界面会给你带来奇迹)。\n\n我后来下决心改进用户界面，花钱请美术高手为我的程序设计了一个很酷的界面，再投放到那些下载网站上，结果，我在HotFiles上获得4个星，Tucows上得了4头牛，ZDnet把我的程序选为99年7月16日的\"The file of the day\"，上了ZDTV的电视节目，我当月的销售额，从原来的3000美元涨到12000美元。附：要得到好的评价，软件具备Install/Uninstall功能是必需的，我使用的安装程序是免费的inno setup，可以从下面网址得到http://www.jordanr.dhs.org/isinfo.htm\n\n第四篇：搜索引擎营销，Internet营销之首选\n你听说过这句格言吗? 你的80%的收益来自于你的20%的努力。对于在Internet上进行销售的你来说，用好了搜索引擎营销，你的90%的收益来自于你的10%的努力。\n\n现在的经济是注意力经济，或者是眼球经济，我手上有一个杀手级的产品，但我怎样才能把它放在用户的眼球面前呢?\n\n我们把潜在的用户分为两类，一类是可能买，也可能不买，但还不知道你的产品的用户。\n\n我们必须要发现这类用户平时读哪些报刊，看哪些电视，逛哪些地方，浏览哪些网站，才能找到一个合适的把产品呈现给用户的方法。另一类用户是正需要你的产品，到处寻找还没有找到你的用户。那么，你要做的就是让他们找到你，不是吗?\n\n第一类用户虽然可能需要并购买你的产品，但是，他们还没有强烈的动机，没有强烈的动机，也就意味着你要花更多的时间和金钱来把东西卖给他们。而第二类用户则不同，他们正在四处搜寻他们想要的产品(你的产品)，他们有强烈的购买动机，如果你首先把精力花费在这些用户身上的话，不仅花费很低，而且效果显著，你所要作的就是:让他们找到你！\n\n为什么用搜索引擎呢？因为，只要你用对了搜索引擎就会给你的网站带来巨大的访问量。访客全是有目的性的，他们对你卖的东西感兴趣。在搜索引擎中排名前列增强了你的网站的\"可信度\"(尤其当你的网站排名前10位时)，用户终于找到并打开你的网页时，他们自我感觉很爽(我很聪明，不是吗)。最重要的一点，搜索引擎营销是完全可操作的，只要你做好了，是一定会成功的。研究搜索引擎最简单的办法，逆向工程加试验调出搜索引擎中排名靠前的页面，看看他为什么排名靠前，改进自己的页面，超过它们。关于搜索引擎的有价值的网站:\n\nhttp://www.marketposition.com\n\nhttp://www.webposition.com\n\n进行搜索引擎营销，很重要的一点是为自己的网页选择合适的关键词，这一点很重要，要把自己假想成用户，假如我是用户，我会在搜索引擎的输入栏中输入什么?\n\n这里有一个很有用的连接供大家参考：\n\nhttp://inventory.go2.com/inventory/Search_Suggestion.jhtml\n\n在下面输入mp3试试，会得到\n\n487915 mp3\n\n34755 free mp3\n\n23346 mp3 player\n\n19667 mp3 music\n\n15319 mp3 download\n\n13144 mp3 search engine\n\n12929 mp3 downloads\n\n11416 mp3 search\n\n6893 mp3 decoder\n\n5610 free mp3 downloads\n\n5230 mp3 file\n\n4659 free mp3 music\n\n4362 mp3 converter\n\n4213 mp3 song\n\n4175 mp3 free download\n\n4173 free mp3 player\n\n3978 mp3 encoder\n\n3972 eminem mp3\n\n3900 mp3 to wav\n\n3509 download mp3\n\n3273 free mp3 music download\n\n2990 mp3 free\n\n2873 mp3 site\n\n2762 u2 mp3\n\n2637 mp3 software\n\n2602 free mp3 song\n\n2548 britney spear mp3\n\n2140 mp3 song downloads\n\n1989 hindi mp3\n\n1916 mp3 to wav converter\n\n1896 the real slim shady mp3\n\n1895 music mp3 download\n\n1890 metallica mp3\n\n1801 free mp3 file\n\n1769 chinese mp3\n\n1674 mp3 to cd\n\n1605 napster mp3\n\n1592 mp3 domain:tr\n\n1518 limp bizkit mp3\n\n1506 mp3 player download\n\n1502 greek mp3\n\n1426 mp3 encoders\n\n1420 portable mp3 player\n\n1396 gundam wing mp3\n\n1378 anime mp3\n\n1370 christian mp3\n\n1310 free mp3 download\n\n1308 mp3 mixer\n\n1293 mp3 finder\n\n1285 pink floyd mp3\n\n1269 mp3 ripper\n\n1264 korn mp3\n\n1209 mp3 cd player\n\n1187 mp3 album\n\n1176 what is mp3\n\n1162 mp3 cd maker\n\n1159 kid rock mp3\n\n1151 convert mp3 to wav\n\n1086 mp3 portable player\n\n1067 mp3 to wave\n\n1028 mp3 warez\n\n1015 rap mp3\n\n1013 mp3 skin\n\n1000 bloodhound gang mp3\n\n994 mac mp3 player\n\n987 queen mp3\n\n982 mp3 full album\n\n980 blink 182 mp3\n\n977 music mp3\n\n961 wav to mp3\n\n959 pearl jam mp3\n\n948 beatles mp3\n\n938 mp3 recorder\n\n929 illegal mp3\n\n927 arabic mp3\n\n916 mp3 music downloads\n\n914 mp3 rippers\n\n912 bon jovi mp3\n\n909 t|rkge mp3\n\n887 mp3 compressor\n\n880 mp3 video\n\n877 mp3 wav convert\n\n868 mp3 editor\n\n829 oasis mp3\n\n815 creed mp3\n\n809 sting mp3\n\n806 abba mp3\n\n797 dixie chick mp3\n\n776 hindi mp3 song\n\n770 hip hop mp3\n\n763 madonna mp3\n\n743 nirvana mp3\n\n722 mp3 to wave converter\n\n717 mp3 free downloads\n\n715 indian mp3\n\n714 mp3 gratis\n\n711 mp3 madonna\n\n691 techno mp3\n\n682 car mp3 player\n\n676 mp3 archive\n\n会得到在这个搜索引擎上，一个月内有多少个和mp3相关的搜索，我的网站，选择mp3做关键词，想排名靠前太难了，但集中优化mp3 to cd，mp3 to wav， convert mp3 to cd，mp3 converter这几个关键词然后让排名靠前还是很现实的。事实上，我的网站就是这么做的，以mp3 to cd为例，我的网站在很多搜索引擎排名前10名。为你的网站找一组好的关键词吧！\n\n好了，你现在找好了一大串关键词，打算把它们放到网页中，并期望搜索引擎给你的网站一个好名次。不，别这样如果你同时在一个网页中优化大量的关键词，搜索引擎会认为你的网站很没有针对性，因此是不会给你好名次的。那么，网页中优化几个关键词比较好呢？答案是1个或两个!\n\n假如你指针对一个关键词优化你的网页，搜索引擎会对你的页面很满意，并且会给较高的排名。那么，你手上还有10来个也很想用的关键词，怎么办呢？笨办法，为每一个单独的关键词单独地做一个网页，然后加上连接到你的主网站里去，这样的网页叫doorway pages。最理想的做法是，为每一个关键词，每一个特定的搜索引擎，做一个Search Engine-Friendly的doorway page。然后统统连到你的主网站上。以我的网站为例，我的主网站是http://www.zy2000.com而下面的URL是我的一个doorway page，是专门针对关键词mp3 to wav，搜索引擎是AltaVista而优化的：\n\nhttp://www.winok.com/mp3towava.html\n\n编写doorway pages很辛苦，但的确是值得干的好法子。关于doorway pages更多的讨论参见http://www.marketposition.com的讨论组。\n\n后记：分析网上销售软件是否能赚钱，数字最有说服力\n来美国数月，一个很大的收获就是发现美国人做生意用数字说话，非常精确，非常科学，值得我们学习。在互联网上面，得到精确的统计数字是最容易的，做互联网生意的人完全应该仔细的挖掘这些数字：数中自有黄金屋。我现在用我自己的网站今年8月1日的数字来给大家参考参考：\n\n访客数：2970其中来自搜索引擎有553个，\n\nAltaVista: 108\n\nBest keyword: mp3 cd maker(13)\n\nconvert mp3 to cd (7)\n\nmp3cdmaker(7)\n\nmp3 to cd audio (6)\n\nconvert mp3 to wav (4)\n\nGoogle: 36\n\ngoto.com: 49\n\nbest keyword: mp3 to wav (14)\n\nsnap.com: 49\n\nbest keyword: convert mp3 to cd(7)\n\nYahoo webpage: 61\n\nbest keyword: mp3 to cda converter (13)\n\nYahoo directory: 122\n\nbest keyword: mp3 cd maker(21) mp3 to cd (20)\n\n直接从软件中点击超连接到网页 922个\n\n从别的网站连接过来的点击(下载站点，友情连接等) 1495个 其中，来自自制Doorway pages: (158)\n\n来自元搜索(meta search)，如Askjeeves.com，metacrawler.com，search.com (115)\n\n当日销售额: $1，705\n\n平均访客价值: 0.60美元\n\n======================================================================\n\n市场活动统计\n\nBanner广告\n\n本人小规模投过几次Banner广告，统计如下\n\n平均价格: $30每CPM\n\n点击率: 0.5%\n\n平均每点击价值: 30/(1000*0.5%) = 0.60美元\n\n结论: 成本极高，几乎不可取\n\nemail广告\n\n本人投过2500元通过一个专业email广告商 www.yesmail.com 做过一期广告，通过其目标订户发放10000份email广告，即时反馈率10%，折合每访客成本 2.5元，考虑到email内容容易保存而且可能转发到广告订户的朋友那里，这种广告的效果可能还会好一些。Yesmail.com已经同意为我提供更好的统计功能，如在我的网站页面里插入一些Tracking代码，以便跟踪哪些email用户最终实际购买。\n\n结论: 成本偏高，具体效果有待下一轮试验\n\nYahoo分类目录\n\n成本: $1450 (由专业公司代为申请)\n\n效果: 每天至少产生 100个以上的访问，以500天计算，每访客成本为3美分\n\n结论: 这是绝好的网站营销手段\n\nGoto.com这是一个拍卖关键词排名的搜索引擎，我采用该网站竞拍我的几个关键词，平均每访客投入2-3美分\n\n其他搜索引擎:\n\nYahoo web page， AltaVista， AOL， MSN， Google， Excite， Lycos， Hotbot等\n\n成本: 0 需要投入的是时间\n\n回报: 每天将近 500的访问，也就是说，每天给带来300美元的收入\n\n结论: 搜索引擎营销是最好的网络营销手段\n\n结论: 利用网络销售软件当然赚钱，但怎么做也有学问，结论需要严谨的数据和\n\n实例支撑，我希望更多的人能参与进来研究和分享网络营销的技巧，找到网络致富的秘诀。"},{"title":"晋升申请怎么写","url":"/posts/1596521817/","content":"1、入职后发现业务产品的设计漏洞，随即作为<font color=\"red\">Owner</font>推动落地风控升级方案，节省并降低<font color=\"red\">700w+</font>运营费用和损耗；\n\n2、深入一线实际运营场景，<font color=\"red\">主动发现向题</font>，优化人效核算、门店运营流程等，<font color=\"red\">提升一线运营效率和客户体验</font>；\n\n3、在完成本职工作外，<font color=\"red\">积极配合</font>其他业务部门解决诸多工作难题；\n\n4、始终保有 <font color=\"red\">Day1</font> 心态，<font color=\"red\">同目标共进退打胜仗</font>"},{"title":"awesome datasets","url":"/posts/1595211059/","content":"# 列表\n## 地址\n- [china_regions](https://github.com/kzgame/china_regions) - 中国省，市，区县，商圈数据。Json格式\n- [china_area_mysql](https://github.com/kakuilan/china_area_mysql) - 中国5级行政区域mysql库\n- [GB2260](https://github.com/cn/GB2260) - 中华人民共和国国家标准 GB/T 2260 行政区划代码\n- [china-city-subway](https://github.com/Seaony/china-city-subway) - 地铁数据库\n- [Community Data](https://github.com/phpxiebin/Community-Data) - 小区数据库\n- [All The Cities](https://github.com/zeke/all-the-cities) - 世界所有人口多的城市\n- [city](https://github.com/pfinal/city) - 中华人民共和国行政区划数据：省份、城市、区县。中国省市区镇三级联动地址数据。城市经纬度数据\n- [GeoIP2-CN](https://github.com/Hackl0us/GeoIP2-CN) - 中国大陆IP地址库\n\n## 中文\n- [nlp_chinese_corpus](https://github.com/brightmart/nlp_chinese_corpus) - 大规模中文自然语言处理语料\n- [Embedding Corpus for Chinese](https://ai.tencent.com/ailab/nlp/embedding.html) - Tencent AI Lab Embedding Corpus for Chinese Words and Phrases\n- [chinese-poetry](https://github.com/chinese-poetry/chinese-poetry) - 最全中华古诗词数据库\n- [chinese_chatbot_corpus](https://github.com/codemayq/chinese_chatbot_corpus) - 聊天语料\n- [ChineseSemanticKB](https://github.com/liuhuanyong/ChineseSemanticKB) - 词语关系列表（同义词/反义词/词分类等）\n- [stopwords](https://github.com/goto456/stopwords) - 停用词词库（可以跳过的词）\n\n## 图像 / 视频\n- [tencent-ml-images](https://github.com/Tencent/tencent-ml-images) - Largest multi-label image database; ResNet-101 model; 80.73% top-1 acc on ImageNet\n- [matting_human_datasets](https://github.com/aisegmentcn/matting_human_datasets) - 人像数据集\n- [VATEX](http://vatex.org/main/index.html) - 视频描述数据集\n\n## 声音\n- [Common Voice](https://voice.mozilla.org/zh-CN/datasets) - 语音\n\n## 其他\n- [Enterprise-Registration-Data-of-Chinese-Mainland](https://github.com/imhuster/Enterprise-Registration-Data-of-Chinese-Mainland) - 中国大陆 31 个省份1978 年至 2019 年一千多万工商企业注册信息\n\n# 爬虫\n- [Fast-Lianjia-Crawler](https://github.com/CaoZ/Fast-LianJia-Crawler) - 链家爬虫\n- [nsfw_data_source_urls](https://github.com/EBazarov/nsfw_data_source_urls) - 成人图片网址\n- [nsfw_data_scrapper](https://github.com/alexkimxyz/nsfw_data_scrapper) - 成人图片爬虫\n\n\n# 别的列表\n- [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)\n- [datasets](https://github.com/tensorflow/datasets) - tensorflow datasets\n- [awesome json datasets](https://github.com/jdorfman/awesome-json-datasets) - A curated list of awesome JSON datasets that don't require authentication\n- [TableBank](https://github.com/doc-analysis/TableBank)\n- [gopup](https://github.com/justinzm/gopup) - 各大网站指数数据","tags":["数据"]},{"title":"服务降级","url":"/posts/1593505779/","content":"# 降级预案\n## 日志级别\n需要对系统进行梳理，哪些是可以降级的，哪些是需要誓死保护的，可以参考日志级别。\n1. 一般：有些服务因为网络抖动或者服务上线而超时，可以自动降级。\n2. 警告：有些服务成功率有波动（95%-100%之间），可以自动降级或人工降级，并发送警告。\n3. 错误：比如错误率低于 90%，或者数据库连接池爆了，或者访问量猛增到系统承受的最大阀值，可以根据情况自动降级或者人工降级。\n4. 严重错误：特殊原因数据错误，此时需要紧急人工降级。\n\n## 完整链路降级\n降级的功能点主要从服务端链路考虑，即根据用户访问的服务调用链路来梳理哪里需要降级\n1. 页面降级：在大促或者某些特殊情况下，某些页面占用了一些稀缺服务资源，在紧急情况下可以对其整个降级，以达到丢卒保帅；\n2. 页面片段降级：比如商品详情页中的商家部分因为数据错误了，此时需要对其进行降级；\n3. 页面异步请求降级：比如商品详情页上有推荐信息/配送至等异步加载的请求，如果这些信息响应慢或者后端服务有问题，可以进行降级；\n4. 服务功能降级：比如渲染商品详情页时需要调用一些不太重要的服务：相关分类、热销榜等，而这些服务在异常情况下直接不获取，即降级即可；\n5. 读降级：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景；\n6. 写降级：比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。\n7. 爬虫降级：在大促活动时，可以将爬虫流量导向静态页或者返回空数据，从而保护后端稀缺资源。\n\n## 自动降级策略\n自动降级是根据系统负载，资源使用情况，SLA 等指标进行降级\n1. 超时降级：当访问的数据库/http服务/远程调用响应慢或者不响应可以设置超时自动降级。\n2. 统计失败次数降级：有时候依赖一些不稳定的API，比如调用外部机票服务，当失败调用次数达到一定阀值自动降级；然后通过异步线程去探测服务是否恢复了，则取消降级。\n3. 故障降级：当调用的远程服务挂掉了（网络故障，DNS 故障，http 服务返回错误的状态码，RPC 服务抛出异常），则可以直接降级。\n4. 限流降级：当我们去秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时开发者会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。\n\n## 降级方式\n1. 人工开关降级：在大促期间通过监控发现线上的一些服务存在问题，这个时候需要暂时将这些服务摘掉。\n2. 读服务降级：对于读服务降级一般采用的策略有：暂时切换读（降级到读缓存、降级到走静态化）、暂时屏蔽读（屏蔽读入口、屏蔽某个读服务）。\n3. 写服务降级：一刀切停止写服务，或者写入消息队列\n\n# 限流算法\n1. 计数器法：实现简单，精度不高，重置节点时无法处理突发请求\n2. 滑动窗口：滑动窗口的窗口越小，则精度越高，相应的资源消耗也更高。\n3. 漏桶算法 : 限制的是流出速率，突发请求要排队，对服务保护较好；流入随机，流出固定\n4. 令牌桶算法 ：限制的是平均流入速率，允许一定程度突发请求（无需排队）。\n\n## 限流方法对比\n计数器 VS 滑动窗口\n计数器算法是最简单的算法，可以看成是滑动窗口的低精度实现。滑动窗口由于需要存储多份的计数器（每一个格子存一份），所以滑动窗口在实现上需要更多的存储空间。也就是说，如果滑动窗口的精度越高，需要的存储空间就越大。\n\n令牌桶和漏桶对比：\n\n令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求；漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝；\n令牌桶限制的是平均流入速率，允许一定的突发请求；而漏桶主要目的是平滑流出速率；\n\n## 开源限流组件\n1. [alibaba/Sentinel](https://github.com/alibaba/Sentinel)\n2. [Netflix/Hystrix](https://github.com/Netflix/Hystrix)\n\n--------------------------------\n参考  \nhttps://blog.csdn.net/ityouknow/article/details/81230412  \nhttps://www.jianshu.com/p/1dbc1a19fa8c","tags":["运维"]},{"title":"ffmpeg常用操作","url":"/posts/1592302487/","content":"```sh\n# 视频转音频\nffmpeg -i video.mp4 -f mp3 sound.mp3\n\n# 转MP3为wav\n\nffmpeg -i input.mp3 -acodec pcm_s16le -ac 2 -ar 44100 output.wav\n\n# 转m4a为wav\n\nffmpeg -i input.m4a -acodec pcm_s16le -ac 2 -ar 44100 output.wav\n\n# wav与PCM的相互转换\n\nffmpeg -i input.wav -f s16le -ar 44100 -acodec pcm_s16le output.raw\n\n# PCM转wav\n\nffmpeg -f s16le -ar 44100 -ac 2 -acodec pcm_s16le -i input.raw output.wav\n\n# 用ffplay播放PCM\n\nffplay -f s16le -ar 44100 -ac 2 **.raw\n```\n\ns16le表示：s表示有符号，l表示小端。 可以用 s16be代替，表示s有符号b表示大端\n\n44100代表采样率，注意保持一致，可以是16000／8000","tags":["ffmpeg"]},{"title":"swoole扫雷","url":"/posts/1579146320/","content":"# http/client\n```php\nnew Swoole\\Coroutine\\Http\\Client($url, $port, $ssl);\n```\n$url 参数不带协议（http/https），如果请求 https，$port=443，$ssl=true\n\n# http/request\n通过 $request->server['request_method] 判断请求是 get 还是 post 还是别的\n\n# 跨域\n```php\n$response->header('Access-Control-Allow-Origin','*');\n```\n\n# 协程锁\nswoole 每次只有一个协程在运行，所以不用加锁\n参考：  \nhttps://wiki.swoole.com/wiki/page/p-differences_with_go.html\n\n# 打印 swoole 配置\nphp --ri swoole","tags":["php"]},{"title":"常用正则表达式","url":"/posts/1578535312/","content":"uri\n- js\n```\n(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]\n```\n- php\n```\n/(https?|ftp|file):\\/\\/[-A-Za-z0-9+&@#\\/\\%?=~_|!:,.;]+[-A-Za-z0-9+&@#\\/\\%=~_|]/\n```\n\n中文\n- js\n```\n[\\u4e00-\\u9fa5]\n```\n- php\n```\n/[\\x{4e00}-\\x{9fa5}]/u\n```\n\n双字节字符（包含中文）\n- js\n```\n[^\\x00-\\xff]\n```\n- php\n```\n/[^\\x00-\\xff]/u\n```\n\n手机号\n```\n^1(3|4|5|6|7|8|9)\\d{9}$\n```","tags":["最佳实践"]},{"title":"手机连接电脑用chrome调试网页","url":"/posts/1576983574/","content":"# 安卓\n## 安卓打开开发者模式\n小米手机需要在 设置=》我的设备全部参数=》MIUI版本 点5次，打开开发者模式\n\n然后在开发者模式里打开 USB 调试\n\n***然后连接电脑的时候会弹出 USB 的用途，选择传输照片（PTP）模式***\n\n## 电脑端\nwindows 需要安装驱动\n\nchrome 打开 chrome://inspect 就能看到设备了\n\n## cordova\ncordova 调试正式版 app，需要在 AndroidManifest.xml 的 <application> 节点里加入\n```\nandroid:debuggable=\"true\"\n```\n\n参考[https://cordova.apache.org/docs/en/latest/guide/next/#debugging-cordova-apps](https://cordova.apache.org/docs/en/latest/guide/next/#debugging-cordova-apps)","tags":["最佳实践"]},{"title":"nginx常用转发配置","url":"/posts/1576906217/","content":"# http 跳转 https\n```conf\nserver {\n    if ($host = www.ljj.pub) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n}\nserver {\n    listen 443 ssl http2 default_server;\n    listen [::]:443 ssl http2 default_server;\n    server_name www.ljj.pub;\n}\n```\n第一个 server 配置是 certbot 自动生成的，目的是将所有 http://www.ljj.pub 的请求转发到 https://www.ljj.pub。注意第二个 server 配置里面不可以有 listen 80; 否则会覆盖上面那个，导致转发不执行。\n\n# 移动和PC端跳转不同页面\n```conf\nserver {\n    if ($http_user_agent ~* 'ipad|iphone|android') {\n        return 301 https://m.ljj.pub;\n    }\n}\n```\n这里的匹配符号有\n- = 严格匹配\n- ~ 区分大小写匹配（可用正则）\n- ~* 不区分大小写匹配（可用正则）\n- !~ 区分大小写不匹配\n- !~* 不区分大小写不匹配\n- ^~ 如果把这个前缀用于一个常规字符串,那么告诉nginx 如果路径匹配那么不测试正则表达式\n-----------------------------\n参考：\n[nginx匹配](https://www.cnblogs.com/duhuo/p/8323812.html)    \n[在线生成配置的工具](https://www.digitalocean.com/community/tools/nginx)","tags":["最佳实践"]},{"title":"温州话普通话不对应的词","url":"/posts/1575601794/","content":"门头，钥匙，蝙蝠，虾姑，落班，坐月子，矮椅，闪雷，腋下，盐水，牡蛎，水姑娘，老娘客，捡拾纸，本扫堂，畚斗，除扫，水桶，脸盆，地拖，厨房间，屋灶间，阁楼，瓦片屋顶，淀粉，糖霜，叉子，筷子，物品，骂脏话，长瓢，他拉方，骷髅排，佛殿，并不是，梨，好过，突然，花路，起里丫，酒家，锈（形容人没精神，变难看了），雀跃，人客，阴静，干切，倒山赖，没办头，咸骨，媛子儿，后生儿，煮类（小吃），靠造化（随便），肩胛头，后背心，背脊心，跳舞衣儿（婚纱），砖头块，火油心，鞋锤儿（锤子），悟空搓，烦人芋（烦人），菠萝粟（玉米），喉震光（扇耳光），肮脏骨（肮脏的人或东西），好甚（甚好），亲眷（亲属），眠床头（床头）\n\nnea wo ni （眼红），半囵吞 （* lung tang。意为半吊子），bei ba （麻烦），西囊（乖巧），赤膊大敛，田田然，苏，无空吵，当当然，柜格洞（音近ju ga dong，课桌抽屉），细媚人相，nong zai ji(乱七八糟，一塌糊涂，满地狼藉。也可以说nong zai bu ji或ha zai ji。) ，\nta la huo(形容很多，也可以说ta ta qu) ，\nba zi guo ni/ba zi ni guo(黏糊糊)，\n短命相（dü men xi。形容某人某事不如人意，讨人嫌。），屋灶岩头，伴手（* xiu，拜访或探望时随手带的礼物），夫姨（* yi，“姨夫”在温州里的是要倒着讲的，绝对的温州特色），动画片(mu dou nian en,“nian en”是温州方言里对“画”的说法，看动画片就会说“ci mu dou nian en”)，涌，套样，零碎，零碎八碎，强（倔强，两种字），搬故窝，价格老，嘎（嘎嘎，现在），搬故屋，讲闲谈，骂脏话，窗门，上辈人，蛇芋（山药），巷弄（巷子），走错巷（迷路），种样（样子），横竖，粘（ba），老古色（老旧），波兰菜（菠菜），饭罩盖，布帐（蚊帐）,高丽肉（腊肉）,扭堂（哪里）,底居、底妹（里面），丝瘦（瘦），煤黑（黑），天色、天时（天气），屋堂（房子），直头（真的），教条（玩弄），摊油炸果（炸油条），等添（再等等），文旦（柚子），铅价子（硬币）\n"},{"title":"希腊穿衣法","url":"/posts/1575601676/","content":"![微博相册](https://wx4.sinaimg.cn/large/726f09bbly1frz3kqsmtvg20sg0dm0v5.gif)"},{"title":"linux程序后台常驻运行","url":"/posts/1575599174/","content":"# &\n在命令后面添加 &，表示在后台运行。但是如果用户退出或者掉线的话，程序也会退出。\n\n# nohup\nnohup 程序可以使命令脱离当前 session 运行。即使用户退出或掉线，程序仍继续运行。\n\n# 重定向\nnohup 默认会把程序输出打印到 nohup.out 文件。如果不需要打印输出，可以在命令后面添加 >/dev/null 2>&1。这几个符号表示：\n- /dev/null 表示空设备文件\n- 0 表示stdin标准输入\n- 1 表示stdout标准输出\n- 2 表示stderr标准错误\n\n连起来就是把标准错误重定向到标准输出，再打印到空设备文件，即丢弃。\n\n这些命令连起来就是\n```sh\n$ nohup php a.php >/dev/null 2>&1 &\n```\n\n这只能做到后台常驻运行，如果想要保证高可用，还要看[这篇](/posts/1559528755)","tags":["常用命令"]},{"title":"cordova项目使用appcenter实现代码热更新","url":"/posts/1574307776/","content":"appcenter.ms 是微软的 app 管理网站，类似国内的友盟。这篇文章介绍使用 appcenter 的 codepush 功能给 cordova 项目实现代码热更新。codepush 除了支持 cordova 外，还支持 react native。\n\n```sh\n# 安装 appcenter\n$ npm install -g appcenter-cli\n# 登录\n$ appcenter login\n# 安装 cordova 插件\n$ cordova plugin add cordova-plugin-code-push@latest\n```\n\n查看自己的 key\n```sh\n$ appcenter codepush deployment list -a {用户名}/{项目名} --displayKeys\n```\n因为 codepush 是被收购后合并到 appcenter 的，所以这里的 key 不是 appcenter 网页上的 key。必需要使用这个命令来查看。这里要注意，用户名既不是邮箱，也不是昵称，而是系统给你分配的用户名，在账号设置里查看。比如我的是boyquestion-163.com。\n\n编辑 config.xml，加入\n```\n<platform name=\"android\">\n    <preference name=\"CodePushDeploymentKey\" value=\"YOUR-ANDROID-DEPLOYMENT-KEY\" />\n</platform>\n<platform name=\"ios\">\n    <preference name=\"CodePushDeploymentKey\" value=\"YOUR-IOS-DEPLOYMENT-KEY\" />\n</platform>\n```\n\n如果你的 config.xml 里不是\n```\n<access origin=\"*\" />\n```\n那么还应该加入\n```\n<access origin=\"https://codepush.appcenter.ms\" />\n<access origin=\"https://codepush.blob.core.windows.net\" />\n<access origin=\"https://codepushupdates.azureedge.net\" />\n```\n\n在代码合适的地方加入\n```js\ndocument.addEventListener(\"resume\", function () {\n    codePush.sync();\n});\n```\n项目就会自动更新了\n\n下次当你编译好新的代码后只要执行\n```sh\n# 测试\n$ appcenter codepush release-cordova -a <ownerName>/<appName> -d Staging\n# 生产。加上 -x 表示默认不生效\n$ appcenter codepush release-cordova -a <ownerName>/<appName> -d Production -x\n```\n就可以推送了。更详细的可以查看参考里的文档。\n\n\n***特别注意***\n每个热更新推送都有一个对应 release 版本（Target Version），这个版本对应用户的 app 版本，不同版本间不会推送。\n\n其实这很好理解，code push 只会更新 web 文件，不会更新插件对应的二进制文件，因此不同版本间的热更新可能会导致插件调用失败。\n\n但是这种更新方式导致除了要维护 app 版本外，还要维护热更新版本。第一次使用的时候令我非常迷惑。\n\n----------------------------------\n参考：  \nhttps://docs.microsoft.com/en-us/appcenter/distribution/codepush/cordova","tags":["最佳实践"]},{"title":"手把手配置cdn","url":"/posts/1572486507/","content":"# 初始配置\n通常 cdn 服务商会让我们配置三个内容\n1. 域名\n2. 源站\n3. 缓存内容规则\n\n比如我的网站已经有了 www.ljj.pub，需要 img.ljj.pub 作为缓存域名。那么①里的域名应该填入 img.ljj.pub。②里的源站填入 www.ljj.pub。这时 nginx 不需要配置 img 域名。\n\ncdn 默认的缓存规则会缓存所有内容，包括动态页面的内容。我需要规则更清楚，因此我设置了按文件类型，.jpg;.jpeg;.png;.svg;.js;.css。过期时间可以自己定。\n\n配置好之后服务商会给一个他们自己的域名，例如 img.ljj.pub.xxx.cloud.cn。**注意这个域名是不能直接访问的**，应该去自己域名的配置页，设置 img.ljj.pub CNAME 指向 img.ljj.pub.xxx.cloud.cn。几分钟后就可以用 img.ljj.pub 访问了。\n\n# https\n新网站 https 是标配，我们自己需要我们自己给出证书。不管是从云服务商申请的，还是自己从证书服务商申请的。快过期的时候都要手动更新。我选择使用 certbot 申请，因为每年自动更新本地证书。\n\n首先因为我的 www 和 img 同源，所以我的 nginx 已经配置了\n> server_name www.ljj.pub img.ljj.pub;\n\n然后执行\n\n```sh\n$ certbot-auto certonly --nginx\n```\n这个命令只申请证书，不配置 nginx。\n\n然后把得到的 fullchain.pem 和 private.pem 里的内容复制到 cdn 配置里面，就可以了。\n\n这样过一会儿，就能访问 https://img.ljj.pub 了。","tags":["最佳实践"]},{"title":"常用命令行处理图片","url":"/posts/1571887927/","content":"# webp 转 png\nwebp 是谷歌推出的格式，压缩率很高，但只能在谷歌内核浏览器使用。如果你用谷歌内核浏览器，有时候下载下载的图片，就是 webp 格式的。\n\n可以用一下命令转成 png 格式使用\n```sh\n# 安装工具\n$ brew install webp\n# 转格式\n$ dwebp ***.webp -o xxx.png\n```\n这个套件还有其他工具，可以进主页查看 https://developers.google.com/speed/webp/\n\n# 规范大小\nmac 自带了一个工具 sips，可以说是神器\n```sh\n# 转换格式\n$ sips -s format jpeg input.png -o output.jpg\n# 规范大小\n$ sips -z pixelsH pixelsW input.png -o output.png\n```\n\n# 压缩\n压缩我暂时只知道 [ImageOptim-CLI](https://github.com/JamieMason/ImageOptim-CLI) 这个工具。这是这个调用本地特定 app 在命令行处理图片。\n\n```sh\n$ imageoptim --imagealpha '**/*.png'\n```\n\n# php批处理代码\n最后用 php 把这几个命令连起来（我是 bash 渣渣）\n```php\n<?php\n$d = dir(getcwd());\nwhile(($file = $d->read()) !== false){\n    if($file == '.' || $file == '..'){\n        continue;\n    }\n    $name = explode('.',$file);\n    exec ('your-command');\n}\n$d->close();\n```\n\n# 在线\n最后推荐几个在线工具救急\n- 在线ps https://ps.gaoding.com/#/\n- 谷歌出的 https://squoosh.app/\n- https://tinypng.com\n- https://tinyjpg.com\n","tags":["常用命令"]},{"title":"命令行翻墙","url":"/posts/1567490025/","content":"假设你已经有了一个ss，ss通过sock5转http帮助我们翻墙。这篇文章转如何给命令行软件设置http代理。\n\n# pip\n~/.config/pip/pip.conf\n```\n[global]\nproxy=http://localhost:1087\n```\n或者用国内镜像\n```\n[global]\nindex-url = http://mirrors.aliyun.com/pypi/simple/\n\n[install]\ntrusted-host=mirrors.aliyun.com\n```\n\n# git\n## clone with ssh\n在 文件 ~/.ssh/config 后添加下面两行\n```\nHost github.com\nProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p\n```\n\n## clone with http\n```\ngit config --global http.proxy http://127.0.0.1:1087\ngit config --global https.proxy http://127.0.0.1:1087\n```\n\n# curl\n~/.curlrc\n```\nsocks5 = \"127.0.0.1:1080\"\n```\n\n# Gradle\n~/.gradle/gradle.properties\n```\nsystemProp.http.proxyHost=127.0.0.1\nsystemProp.http.proxyPort=1087\nsystemProp.https.proxyHost=127.0.0.1\nsystemProp.https.proxyPort=1087\n```\n\n# go get\n```\nHTTP_PROXY=socks5://localhost:1080 go get\n```\n\n# npm\n```\nnpm config set proxy http://127.0.0.1:1087\nnpm config set https-proxy http://127.0.0.1:1087\n```\n\n# yarn\n```\nyarn config set proxy http://XX\nyarn config set https-proxy http://XX\n```\n\n# gem\n~/.gemrc\n```\n---\n# See 'gem help env' for additional options.\nhttp_proxy: http://localhost:1087\n```\n\n# brew\n```\nALL_PROXY=socks5://localhost:1080 brew ...\n```\n\n# wget\n~/.wgetrc\n```\nuse_proxy=yes\nhttp_proxy=127.0.0.1:1087\nhttps_proxy=127.0.0.1:1087\n```\n\n------------------------------\n参考：  \nhttps://github.com/comwrg/FUCK-GFW","tags":["最佳实践"]},{"title":"谷歌Colaboraty使用介绍","url":"/posts/1565938894/","content":"[谷歌Colaboraty](https://colab.research.google.com)是谷歌推出的 python 练习工具，因为提供 GPU 和可以连接谷歌硬盘，非常方便。下面介绍几个常用使用方法。\n\n1. 运行 github 上的项目\n```python\n!git clone https://github.com/Puzer/stylegan-encoder.git\n# 行首加上“!”就可以执行 linux 命令\n\n# 把网盘文件复制到本地\nfrom shutil import copyfile\ncopyfile('/content/drive/My Drive/source/file1', 'target/file1)\n\n# 升级 tensorflow 版本\n!pip install --upgrade tensorflow-gpu\n\n# 降级 tensorflow\n!pip uninstall tensorflow\n!pip install tensorflow-gpu==1.15.3\n\n# 执行文件\nimport os\nos.chdir(\"stylegan-encoder\")\n\n!python train.py\n```","tags":["在线工具"]},{"title":"用ab压测","url":"/posts/1565682061/","content":"# ab\n参数说明：\n- -n: 总请求数，请求结束后退出\n- -c: 一次产生的请求数，即并发个数\n- -p: 模拟post请求，文件格式为gid=2&status=1,配合-T使用\n- -T: post数据所使用的Content-Type头信息，比如 -T 'application/x-www-form-urlencoded'\n\n1. 模拟gei请求\n```\nab -c 10 -n 10 http://www.test.api.com/?gid=2\n```\n\n2. 模拟post请求\n在当前目录下创建一个文件post.txt\n\n编辑文件post.txt写入\n\ncid=4&status=1\n\n相当于post传递cid,status参数\n```\nab -n 100  -c 10 -p 'post.txt' -T 'application/x-www-form-urlencoded' 'http://test.api.com/ttk/auth/info/'\n```\n\n3. 结果分析\n```\nServer Software:        BWS/1.1\nServer Hostname:        www.baidu.com\nServer Port:            80\n\nDocument Path:          /\nDocument Length:        154179 bytes\n\nConcurrency Level:      10\nTime taken for tests:   0.877 seconds\nComplete requests:      10\nFailed requests:        9\n   (Connect: 0, Receive: 0, Length: 9, Exceptions: 0)\nTotal transferred:      1549288 bytes\nHTML transferred:       1539602 bytes\nRequests per second:    11.41 [#/sec] (mean)\nTime per request:       876.697 [ms] (mean)\nTime per request:       87.670 [ms] (mean, across all concurrent requests)\nTransfer rate:          1725.77 [Kbytes/sec] received\n\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:       31   37   5.6     42      42\nProcessing:   201  571 169.9    540     769\nWaiting:       34  107  97.7     50     311\nTotal:        232  608 171.9    582     811\n\nPercentage of the requests served within a certain time (ms)\n  50%    582\n  66%    733\n  75%    753\n  80%    782\n  90%    811\n  95%    811\n  98%    811\n  99%    811\n 100%    811 (longest request)\n```\n当结果里 Failed requests 不为0的时候，就表示已经达到系统最高并发了，这时的 Requests per second 较为准确\n","tags":["运维"]},{"title":"php面试题","url":"/posts/1564977130/","content":"# php\n## php7 为什么比 php5 快\n\n减少内存分配次数，多使用栈内存，缓存数组hash值，字符串解析成参数改为宏展开，使用大块连续内存代替小块碎片内存等等。\n\nPHP7卓越性能背后的原理有哪些？ - 韩天峰的回答 - 知乎\nhttps://www.zhihu.com/question/38148900/answer/75115687\n\n## php 的变量以什么数据结构保存在内存里\n\nphp 内存分为堆内存、栈内存、代码段、初始化静态段。\n\n**栈内间段：**是存储占用相同空间长度并且占用空间小的数据类型的地方，比如说整型1，10，100，1000，10000，100000 等等，在内存里面占用空间是等长的，都是64 位4 个字节。存储的都是局部变量，凡是定义在方法中的都是局部变量（方法外的是全局变量），变量有自己的作用域，一旦离开作用域，变量就会被释放。栈内存的更新速度很快，因为局部变量的生命周期都很短。所以在栈空间的数据都是可以通过代码手动进行释放。\n\n**堆空存段：**数据长度不定长，而且占有空间很大的数据类型的数据。在堆内存是里是不可以直接存取的内存，堆内存存储的是数组和对象（其实数组就是对象）。凡是new建立的都是在堆中，堆中存放的都是实体（对象），实体用于封装数据，而且是封装多个（实体的多个属性），如果一个数据消失，这个实体也没有消失，还可以用，所以堆是不会随时释放的，但是栈不一样，栈里存放的都是单个变量，变量被释放了，那就没有了。堆里的实体虽然不会被释放，但是会被当成垃圾，最后通过垃圾回收机制去实现垃圾回收。对于我们的对象来数就是一种大的数据类型而且是占用空间不定长的类型，所以说对象是放在堆里面的，但对象名称是放在栈里面的，这样通过对象名称就可以使用对象。\n\nhttps://cloud.tencent.com/developer/article/1162322\n\n## php的垃圾回收\n采用计数法，当一个变量增加一个引用的时候，计数加一，没有引用的时候清理掉\n\n## 接口和抽象类的区别\n1. 抽象类可以有构造方法,接口中不能有构造方法。\n2. 接口中每个方法都只有声明而没有实现，其中的每个方法实现类必须要实现；而抽象类中只需要实现抽象方法，其它方法可以选择性的实现\n3. 接口中只能声明public的方法，不能声明private和protected的方法，不能对方法进行实现，也不能声明实例变量；但是抽象类中可以\n4. 一个类可以实现多个接口,但是继承一个抽象类。二者在应用方便也有一定的区别：接口更多的是在系统架构设计方法发挥作用,主要用于定义模块之间的通信契约。而抽象类在代码实现方面发挥作用,可以实现代码的重用,例如,模板方法设计模式是抽象类的一个典型应用,假设某个项目的所有Servlet类都要用相同的方法进行权限判断，记录访问日志和异常处理,那么就可以定义一个抽象的基类,让所有的Servlet都继承这个抽象基类,在抽象基类的service方法中玩具城权限判断,记录访问日志和处理异常的代码,在各个子类中只是完成各自的业务逻辑代码\n5. 抽象类需要继承，用extends，而接口需要实现，用implements\n7. 一个类可以实现多个接口，但只能继承一个抽象类\n\n## public private protect\n- public 外部可调用，子类可调用\n- protect 外部不能调用，子类可调用\n- private 外部不能调用，子类不能调用\n\n## self:: static::\nself::调用父类，static::调用当前类（子类）\n\n# 数据库\n## redis 跳表的数据结构\n简单的来说就是自带了一个跳跃的索引，比如数据是123456789，那么跳表的一级索引可以是148，二级索引是14\n\nhttps://www.jianshu.com/p/d12389b80a19\n\n## redis key 过期策略\n1. 定期删除：每一段时间查找过期的key\n2. 惰性删除：访问key的时候检查是否过期\n## redis 内存淘汰策略\n1. lru(Least Recently Used)：最近最少使用数据淘汰（redis不是使用队列而是使用用时钟生成一个近似顺序）\n2. lfu(Least frequently used)：最少使用数据淘汰（时钟末尾改成计数器）\n[参考](/posts/1628930496)\n\n## 聚簇索引和非聚簇索引的区别\ninnodb 数据是一个b+数，即所有的枝干是主键索引，所有的叶子是数据，叶子和叶子之间首尾连接。这种索引和数据放在一起的结构叫聚簇索引。非主键索引放在另一个文件，枝干是索引，叶子是主键索引。这种索引是一个单独文件的结构，叫非聚簇索引。\n\n## mysql有哪些存储引擎\n1. InnoDB  \n灾难恢复性好  \n支持事务  \n支持行级锁  \n支持外键关联  \n支持热备份  \n对于InnoDB引擎中的表，其数据的物理组织形式是簇表（Cluster Table），主键索引和数据是在一起的，数据按主键的顺序物理分布  \n实现了缓冲管理，不仅能缓冲索引也能缓冲数据，并且会自动创建散列索引以加快数据的获取\n\n2. MyISAM  \n不支持事务  \n使用表级别锁  \n主机宕机后表容易损坏，灾难恢复性不佳  \n数据紧凑存储，因此可以获得更小的索引和更快的全表扫描性能\n\n3. MEMORY(HEAP)  \n全内存表，不支持事务和外键\n\n4. ARCHIVE\n只支持insert 和 select  \n适合归档历史数据，没有索引，查询比较慢\n\n5. Cluster/NDB  \n官方集群方案专用\n\n6. CSV\n\n7. merge/mrg_myisam\n在多个相同的 myisam 表上加一层代理，可以用作水平分表\n[参考](https://www.jianshu.com/p/4320aaaec90d)\n\n8. PERFORMANCE_SCHEMA  \n该引擎主要用于收集数据库服务器性能参数。这种引擎提供以下功能：提供进程等待的详细信息，包括锁、互斥变量、文件信息；保存历史的事件汇总信息，为提供MySQL服务器性能做出详细的判断；对于新增和删除监控事件点都非常容易，并可以随意改变mysql服务器的监控周期，例如（CYCLE、MICROSECOND）。\n\n[参考1](https://blog.csdn.net/Java_fenxiang/article/details/82870335)  \n[参考2](https://www.cnblogs.com/zhuchuanbo/p/8038733.html)\n\n## mysql的4种隔离级别\n1. 读未提交（一个事务可以读另一个事务未提交的内容）\n2. 读已提交（一个事务可以读另一个事务已提交的内容）\n3. 可重读（一个事务不可以读到另一个事务已提交的内容）\n4. 串行化（一次只执行一个事务）\n\n[参考](/posts/1528164495)\n\n# 安全\n## 常见攻击防御\n1. sql注入\n原理：  \n用户提交sql语句，比如 ';update user'，那么后台的sql语句会变成select user '';update user ''\n防御：  \nphp使用pdo\n\n2. xss攻击\n原理：  \n用户上传js脚本，比如商品详情里上传<script></script>\n防御：  \nphp使用htmlspecialchars()转换字符\n\n3. csrf攻击\n原理：  \n黑客模仿（引导）用户身份发出跨站请求\n防御：  \n每次请求由服务端先给出token，请求必须验证token\n\nhttps://segmentfault.com/a/1190000018004657\n\n# 综合\n## 有一个活动预计1000万用户参与，总计10小时，问怎么部署软硬件\n1. 假设是一个力度大的活动，80%流量落在前10分钟，即1.4万qps。然后根据压测数据申请服务器，注意预留30%性能\n2. 如果不是秒杀场景，可以用令牌桶算法限流。秒杀场景由于是先到先得，可以用消息队列缓存\n3. 有资格参加活动的用户和活动奖品可以预先保存在缓存或消息队列里，数据库只保存最终结果\n4. 可以用一致性哈希算法对用户token进行计算，那么特定用户只会访问特定业务服务器，用户数据和页面固定数据可以缓存在各台业务服务器上，避免单key压力\n5. 缓存和数据库采用集群缓解压力\n\n## nginx last 和 break 有什么区别\n两者都是停止后续匹配，last 会重新发起请求，而 break 不会\n\nbreak 通常用于判断如果真实存在的文件,则用break语句停止rewrite检查\n```\nif (-f $request_filename) {\nbreak;\n}\n```\n\n## 数据按 id 哈希分表后，怎么按 username 查询\n1. 另外建一张表，存储 username -> id 作为索引\n2. username 基因融入 id\n[参考](https://blog.csdn.net/wufaliang003/article/details/78763686)\n\n# 反问\n面试最后会问你有什么想问的，这个时候把之前没有答上来的再问回去。这样不一定能面上，但至少能知道答案，避免回去自己在网上查。\n\n其他可以问一下项目组具体是做什么项目，技术栈是什么。","tags":["php"]},{"title":"awk用法举例","url":"/posts/1563502663/","content":"awk 是用来读取文件的每一行，每一列（默认空格分开），然后打印出来的程序。基本语法是\n```\nawk '正则表达式 {操作}' 文件名\n```\n# 基本操作\n下面是一些例子。先来生成一个文件a.txt，内容是\n```\n11 12 13 14 15\n21 22 23 24 25\n31 32 33 34 35\n```\n\n## 初次尝试\nprint 命令表示打印，这个表达式会打印整个文件\n```\n$ awk '{ print }' a.txt\n11 12 13 14 15\n21 22 23 24 25\n31 32 33 34 35\n```\n\n在 print 后面跟 $0 表示列数，$0表示整行（不分列），$1 表示第一列，这个表达式也是打印整个文件\n```\n$ awk '{ print $0 }' a.txt\n11 12 13 14 15\n21 22 23 24 25\n31 32 33 34 35\n```\n\n\"\" 里面放的是要打印字符串，这个命令针对每一行打印 ljj\n```\n$ awk '{ print \"ljj\" }' a.txt\nljj\nljj\nljj\n```\n\n## 多个值\n-F后面跟分隔列的字符串，a.txt是用空格分隔，所以这里跟\" \"。这里打印第一列和第三列\n```\n$ awk -F\" \" '{ print $1 $3 }' a.txt\n1113\n2123\n3133\n```\n\n上面这个把第一列和第三列连起来了，在中间加 \" \" 隔开\n```\n$ awk -F\" \" '{ print $1 \" \" $3 }' a.txt\n11 13\n21 23\n31 33\n```\n\n添加你要的任意字符串\n```\n$ awk -F\" \" '{ print \"第一列：\" $1 \" 第三列：\" $3 }' a.txt\n第一列：11 第三列：13\n第一列：21 第三列：23\n第一列：31 第三列：33\n```\n\n## 扩展脚本\n如果你的命令很复杂，还要多次使用，那么可以保存成文件，新建一个文件 myscript.awk\n```\nBEGIN {\n    FS=\" \"\n}\n{ print $1 }\n```\n然后运行\n```\n$ awk -f myscript.awk a.txt\n```\n\n## 正则表达式\n先来个简单的，打印有 foo 的行\n```\n$ awk '/foo/ {print}'\n```\n\n## 等式\n打印第一列等于 11 的行的第三列\n```\n$ awk '$1 == \"11\" {print $3}' a.txt\n13\n```\n这种等式还支持 “==”, “<“, “>”, “<=”, “>=”, 和 “!=”。此外，“~” 和 “!~” 后面可以跟正则表达式，分别表示包含和不包含\n```\n$ awk '$1 ~ /11/ {print $3}' a.txt\n```\n\n## 条件\n类似程序代码，awk 也支持条件，比如\n```\n{ \n  if ( $5 ~ /root/ ) { \n          print $3 \n  } \n}\n```\n或者更复杂一点\n```\n{ \n  if ( $1 == \"foo\" ) { \n           if ( $2 == \"foo\" ) { \n                    print \"uno\" \n           } else { \n                    print \"one\" \n           } \n  } else if ($1 == \"bar\" ) { \n           print \"two\" \n  } else { \n           print \"three\" \n  } \n}\n```\n\n表达式还能做逻辑判断\n```\n( $1 == \"foo\" ) && ( $2 == \"bar\" ) { print }\n```\n\n## 分隔符\n上面用 -F\" \" 表示用空格座位分隔符，其实 -F 也支持正则表达式。比如多个制表符\n```\n-F\"\\t+\"\n```\n或者别的\n```\n-F\"foo[0‑9][0‑9][0‑9]\"\n```\n\n## 列数\nNF 表示列数（Number of fields），下面判断列数\n```\n$ awk 'NF == 5 {print}' a.txt\n11 12 13 14 15\n21 22 23 24 25\n31 32 33 34 35\n```\n5改成别的数字就不输出了\n\n## 行数\nNR 表示行数(Number of record)，下面判断行数，排除了第2行\n```\n$ awk '(NR<2) || (NR>2) {print}' a.txt\n11 12 13 14 15\n31 32 33 34 35\n```\n\n# 实现SQL\n先新建两个文件\nuser，字段 id name addr\n```\n1 zhangsan hubei\n3 lisi tianjin\n4 wangmazi guangzhou\n2 wangwu beijing\n```\n\nconsumer，字段 id cost date\n```\n1 15 20121213\n2 20 20121213\n3 100 20121213\n4 99 20121213\n1 25 20121114\n2 108 20121114\n3 100 20121114\n4 66 20121114\n1 15 20121213\n1 115 20121114\n```\n\n## where 条件过滤\n```\nselect * from user; \nawk 1 user;\nselect * from consumer where cost > 100;\nawk '$2>100' consumer\n```\n\n## 去重 distinct\n```\nselect distinct(date) from consumer;\nawk '!a[$3]++ {print $3}' consumer\nselect distinct(*) from consumer;\nawk '!a[$0]++' consumer\n```\n这里新建了一个变量数组 a[]，当 a 里没有 key 的时候打印，即第一次打印，余下都跳过\n\n## 排序 order by\n```\nselect id from user order by id;\nawk '{a[$1]}END{asorti(a);for(i=1;i<=length(a);i++) {print a[i]}}' user\n```\n\n## limit\n```\nselect * from consumer limit 2;\nawk 'NR<=2' consumer\nawk 'NR>2{exit}1' consumer # performance is better\n```\n\n## 分组求和统计，关键词：group by、having、sum、count\n```\nselect id, count(1), sum(cost) from consumer group by id having count(1) > 2;\nawk '{a[$1]=a[$1]==\"\"?$2:a[$1]\",\"$2}END{for(i in a){c=split(a[i],b,\",\");if(c>2){sum=0;for(j in b){sum+=b[j]};print i\"\\t\"c\"\\t\"sum}}}' consumer\n```\n\n## 模糊查询，关键词：like（like属于通配，也可正则 REGEXP）\n```\nselect name from user where name like 'wang%';\nawk '$2 ~/^wang/{print $2}' user\nselect addr from user where addr like '%bei';\nawk '/.*bei$/{print $3}' user\nselect addr from user where addr like '%bei%';\nawk '$3 ~/bei/{print $3}' user\n```\n\n## 多表 join 关联查询，关键词：join\n```\nselect a.* , b.* from user a inner join consumer b  on a.id = b.id and b.id = 2;\nawk 'ARGIND==1{a[$1]=$0;next}{if(($1 in a)&&$1==2){print a[$1]\"\\t\"$2\"\\t\"$3}}' user consumer\n```\n\n## 多表水平联接，关键词：union all\n```\nselect a.* from user a union all select b.* from user b;\nawk 1 user user\nselect a.* from user a union select b.* from user b;\nawk '!a[$0]++' user user\n```\n\n## 随机抽样统计，关键词：order by rand()\n```\nSELECT * FROM consumer ORDER BY RAND() LIMIT 2;\nawk 'BEGIN{srand();while(i<2){k=int(rand()*10)+1;if(!(k in a)){a[k];i++}}}(NR in a)' consumer\n```\n\n------------------------------\n参考资料：  \nhttps://developer.ibm.com/tutorials/l-awk1/  \nhttps://my.oschina.net/leejun2005/blog/100710#OSC_h3_5","tags":["常用命令"]},{"title":"用supervisor做高可用","url":"/posts/1559528755/","content":"Supervisor 是 Linux 系统中常用的进程守护程序。它会执行一段 shell 脚本，如果脚本中断，则会自动重新执行。\n\n# 安装 Supervisor\n```\nsudo apt-get install supervisor\n```\n\n# 配置 Supervisor\nSupervisor 配置文件通常存放在 /etc/supervisor/conf.d 目录，在该目录下，可以创建多个配置文件指示 Supervisor 如何监视进程，例如，让我们创建一个开启并监视 queue:work 进程的 laravel-worker.conf 文件：\n```\n[program:laravel-worker]\nprocess_name=%(program_name)s_%(process_num)02d\ncommand=php /home/forge/app.com/artisan queue:work sqs --sleep=3 --tries=3\nautostart=true\nautorestart=true\nuser=forge\nnumprocs=8\nredirect_stderr=true\nstdout_logfile=/home/forge/app.com/worker.log\n```\n在本例中，numprocs 指令让 Supervisor 运行 8 个 queue:work 进程并监视它们，如果失败的话自动重启。当然，你需要修改 queue:work sqs 的 command 指令来映射你的队列连接。\n\n# 启动 Supervisor\n当成功创建配置文件后，需要刷新 Supervisor 的配置信息并使用如下命令启动进程:\n```\nsudo supervisorctl reread\nsudo supervisorctl update\nsudo supervisorctl start laravel-worker:*\n```\n\n--------------------------------\n转自：https://laravelacademy.org/post/19516.html#toc_19  \nSupervisor 官方文档：http://supervisord.org/index.html","tags":["运维"]},{"title":"尽力说清楚POST/PUT/PATCH","url":"/posts/1557286782/","content":"# 首先要先区分 form-data 和 x-www-form-urlencoded\n在 postman 里面，我们可以看到 form-data 的源代码类似\n```\nPOST /api/order?ab=ab HTTP/1.1\nHost: localhost:8081\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW\ncache-control: no-cache\nPostman-Token: 07d87f1e-94fd-4656-881c-898cfc66be36\n\nContent-Disposition: form-data; name=\"goodsId\"\n\n1\n\nContent-Disposition: form-data; name=\"num\"\n\n1\n\nContent-Disposition: form-data; name=\"skuMapIndex\"\n\n黄色>M\n\nContent-Disposition: form-data; name=\"addressId\"\n\n1\n\n------WebKitFormBoundary7MA4YWxkTrZu0gW--\n```\n\nx-www-form-urlencoded 的源代码类似\n```\nPOST /api/order?ab=ab HTTP/1.1\nHost: localhost:8081\nContent-Type: application/x-www-form-urlencoded\ncache-control: no-cache\nPostman-Token: 92f20568-aad7-445d-aaae-e949db87c53d\n%08apiToken=ljjljja=b\n```\n\nx-www-form-urlencoded 优点：\n1. 使用&连接的k=v字符串，更简洁\n\n缺点：\n1. 使用utf-8编码，中文长度变长\n2. 不支持文件（2进制内容）\n\n# POST PUT 和 PATCH\n标准中 post 用来更新全部内容，put 和 patch 用来更新部分资源。其中 put 是幂等的，patch 不是幂等。\n\n但是实际项目中，即使 post 也不会用来更新全部内容，比如 created_time 就一定是服务器端生成，而不是客户端上传。因此这三者更实用上的区别是：**PUT、PATCH 不支持 form-data**","tags":["http"]},{"title":"词性标注","url":"/posts/1557024483/","content":"# 中文词性标注：结巴分词\n词性代碼 | 現代漢语词性 | 词性名称 | 词性代碼的命名方式與補充說明 | 舉例\n--------|------------|--------|--------------------------|----\na | 形容词 | 形容词 | 取英语形容词adjective的第1個字母。 | 大, 好, 新\nag | 形容词 | 形语素 | 形容词性语素。形容词代碼為a，语素代碼g前面置以a。 | 奇, 私, 秀\nad | 形容词 | 副形词 | 直接作狀语的形容词。形容词代碼a和副词代碼d並在一起。 | 完全, 突然, 直接\nan | 形容词 | 名形词 | 具有名词功能的形容词。形容词代碼a和名词代碼n並在一起。 | 安全, 困難, 矛盾\nb | 形容词 | 區別词 | 取漢字“別”的聲母。 | 主要, 副, 總\nc | 连词 | 连接词 | 取英语连词conjunction的第1個字母。 | 和, 而, 但\nd | 副词 | 副词 | 取adverb的第2個字母，因其第1個字母已用於形容词。 | 不, 也, 就\ndg | 副词 | 副语素 | 副词性语素。副词代碼為d，语素代碼ｇ前面置以d。只有兩個。 | 俱, 輒\ndf * | 动词 | 能願动词: 不要 | 专指不要 | 不要\ne | 叹词 | 叹词 | 取英语叹词exclamation的第1個字母。 | 嗯, 哎, 咦\neng * | 外语 | 外语 |  | \nf | 动词 | 方位词(趨向动词) | 取漢字“方”的聲母。 | 上, 中, 後\ng | (難以判斷) | 语素 | 絕大多數语素都能作為合成词的“词根”，取漢字“根”的聲母。 | 浠, 僭, 涔\nh | 副词 | 前接成分 | 取英语head的第1個字母。只有兩個。 | 非, 超低\ni | 形容词 | 成语 | 取英语成语idiom的第1個字母。 | 一口气, 大吃一驚, 九曲迴腸\nj | 名词 | 间称略语 | 取漢字“间”的聲母。 | 法, 人大, 漢\nk | 代词 | 後接成分 | 只有四個。 | 們, 者, 型, 式\nl | (難以判斷) | 慣用语 | 慣用语尚未成為成语，有點“臨時性”，取“臨”的聲母。 | 發言人, 是不是, 沒想到\nm | 數词 | 數词 | 取英语numeral的第3個字母，n，u已有他用。 | 年, 一, 月, 多\nmg * | 名词 | 干支 | 只有兩個。 | 巳, 寅\nmq * | 代词 | 指示代词 | 布丁註：不太確定。 | 這件, 這場, 一方面\nn | 名词 | 名词 | 取英语名词noun的第1個字母。 | 人, 時, 國家\nng | 名词 | 名语素 | 名词性语素。名词代碼為n，语素代碼ｇ前面置以n。 | 子, 身, 師, 眾\nnr | 名词 | 人名 | 名词代碼n和“人(ren)”的聲母並在一起。 | 连, 王, 楊\nnrfg * | 名词 | 完整人名 | 明確可以辨別為人名的词。 | 李自成, 張居正, 康熙\nnrt * | 名词 | 外國名词 | 布丁註：不太確定。 | 二人, 闖王, 崇禎\nns | 名词 | 地名 | 名词代碼n和处所词代碼s並在一起。 | 臺灣, 美國, 日本\nnt | 名词 | 机构团体 | “团”的聲母為t，名词代碼n和t並在一起。 | 國務院, 外交部\nnz | 名词 | 其他专名 | “专”的聲母的第1個字母為z，名词代碼n和z並在一起。 | 百科, 和平, 英语\no | 拟声词 | 拟声词 | 取英语拟声词onomatopoeia的第1個字母。 | 哈哈, 砰, 嗚, 嘿嘿\np | 介词 | 介词 | 取英语介词prepositional的第1個字母。 | 在, 為, 對\nq | 量词 | 量词 | 取英语quantity的第1個字母。 | 道, 個, 家\nr | 代词 | 代词 | 取英语代词pronoun的第2個字母,因p已用於介词。 | 他, 我, 這\nrg * | 代词 | 茲 | 只有一個。 | 茲\nrr * | 代词 | 多數代词 | 只有三個。 | 其他人, 妳們, 偺們\nrz * | 代词 | 這位 | 只有一個。 | 這位\ns | 名词 | 处所词 (方位名词) | 取英语space的第1個字母。 | 心中, 國內, 身上\nt | 副词 | 时间词 | 取英语time的第1個字母。 | 當, 現在, 當時\ntg | 名词 | 時语素 | 时间词性语素。时间词代碼為t,在语素的代碼g前面置以t。 | 現, 晚, 春\nu | 助词 | 助词 | 取英语助词auxiliary的第2個字母,因a已用於形容词。 | 等, 之, 來說\nud * | 助词 | 結構助词: 得 | 只有一個。 | 得\nuj * | 助词 | 結構助词: 的 | 只有一個。 | 的\nuv * | 助词 | 結構助词: 地 | 只有一個。 | 地\nug * | 助词 | 动態助词: 過 | 只有一個。 | 過\nul * | 助词 | 动態助词: 了 | 只有一個。 | 了\nuz * | 助词 | 动態助词: 著 | 只有一個。 | 著\nv | 动词 | 动词 | 取英语动词verb的第一個字母。 | 是, 有, 說\nvg | 动词 | 动语素 | 动词性语素。动词代碼為v。在语素的代碼g前面置以V。 | 喝, 言, 怒\nvd | 动词 | 副动词 | 直接作狀语的动词。动词和副词的代碼並在一起。只有三個。 | 持續, 狡辯, 逆勢\nvi * | 动词 | 不及物动词(內动词) | 只有四個。 | 等同於, 徜徉於, 沉溺於, 沉緬於\nvn | 动词 | 名动词 | 指具有名词功能的动词。动词和名词的代碼並在一起。 | 發展, 工作, 研究\nvq * | 动词 | 完成动词 | 只有四個。 | 去過, 去淨, 唸過, 捱過\nw | (标点符号) | 标点符号 | 布丁註：結巴並沒有內建标点符号词性。 | \nx | (未知词) | 非语素字 | 非语素字只是一個符號，字母x通常用於代表未知數、符號。 | 榪, 姆, 灞\ny | 助词 | 语气词(语气助词) | 取漢字“语”的聲母。 | 呢, 吧, 嗎\nz | 形容词 | 状态词 | 取漢字“狀”的聲母的前一個字母。 | 涓, 優良, 最佳\nzg * | 副词 | 副状态词 | 布丁註：不太確定。 | 很, 此, 較\n\n# 百度词性标注\n## 词性缩略说明\n词性 ｜ 含义 ｜ 词性 ｜ 含义 ｜ 词性 ｜ 含义 ｜ 词性 ｜ 含义\n----｜------｜-----｜-----｜-----｜------｜-----—｜----\nn | 普通名词 ｜ f ｜ 方位名词 ｜ s ｜ 处所名词 ｜ t ｜ 时间名词\nnr ｜ 人名 ｜ ns ｜ 地名 ｜ nt ｜ 机构团体名 ｜ nw ｜ 作品名\nnz ｜ 其他专名 ｜ v ｜ 普通动词 ｜ vd ｜ 动副词 ｜ vn ｜ 名动词\na ｜ 形容词 ｜ ad ｜ 副形词 ｜ an ｜ 名形词 ｜ d ｜ 副词\nm ｜ 数量词 ｜ q | 量词 ｜ r ｜ 代词 ｜ p ｜ 介词\nc ｜ 连词 ｜ u ｜ 助词 ｜ xc ｜ 其他虚词 ｜ w ｜ 变电符号\n\n## 专名识别缩略词含义\n缩略词 ｜ 含义 ｜ 缩略词 ｜ 含义 ｜ 缩略词 ｜ 含义 ｜ 缩略词 ｜ 含义\n------｜-----｜-------｜------｜-------｜-----｜-------｜-----\nPER ｜ 人名 ｜ LOC ｜ 地名 ｜ ORG ｜ 机构名 ｜ TIME ｜ 时间\n\n# 英文词性标注：FastTag\n词性代碼 | 主要词性分類 | 词性說明 | 例子\n--------|-----------|---------|-----\nCC | 连接词 | 连接词(Coord Conjuncn) | and,but,or\nCD | 名词 | 數字(Cardinal number) | one,two\nDT | 冠词 | 冠词(Determiner) | the,some\nEX | 名词 | 存在词(Existential there) | there\nFW | (外语) | 外语(Foreign Word) | mon dieu\nIN | 介系词 | 介词(Preposition) | of,in,by\nJJ | 形容词 | 形容词(Adjective) | big\nJJR | 形容词 | 形容词，比較級(Adj., comparative) | bigger\nJJS | 形容词 | 形容词，最高級(Adj., superlative) | biggest\nLS | 标点符号 | 列點標示(List item marker) | 1,One\nMD | 动词 | 助动词(Modal) | can,should\nNN | 名词 | 名词，單數或不可數(Noun, sing. or mass) | dog\nNNS | 名词 | 名词，複數(Noun, plural) | dogs\nNNP | 名词 | 专有名词，單數(Proper noun, sing.) | Edinburgh\nNNPS | 名词 | 专有名词，複數(Proper noun, plural) | Smiths\nPOS | 介系词 | 名词所有格的完結(Possessive ending) | Õs\nPDT | 形容词 | 前限定词(Predeterminer) | all, both\nPP$ | 代名词 | 所有代名词(Possessive pronoun) | my,oneÕs\nPRP | 代名词 | 人称代名词(Personal pronoun) | I,you,she\nRB | 副词 | 助动词(Adverb) | quickly\nRBR | 副词 | 助动词，比較級(Adverb, comparative) | faster\nRBS | 副词 | 助动词，最高級(Adverb, superlative) | fastest\nRP | 介系词 | 虛词(Particle) | up,off\nSYM | 标点符号 | 符號(Symbol) | +,%,&\nTO | 介系词 | to | to\nUH | 感叹词 | 感叹词(Interjection) | oh, oops\nURL | 名词 | 網址(URL) | http://blog.pulipuli.info/\nVB | 动词 | 动词，原型(verb, base form) | eat\nVBD | 动词 | 动词，過去式(verb, past tense) | ate\nVBG | 动词 | 动词，現在進行式(verb, gerund) | eating\nVBN | 动词 | 动词，過去完成式(verb, past part) | eaten\nVBP | 动词 | 动词，現在式(Verb, present) | eat\nVBZ | 动词 | 动词，現在式第三人用(Verb, present) | eats\nWDT | 名词 | Wh開頭的限定词(Wh-determiner) | which,that\nWP | 代名词 | Wh代名词(Wh pronoun) | who,what\nWP$ | 代名词 | Wh所有格(Possessive-Wh) | whose\nWRB | 副词 | Wh助动词(Wh-adverb) | how,where\n, | (标点符号) | 逗點符號(Comma) | ,\n. | (标点符号) | 句子完結符號(Sent-final punct) | . ! ?\n: | (标点符号) | 句子中間符號(Mid-sent punct.) | : ; Ñ\n$ | (标点符号) | 金錢符號(Dollar sign) | $\n# | (标点符号) | 英鎊符號(Pound sign) | #\n\" | (标点符号) | 括號(quote) | \"\n( | (标点符号) | 左括弧(Left paren) | (\n) | (标点符号) | 右括弧(Right paren) | )\n\n-----------------------------\n参考资料：  \nhttp://blog.pulipuli.info/2017/11/fasttag-identify-part-of-speech-in.html","tags":["机器学习"]},{"title":"消息队列中间件的选型","url":"/posts/1555150954/","content":"看到一篇非常好的对比 Kafka 和 RabbitMQ 的文章，简化一下写在这里。原文参考底部。\n\n# 功能\n## 优先级队列\n优先级队列不同于先进先出队列，优先级高的消息具备优先被消费的特权。这个优先级队列有一个前提：如果消费的速度大于生产的速度，消息无法堆积并排序，那么就不能保证优先级了。\n\n## 延迟队列\n延迟队列一个典型应用是用户下单后没有支付，一定时间后自动取消订单。延迟列队一般分两种：基于消息的延迟和基于队列的延迟。基于消息的延迟是利用优先级队列，插入后重新排序，延迟低的拍前面，每次都排序肯定会对性能造成很大的影响。实际应用中大多采用基于队列的延迟，设置不同延迟级别的队列，比如5s、10s、30s等，每个队列中消息的延迟时间都是相同的。\n\n## 死信队列\n由于某些原因消息无法被正确的投递，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列。与此对应的还有一个“回退队列”的概念，试想如果一个消息被消费多次都失败了，系统决定不再重试，就将其放入一个回退队列。\n\n## 重试队列\n重试队列结合了延迟队列和回退队列。当消费失败，系统将其放入20s的延迟队列，如果再次失败，则放入20s的队列。\n\n## 消费模式\n消费模式分为推（push）模式和拉（pull）模式。推模式是指由队列主动推送，实时性较好，不过要确保不会压垮消费端。而拉模式实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量。\n\n## 广播消费\n广播模式即发布/订阅(Pub/Sub)模式。队列通过推模式，将消息推送给所有订阅者。\n\n## 消息回溯\n相当于日志。消息回溯可以用于 debug 外，还有索引恢复、本地缓存重建，有些业务补偿方案也可以采用回溯的方式来实现。\n\n## 消息堆积+持久化\n流量削峰是消息中间件的一个非常重要的功能，而这个功能其实得益于其消息堆积能力。从某种意义上来讲，如果一个消息中间件不具备消息堆积的能力，那么就不能把它看做是一个合格的消息中间件。特别一提的是，由于 Kafka 是基于硬盘的，所以整个消息队列可以当成数据库来用。\n\n## 消息追踪\n对于消息追踪最通俗的理解就是要知道消息从哪来，存在哪里以及发往哪里去。基于此功能下，我们可以对发送或者消费完的消息进行链路追踪服务，进而可以进行问题的快速定位与排查。\n\n## 消息过滤\n消息过滤是指按照既定的过滤规则为下游用户提供指定类别的消息。比如 Kafka 的 topic。\n\n## 多租户\n各个用户看不到彼此的队列。\n\n## 多协议\n一般消息队列支持的协议有 AMQP、MQTT、STOMP、XMPP等\n\n## 跨语言支持\n提供各种语言的客户端\n\n## 流量控制\n流量控制（flow control）针对的是发送方和接收方速度不匹配的问题，提供一种速度匹配服务抑制发送速率使接收方应用程序的读取速率与之相适应。通常的流控方法有Stop-and-wait、滑动窗口以及令牌桶等。\n\n## 消息顺序性\n必须保证消息严格有序\n\n## 安全机制\n是否提供 TLS/SSL，密码登录等机制\n\n## 消息幂等性\n对于确保消息在生产者和消费者之间进行传输而言一般有三种传输保障（delivery guarantee）：At most once，至多一次，消息可能丢失，但绝不会重复传输；At least once，至少一次，消息绝不会丢，但是可能会重复；Exactly once，精确一次，每条消息肯定会被传输一次且仅一次。对于大多数消息中间件而言，一般只提供At most once和At least once两种传输保障，对于第三种一般很难做到，由此消息幂等性也很难保证。\n\nKafka自0.11版本开始引入了幂等性和事务，Kafka的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚，这两个功能加起来可以让Kafka具备EOS（Exactly Once Semantic）的能力。\n\n## 事务性消息\n即事务开始（Begin Transaction）和事务结束（End Transaction）之间执行的全体操作要么都成果，要么都失败。\n\n功能项 | Kafka(1.1.0) | RabbitMQ(3.6.10)\n------|--------------|-----------------\n优先级队列 | 不支持 | 支持\n延迟队列 | 不支持 | 支持\n死信队列 | 不支持 | 支持\n重试队列 | 不支持 | 不支持\n消费模式 | 拉取 | 推+拉\n广播消费 | 支持 | 支持\n消息回溯 | 支持(offset和timestamp两种维度) | 不支持\n消息堆积 | 支持 | 支持（性能不如Kafka）\n持久化 | 支持 | 支持\n消息追踪 | 不支持 | 支持(Firehose)\n消息过滤 | 客户端级别支持 | 不支持\n多租户 | 支持 | 支持\n多协议 | 不支持 | 支持\n跨语言 | 支持 | 支持\n流量控制 | client和user级别 | 支持\n消息顺序性 | 单分区级别 | 不严格\n安全机制 | （TLS/SSL、SASL）身份认证和（读写）权限控制 | 与Kafka相似\n幂等性 | 支持单个生产者单分区单会话的幂等性 | 不支持\n事务性消息 | 支持 | 支持\n\n# 选型的建议\n消息中间件选型切忌一味的追求性能或者功能，性能可以优化，功能可以二次开发。如果要在功能和性能方面做一个抉择的话，那么首选性能，因为总体上来说性能优化的空间没有功能扩展的空间大。然而对于长期发展而言，生态又比性能以及功能都要重要。\n\n------------------------------\n参考：https://blog.csdn.net/u013256816/article/details/79838428","tags":["分布式"]},{"title":"zookeeper怎么用","url":"/posts/1555060655/","content":"zookeeper 功能简单，但是原理非常复杂，内部用 paxos 算法实现数据同步。\n\n# 安装\n```sh\n$ cp conf/zoo_example.cfg conf/zoo.cfg #里面的 tickTime=2000 表示2秒检查一次，分布式锁可以以此作为过期时间\n$ bin/zkServer.sh start\n$ bin/zkCli.sh -server 127.0.0.1:2181\n\nhelp #查看帮助\n```\n\n# 命名服务\n```sh\ncreate /foo bar #创建数据\nset /foo b #修改数据\ncreate -s /foo bar #得到 /foo0000000001\ncreate -s /foo bar #得到 /foo0000000002\n```\n可以看到 create -s /foo 的时候实际创建的是 /foo0000000001。foo后面跟的数字是有序的，可以作为集群获得唯一有序名称的来源。\n\n# 注册中心\n注册中心的需求是当集群里面有新节点进入或老节点退出的时候，其他节点能得到通知并更新数据。可以使用 zookeeper 的临时数据和观察特定来做到。\n\ncreate -e 命令创建一个临时数据，当创建者断开连接的时候，数据被清除。利用的是心跳机制。\nls -w 观察一个节点\n\n客户端1\n```sh\ncreate /namespace\ncreate -e /namaspace/node1 #得到临时key\n```\n\n客户端2\n```sh\nls -w /namespace\n```\n\n这个时候删除 /namespace/node1 或者直接退出客户端1\n\n客户端2\n```sh\nWATCHER::\n\nWatchedEvent state:SyncConnected type:NodeChildrenChanged path:/namespace\n```\n\n我们发现当客户端1退出的时候，客户端2收到了通知。这个时候客户端2只要重新从zookeeper拉取一次数据，就得到了最新的数据\n[延伸阅读1]\n\n# 分布式锁/集群选主\n当一个客户端创建了 /path 数据后，别的客户端就不能创建了。利用这个特性可以实现分布式锁。\n\n如果有一个集群需要一个主节点，这个主节点退出后其他节点得到通知，创建一个临时数据作为锁，申请到的节点就自封为主节点。如果这个主节点退出，那么这个锁会一起被清除。不影响其他节点申请锁。\n\n# zookeeper 选举原理\n## paxos 算法\npaxos 算法是选举算法的一种，原理是客户端向一个节点写入数据的时候，节点把请求发给其他所有节点，如果得到了半数以上节点同意的回复，返回成功。这里同意的回复表示该节点的数据版本低于更新数据的版本。反对则表示该节点的数据也被另一个客户端改过了，版本号相同或更高。\n\n## fast-paxos 算法\npaxos 允许所有节点可写，但是每次写数据都要经过选举，太慢。fast-paxos 算法给系统中选举出一个主节点，只有这个主节点可写，其他节点收到的写请求都被转发到这个主节点。\n\n这种单写的优点是选出主节点后就不需要选举了，而且所有数据是有序的。缺点是单写有性能瓶颈。\n\n## 主节点选举，选举阶段 Leader election\nzookeeper 的主节点退出后其他节点会拒绝所有客户端写请求，进入选举状态。每个节点有一个XZID表示本地最新的事务编号\n1. 所有节点处于Looking状态，各自依次发起投票，投票包含自己的服务器ID和最新事务ID（ZXID）。\n2. 如果发现别人的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点。\n3. 每次投票后，服务器都会统计投票数量，判断是否有某个节点得到半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点的状态变为Following。\n\n## 发现阶段 Discovery\n1. 为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。[延伸阅读2]\n2. Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。\n3. 各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。\n\n## 同步阶段 Synchronization\nLeader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。\n\n---------------------------\n延伸阅读\n1. 为什么 Apollo 没有使用 zookeeper?\n\n[Apollo](https://github.com/ctripcorp/apollo)使用的是 Eureka。因为 zookeeper 获得通知后要再次订阅，才能再次获得通知。\n\n2. 如果发生脑裂怎么办\n\n脑裂指的是系统彻底分成两个部分，两个部分根据选举都选出了主节点。zookeeper规定服务器必须过半，即数量不到一半的那个网络，会停止服务。\n\n---------------------------\n参考：  \nhttps://juejin.im/post/5cdbda12e51d453ccd24650f  \nhttps://blog.csdn.net/u013256816/article/details/80865540","tags":["分布式"]},{"title":"mysql集群方案","url":"/posts/1554880199/","content":"上一篇文章提到 MySQL 集群方案，除了（[分布式系统的ID](/posts/1553830839)）里提到的通过 ID 分片外，官方有许多集群方案，这篇文章介绍几个。\n\n# InnoDB Cluster (MySQL 7+)\n## MySQL Router\n之前的文章[mysql配置主从分离](/posts/1528164516) 但是没有说怎么做高可用，MySQL Router 即是扮演这个角色，在 master 不可用的时候，选择一台 slaver 充当主。MySQL Router 原理类似 LVS，有一个 VIP 暴露给应用层，而应用层不需要知道内部数据库服务器的增减。注意 Router 本身不提供高可用，可以通过 keepalived 提供。\n\n配置文件如下：\n```sh\n[mysql@hdp2~]$more /etc/mysqlrouter.conf\n[DEFAULT]\n# 日志路径\nlogging_folder = /home/mysql/mysql-router-2.1.6/log\n \n# 插件路径\nplugin_folder = /home/mysql/mysql-router-2.1.6/lib/mysqlrouter\n \n# 配置路径\nconfig_folder = /home/mysql/mysql-router-2.1.6/config\n \n# 运行时状态路径\nruntime_folder = /home/mysql/mysql-router-2.1.6/run\n \n# 数据文件路径\ndata_folder = /home/mysql/mysql-router-2.1.6/data\n \n[logger]\n# 日志级别\nlevel = INFO\n \n# 以下选项可用于路由标识的策略部分\n[routing:basic_failover]\n# Router地址\nbind_address = 172.16.1.125\n# Router端口\nbind_port = 7001\n# 读写模式\nmode = read-write\n# 目标服务器\ndestinations = 172.16.1.126:3306,172.16.1.127:3306\n \n# routing:名称没有要求\n[routing:load_balance]\nbind_address = 172.16.1.125\nbind_port = 7002\nmode = read-only\ndestinations = 172.16.1.126:3306,172.16.1.127:3306\n```\n\n配置字段[routing:basic_failover]部分对应写服务器(master)规则，对应SQL: INSERT, UPDATE...，[routing:load_balance]部分对应读服务器(slave)规则，对应SQL: SELECT。如果有其他集群，还可以继续配置。\n\nmode字段可选值有 read-write和read-only\n\nread-write 表示前一个服务器失败后，按照顺序启用后一个服务器。所有的请求都集中在一个服务器。如果前一个服务器恢复了，也不会加回到路由表。只能重启 Router。\n\nread-only 表示一个服务器失败后，会按照顺序启用后一个服务器。所有的请求会按照顺序分配到各个服务器。如果前一个服务器恢复了，可以加回到路由表。\n\n由此可知，写服务只能选择 read-write。如果读服务对一致性有高要求，也应该选择 read-write，如果没有高要求，可以选择 read-only。\n\n查看路由\n\n```sh\nC:\\WINDOWS\\system32>mysql -utest -p123456 -h172.16.1.125 -P7001 -e \"show variables like 'server_id'\"\nmysql: [Warning] Using a password on the command line interface can be insecure.\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| server_id     | 127   |\n+---------------+-------+\n```\n\n## 集群配置\n- 服务器（至少3台）：svr1, svr2, svr3\n\n配置文件 my.cnf\n- 修改不同机器的名称或IP；\n- server_id使用不同编号；\n- loose-group_replication_group_name使用UUID形式，集群中机器使用同一个UUID；\n- loose-group_replication_single_primary_mode在单主模式中为ON，在多主模式中为OFF。\n\n```ini\n[mysqld]\n# server configuration\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\ndatadir         = /var/lib/mysql\nlog-error       = /var/log/mysql/error.log\nbind-address    = 0.0.0.0\n# Disabling symbolic-links is recommended to prevent assorted security risks\n#symbolic-links = 0\n# Replication configuration parameters\nserver_id = 1 #2,3\ngtid_mode = ON\nenforce_gtid_consistency = ON\nmaster_info_repository = TABLE\nrelay_log_info_repository = TABLE\ntransaction_write_set_extraction = XXHASH64\nbinlog_checksum = NONE\nlog_slave_updates = ON\nlog_bin = binlog\nbinlog_format = ROW\nrelay-log = svr-relay-bin\n#\n# Group Replication configuration\nloose-group_replication_group_name = a38e32fd-5fb6-11e8-ad7a-00259015d941\nloose-group_replication_start_on_boot = OFF\nloose-group_replication_local_address = svr1:33061\nloose-group_replication_group_seeds = svr1:33061,svr2:33061,svr3:3306\nloose-group_replication_bootstrap_group = OFF\nloose-group_replication_allow_local_disjoint_gtids_join = ON\n# Group Replication configuration multi-primary mode\nloose-group_replication_single_primary_mode = OFF\nloose-group_replication_enforce_update_everywhere_checks = ON\n```\n\n创建集群\n\n```sh\n$ sudo -i mysqlsh --uri=user@svr1:3306\nmysql-js> dba.checkInstanceConfiguration('user@svr1:3306') #检查配置\n\n#创建集群\nmysql-js> var cluster = dba.createCluster('mysqlCluster')  # 单主模式集群\nmysql-js> var cluster = dba.createCluster('mysqlCluster', {multiMaster:true})  # 多主模式集群\nmysql-js> cluster.addInstance('user@svr2:3306')\nmysql-js> cluster.addInstance('user@svr3:3306')\n\n#查看状态\nmysql-js> var cluster = dba.getCluster()\nmysql-js> cluster.status();\n```\n\n# NDB Cluster\nNDB Cluster 的采用的是 NDB 引擎，和InnoDB最大的区别是隔离级别只支持 Read Committed。因为InnoDB的默认隔离级别是 Repeatable Read，所以在设计数据库和迁移数据库的时候要格外注意这点。NDB Cluster 官方提供了专门的安装引导，这里就不详细说明了。\n\n----------------------------\nPS\n其实是看到 MySQL Fabric 方案才想写这篇文章的，不过从官方网站上看，好像 Fabric 方案已经被废弃了。\n\n----------------------------\n参考资料：  \n[适用MySQL Router实现高可用](https://blog.csdn.net/wzy0623/article/details/81103469)  \n[MySQL InnoDB Cluster配置](https://www.jianshu.com/p/6e2918845ec8)  \n[通过例子理解mysql事务的4种隔离级别](/posts/1528164495)","tags":["mysql"]},{"title":"实时大数据sql方案","url":"/posts/1554870854/","content":"\n使用SQL的好处是当我们的需求改变的时候，不用改程序，只用改SQL语句即可。但单体sql引擎无法满足大数据的实时计算，这里介绍几种可行的方案。\n\n# 数据库集群\n如果系统数据库已经采用了分片集群，那么可以采用分而治之的方案，从各个集群中先统计出部分数据，再归总。\n\n**优点**\n- 不用新建系统\n- 速度快\n\n**缺点**\n- 如果数据库不是集群，则要新建系统\n- 无法分而治之的情况不能适用\n\n# ElasticSearch SQL\nES 最近公布了新的 SQL 功能，给开发者带来了福音。三个方案里首选的就是这个，因为搭建方便\n\n**优点**\n- 搭建简单\n\n**缺点**\n\n\n现在没有修改的功能，下面是支持的语句\n\n命令 | 说明\n----|-----\nDESC table | 用来描述索引的字段属性\nSHOW COLUMNS | 功能同上，只是别名\nSHOW FUNCTIONS | 列出支持的函数列表，例如count(), sum()，支持通配符过滤\nSELECT .. FROM table_name WHERE .. GROUP BY .. HAVING .. ORDER BY .. LIMIT .. | 用来执行查询的命令\n\n现在试试看，先建一条数据\n```\nPOST twitter/doc/\n{\n  \"name\":\"medcl\",\n  \"twitter\":\"sql is awesome\",\n  \"date\":\"2018-07-27\",\n  \"id\":123\n}\n```\n\n然后查询\n```\nPOST /_xpack/sql?format=txt\n{\n    \"query\": \"SELECT * FROM twitter\"\n}\n```\n**因为 SQL 特性是 xpack 的免费功能，所以是在 _xpack 这个路径下面，我们只需要把 SQL 语句传给 query 字段就行了，注意最后面不要加上 ; 结尾，注意是不要！**\n\n下面是比较常用的函数\n\nname      |     type      \n----------------|---------------\nAVG             | AGGREGATE\nCOUNT           |AGGREGATE\nMAX             |AGGREGATE\nMIN             |AGGREGATE\nSUM             |AGGREGATE\nSTDDEV_POP      |AGGREGATE\nVAR_POP         |AGGREGATE\nPERCENTILE      |AGGREGATE\nPERCENTILE_RANK |AGGREGATE\nSUM_OF_SQUARES  |AGGREGATE\nSKEWNESS        |AGGREGATE\nKURTOSIS        |AGGREGATE\nDAY_OF_MONTH    |SCALAR   \nDAY             |SCALAR   \nDOM             |SCALAR   \nDAY_OF_WEEK     |SCALAR   \nDOW             |SCALAR   \nDAY_OF_YEAR     |SCALAR   \nDOY             |SCALAR   \nHOUR_OF_DAY     |SCALAR   \nHOUR            |SCALAR   \nMINUTE_OF_DAY   |SCALAR   \nMINUTE_OF_HOUR  |SCALAR   \nMINUTE          |SCALAR   \nSECOND_OF_MINUTE|SCALAR   \nSECOND          |SCALAR   \nMONTH_OF_YEAR   |SCALAR   \nMONTH           |SCALAR   \nYEAR            |SCALAR   \nWEEK_OF_YEAR    |SCALAR   \nWEEK            |SCALAR   \nABS             |SCALAR   \nACOS            |SCALAR   \nASIN            |SCALAR   \nATAN            |SCALAR   \nATAN2           |SCALAR   \nCBRT            |SCALAR   \nCEIL            |SCALAR   \nCEILING         |SCALAR   \nCOS             |SCALAR   \nCOSH            |SCALAR   \nCOT             |SCALAR   \nDEGREES         |SCALAR   \nE               |SCALAR   \nEXP             |SCALAR   \nEXPM1           |SCALAR   \nFLOOR           |SCALAR   \nLOG             |SCALAR   \nLOG10           |SCALAR   \nMOD             |SCALAR   \nPI              |SCALAR   \nPOWER           |SCALAR   \nRADIANS         |SCALAR   \nRANDOM          |SCALAR   \nRAND            |SCALAR   \nROUND           |SCALAR   \nSIGN            |SCALAR   \nSIGNUM          |SCALAR   \nSIN             |SCALAR   \nSINH            |SCALAR   \nSQRT            |SCALAR   \nTAN             |SCALAR   \nSCORE           |SCORE    \n\n# Hadoop + Hive（非实时）\nHadoop 由于是 MapReduce 方案，无法保证实时，但是 Hadoop 生态非常大，可能有实时方案，姑且介绍一下。\n\nHadoop + Hive 方案是最早的方案，Hadoop 负责存储和分发数据，Hive 负责解析SQL和处理数据。其中 Hive 支持作为 thrift 服务，能够很好的融入到微服务系统中。\n\n**优点**\n- 节点数和数据量没有限制\n- 在SQL无法满足的情况下可以自己写程序弥补\n\n**缺点**\n- 搭建困难\n- 不是实时\n\n这里有一份[大数据学习笔记](https://chu888chu888.gitbooks.io/hadoopstudy/) 介绍框架的搭建方案。","tags":["elasticsearch"]},{"title":"docker基础知识","url":"/posts/1554604484/","content":"# Docker\n## 镜像\n镜像是大家制作的程序包，里面可以只有 linux 环境，也可以包含特定的软件。\n```sh\n$ docker image ls # 列出本地所有镜像\n$ docker image rm [imageName] # 删除制定镜像\n$ docker image pull hello-world # 下载镜像到本地\n```\n\n## 容器\n容器是运行中的镜像。docker 会把镜像复制一份，然后运行。\n```sh\n$ docker container run hello-world\n```\nhello-world 是 docker 官方的镜像。如果没有执行 image pull，会自动下载。\n\n因为容器是镜像复制出来的，所以一旦运行后，也会有文件生成\n```sh\n$ docker container ls # 列出运行中的容器\n$ docker container ls --all # 包括没在运行的容器\n$ docker container rm [containerId] # 删除容器文件\n```\n\n## 开一个可交互的 nginx 容器\n```sh\n$ docker container run \\\n  -d \\ # 后台运行\n  -p 127.0.0.1:8080:80 \\ # 容器内的 80 端口映射到本地8080端口\n  -p 127.0.0.1:8081:443 \\ # 容器内的 443 端口映射到本地8081端口\n  --rm \\ # 停止运行后删除容器\n  --name mynginx \\ #容器命名为mynginx\n  --volume \"$PWD/html\":/usr/share/nginx/html \\ #映射文件目录到本地\n  --volume \"$PWD/conf\":/etc/nginx \\ #映射配置文件到本地\n  nginx\n```\n\n## 针对 linux\n```sh\n$ sudo groupadd docker # 添加 docker 组\n$ sudo usermod -aG docker $USER # 将用户添加到 docker 组\n$ sudo systemctl start docker # systemctl 开启服务\n$ sudo service docker start # 或者 service 开启服务\n```\n\n# Dockerfile\n下面来做一个 swoole 本地开发 dockerfile\n```dockerfile\n# 在 PHP 官方镜像基础上构建\nFROM php:7.2-cli\n\n# 复制本地文件到 /tmp\nCOPY swoole.tar.gz /tmp\n\n# 指定接下来的工作目录\nWORKDIR /app\n\nRUN tar -xzf /tmp/swoole.tar.gz -C /tmp/swoole --strip-components=1 \\\n  && phpize \\\n  && ./configure \\\n  && make \\\n  && make install \\\n  && docker-php-ext-enable \\\n  && rm -f /tmp/swoole.tar.gz \\\n  && rm -f /tmp/swoole \\\n\n# 映射文件\nVOLUME [\"/app\",\"/www\"]\n\n# 暴露 8081 端口\nEXPOSE 8081\n```\n\n编译运行\n```sh\n$ docker image build -t swoole-dev . # -t 后面跟镜像的名字\n$ docker container run -p 8000:3000 swoole-dev\n```\n\n# Docker Compose\n如果我们有多个服务，比如 wordpress + mysql，这个时候要先启动 mysql，然后根据 mysql 的 ip，改变 wordpress 的配置。这种情况，就要用到 docker compose 了。下面是一个例子\n```yml\n# 文件 docker-compose.yml\nmysql:\n    image: mysql:5.7\n    environment:\n        - MYSQL_ROOT_PASSWOD=123456\n        - MYSQL_DATABASE=wordpress\nweb:\n    image: wordpress\n    links:\n        - mysql\n    environment:\n        - WORDPRESS_DB_PASSWORD=123456\n    ports:\n        - \"127.0.0.1:8080:80\"\n    working_dir: /var/www/html\n    volumes:\n        - wordpress: /var/www/html\n```\n\n执行\n```sh\n$ docker-compose up # 启动所有服务\n$ docker-compose stop # 关闭所有服务\n$ docker-compose rm # 删除容器\n```\n\n# 其他有用的命令\n```sh\n$ docker container start [containerId] #启动容器\n$ docker container stop [containerId] #停止容器，先发出 SIGTERM 信号，然后发出 SIGKILL 信号\n$ docker container kill [containerId] # 杀死运行中的容器，发出 SIGKILL 信号\n$ docker container logs [containerId] # 查看 shell 输出\n$ docker container exec -it [containerId] /bin/bash # 进入到容器内部 linux 环境\n$ docker container cp [containerId]:[/path/to/file] # 复制容器\n$ docker container inspect [containerId] # 查看容器 IP 地址\n```\n\n------------------------------\n参考资料：  \nhttp://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html  \nhttp://www.ruanyifeng.com/blog/2018/02/docker-wordpress-tutorial.html  \nhttp://www.ruanyifeng.com/blog/2018/02/nginx-docker.html","tags":["运维"]},{"title":"分布式系统的ID","url":"/posts/1553830839/","content":"在分布式系统中，为了适应可能有多台主（写）服务器，任何时刻都可能有服务器加进来或者去掉这种情况，就不能用传统的数据库自增ID方案。这篇文章介绍几个在分布式系统中用的ID生成方案。\n\n# 业务服务器\n业务服务器指的是我们写的后端服务器。这里的着重点是自己生成id，不需要数据库自己给出一个自增id。\n\n## 自增\n自增ID是最简单的方案，数据库自己提供了这个功能。但是一旦有多台写服务器就不能适用了。而且自增ID会影响写性能，在数据库的写性能是整个系统性能瓶颈的情况下，能减轻一点压力都是好的。\n\n## 有序uuid\nuuid是一个32位的字符串ID，在服务器本地生成，可以保证单机生成的ID在整个系统中独立。原始版本的uuid是无序的，这在数据库取出一系列有序数据时非常影响性能。幸好现在已经有了可以生成有序uuid的算法，比如 Laravel 的 Str::orderedUuid()。但是由于uuid是32位字符串，依然影响性能。\n\n## snowflake\n之前的文章[大型服务器的架构](/posts/1532314825)中描述了蚂蚁金服的id生成方案，即是一种类snowflake结构。原始的snowflake结构是\n\n> 41位时间+10位机器编号+12位自增序列号\n\n因为id中包含了机器号，所以能保证绝对不会和其他服务器生成的id重复。但是这要求机器自己知道自己的id，比如在初始化的时候从管理服务处获得，或者有一个独立的id生成服务器。\n\n参考资料[1]介绍了一种 php 的 snowflake id 生成算法。\n\n# 资源服务器\n资源服务器指的是数据库或者缓存。这里的着重点是如何分布式存储数据，即每台服务器内容不同。\n\n## 取模\n获得业务服务器生成的id后，为了存储在不同的服务器，可以将id取模。比如我们有4台服务器，那么 id%4 的到的余数就是我们要的机器id，然后就可以存储到对应的数据库了。但是如果服务器数量增加或者减少，取模后的到的余数就不能对应到原来的机器id，原来的数据也就不能正常取出了。\n\n## 一致性哈希算法\n简单的来说，一致性哈希算法就是把数据 id 和 服务器 id 进行相同的哈希，然后存储在一个被分成 2^32 部分的圆中，存取的时候找到离数据右边最近的服务器。比如服务器id \"S1\", \"S2\" 哈希后投射到圆上的两个点，把这两个点中间的所有点取出来，就是下面这段\n\nS1-------------------S2\n\n这时有个数据id，哈希后的值落在 S1 S2 之间，会被存储在 S2 里。这时增加服务器 S3\n\nS1---------S3----------S2\n\n这时数据id哈希后落在 S1~S3 会存储在S3中，S3~S2 会存储在S2中。这里需要手动把S2里面应该落在S3的数据（永久缓存）手动转移到S3中。\n\n参考资料[3][4]介绍了一种 php 的一致性哈希算法。\n\n### 算法最佳实践\n一般用time33 和 crc32 作为哈希算法。但是由于我们起的原始ID不够离散，很容易只落在几个服务器上，所以建议在哈希之前再加一层md5。下面是time32的算法\n```php\nfunction time33($str) {\n    // hash(i) = hash(i-1) * 33 + str[i]\n    $hash = 0;\n    $s    = md5($str); //让id更加离散\n    $seed = 5;\n    $len  = 32;\n    for ($i = 0; $i < $len; $i++) {\n        // (hash << 5) + hash 相当于 hash * 33\n        //$hash = sprintf(\"%u\", $hash * 33) + ord($s{$i});\n        //$hash = ($hash * 33 + ord($s{$i})) & 0x7FFFFFFF;\n        $hash = ($hash << $seed) + $hash + ord($s{$i});\n    }\n \n    return $hash & 0x7FFFFFFF;\n}\n \n//echo myHash(\"却道天凉好个秋~\");\necho \"key1: \" . myHash(\"key1\") . \"\\n\";\n```\n\n### 业务最佳实践\n另一个业务上的最佳实践是，不一定按照ID进行哈希。比如我们有一个论坛，访问量最大的就是按板块分的帖子页，即需要一次性取出一个板块里面的一批帖子。我们希望这些帖子是在一台服务器上的，那么就不能按照帖子id哈希，而要按照板块id哈希。\n\n如果这时我们有其他列表业务，比如一个用户的所有帖子。我的建议是缓存一个用户的前1000个帖子id到 redis。\n\n# 对外混淆\n对于对外接口，要将ID混淆，避免关键信息暴露，这种情况可以使用 [hashids](https://hashids.org)。这个库可以将数字id可逆的转成字符串。\n\n------------------------------\n参考资料：  \n[1]https://huoding.com/2016/11/03/552  \n[2]https://blog.csdn.net/bntX2jSQfEHy7/article/details/79549368  \n[3]https://blog.csdn.net/jt521xlg/article/details/49360895  \n[4]http://www.cnblogs.com/phpfans/p/4641490.html","tags":["分布式"]},{"title":"前端axios踩坑","url":"/posts/1553242000/","content":"axios 库是前端非常流行的网络请求库，下面是我刚使用的时候遇到的坑\n\n本地开发跨域问题（CORS），首先在服务端要接受跨域\n```php\nheader(\"Access-Control-Allow-Origin: *\");\n```\n\n这个时候 axios 在 post/put 的时候会先发起 option 请求。如果服务器不支持，则返回失败。为了避免这个，要避免 json 请求。qs 库可以把 json 解析成 www-form 的样子，即 a=1&b=2\n\naxios 有两个数据参数 params 和 data，params 会被放到 url 里，data 会被放到 body 里\n\n```js\nconst qs = require('qs')\n\n  param.headers = {\n    'Content-type': 'application/x-www-form-urlencoded;charset=utf-8'\n  }\n  let method = param.method ? param.method.toUpperCase() : 'GET'\n  if(method == 'POST' || method == 'PUT'){\n    param.data = qs.stringify(param.data, {arrayFormat: 'brackets'})\n  } else {\n    param.params = param.data\n    param.paramsSerializer = params => {\n      return qs.stringify(params, {arrayFormat: 'brackets'})\n    }\n  }\naxios(param)\n```\n\n像上面这样修改后，浏览器就不会报跨域错误了，而且服务端还能获得 form 参数，而不是 json。","tags":["javascript"]},{"title":"mac安装swoole","url":"/posts/1552358380/","content":"在 mac 下 pecl 识别不了 openssl 依赖路径，只能手动编译安装。具体的方法是先下载 swoole 安装包，如果是用 pecl 下载，那么安装包应该在 /tmp/pear/download 里面。\n\n然后执行\n\n```sh\n$ brew install openssl #如果需要支持 openssl\n$ brew install nghttp2 #如果需要支持 http2\n$ cd swoole\n$ phpize\n$ ./configure --enable-openssl --enable-http2 --enable-sockets --enable-mysqlnd -with-openssl-dir=/usr/local/Cellar/openssl/1.0.2q/\n$ make && make install\n```\n\n然后把 extension=swoole 写入 php.ini","tags":["php"]},{"title":"php结合xdebug和vscode调试","url":"/posts/1551930448/","content":"# 准备工作\n1. php 安装 xdebug 扩展\n```sh\npecl install xdebug\n```\n添加配置\n```\n[xdebug]\nzend_extension=xdebug.so\nxdebug.remote_enable = 1\nxdebug.remote_autostart = 1\nxdebug.remote_port = 9001\n; 默认端口号是9000，跟php-fpm冲突\n```\n\n2. vscode 安装 PHP Debug 扩展\n点菜单的调试-打开配置-PHP，在配置里添加\n```\n\"configurations\": [\n    {\n        \"name\": \"Listen for XDebug\",\n        \"type\": \"php\",\n        \"request\": \"launch\",\n        \"port\": 9001\n    },\n```\n\n# 使用\n点左边菜单的小虫子，然后就可以正常的调试了\n","tags":["php"]},{"title":"mysql中文全文搜索","url":"/posts/1551925134/","content":"# 基础\nElasticsearch 是全文搜索的首选，但是对于资金没有那么充足，或者数据量没有那么多的团队，MySQL 提供的全文搜索已经可以满足需求。\n\nMySQL 的全文搜索默认不支持中文，如果要支持中文，要在配置里加入\n\n```\n[mysqld]\nngram_token_size=2\n```\n这个时候 MySQL 可以搜索至少两个字的关键词，1个字还是不能搜索的。然后在建索引的时候要设置 WITH PARSER ngram\n\n```sql\nmysql> USE test;\n\nmysql> CREATE TABLE articles (\n      id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,\n      title VARCHAR(200),\n      body TEXT,\n      FULLTEXT (title,body) WITH PARSER ngram\n    ) ENGINE=InnoDB CHARACTER SET utf8mb4;\n\nmysql> SET NAMES utf8mb4;\n\nINSERT INTO articles (title,body) VALUES\n    ('数据库管理','在本教程中我将向你展示如何管理数据库'),\n    ('数据库应用开发','学习开发数据库应用程序');\n```\n\n对于已存在的表，这样建立索引\n```sql\nCREATE TABLE articles (\n      id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,\n      title VARCHAR(200),\n      body TEXT\n     ) ENGINE=InnoDB CHARACTER SET utf8;\n\nALTER TABLE articles ADD FULLTEXT INDEX ft_index (title,body) WITH PARSER ngram;\n\n# Or:\n\nCREATE FULLTEXT INDEX ft_index ON articles (title,body) WITH PARSER ngram;\n```\n\n现在可以这样搜索\n```sql\nSELECT * FROM articles WHERE MATCH(title,body) AGAINST('数据库教程');\n```\n注意这里不管是索引还是关键词“数据库教程”，我都没有做分词，MySQL都自动处理了。\n\n# 高级\n## IN NATURAL LANGUAGE MODE\n默认的搜索方式是 IN NATURAL LANGUAGE MODE，即全部匹配关键词，使用如下\n```sql\nmysql> SELECT * FROM articles\n    WHERE MATCH (title,body)\n    AGAINST ('database' IN NATURAL LANGUAGE MODE);\n+----+-------------------+------------------------------------------+\n| id | title             | body                                     |\n+----+-------------------+------------------------------------------+\n|  1 | MySQL Tutorial    | DBMS stands for DataBase ...             |\n|  5 | MySQL vs. YourSQL | In the following database comparison ... |\n+----+-------------------+------------------------------------------+\n2 rows in set (0.00 sec)\n```\n即使不加 IN NATURAL LANGUAGE MODE 也是这个结果\n\n## IN BOOLEAN MODE\nBOOLEAN MODE 提供高级搜索方法，使用如下\n```sql\nmysql> SELECT * FROM articles WHERE MATCH (title,body)\n    AGAINST ('+MySQL -YourSQL' IN BOOLEAN MODE);\n+----+-----------------------+-------------------------------------+\n| id | title                 | body                                |\n+----+-----------------------+-------------------------------------+\n|  1 | MySQL Tutorial        | DBMS stands for DataBase ...        |\n|  2 | How To Use MySQL Well | After you went through a ...        |\n|  3 | Optimizing MySQL      | In this tutorial we will show ...   |\n|  4 | 1001 MySQL Tricks     | 1. Never run mysqld as root. 2. ... |\n|  6 | MySQL Security        | When configured properly, MySQL ... |\n+----+-----------------------+-------------------------------------+\n```\n这里关键词里面的\n- +表示必须有\n- -表示必须没有\n- 不加符号表示可有可没有\n- @表示距离，即关键词必须在某距离内，例如 MATCH(col1) AGAINST('\"word1 word2 word3\" @8' IN BOOLEAN MODE)\n- < > 这两个符号表示关键词权重，> 提升权重，< 降低权重\n- ( ) 表示表达式优先级\n- ~ 表示关键词可以没有，如果有，则降低权重\n- *匹配以关键词开始的词（见下面例子）\n- \" 匹配完整的词\n\n例子：\n- 'apple banana'  \n包含至少一个词\n\n- '+apple + juice'  \n必须包含两个词\n\n- '+apple macintosh'  \n包含\"apple\"，如果也包含“macintosh”则提高优先级\n\n- '+apple -macintosh'  \n包含'apple'但是不能包含 'macintosh'\n\n- '+apple ~macintosh'  \n包含'apple'，如果也包含'macintosh'，则降低优先级\n\n- '+apple +(>turnover <strudel)'  \n包含 'apple' 和 'turnover'，或者 'apple' 和 'strudel'（顺序不限），前者比后者优先级高\n\n- 'apple*'  \n匹配所有'apple'开头的词，如'apples','applesauce'，或'applet'\n\n- '\"some words\"'  \n匹配完整的词，例如匹配\"some words of wisdom\"，但不匹配\"some noise words\"\n\n## with Query Expansion\nwith Query Expansion 表示联想词。如果用户给的关键词太少，MySQL 会自动联想出其他关键词，例如如果用户搜索'database'，MySQL 会自动匹配 'MySQL', 'Oracle', 'DB2'和'RDBMS'，使用如下\n\n```sql\nmysql> SELECT * FROM articles\n    WHERE MATCH (title,body)\n    AGAINST ('database' IN NATURAL LANGUAGE MODE);\n+----+-------------------+------------------------------------------+\n| id | title             | body                                     |\n+----+-------------------+------------------------------------------+\n|  1 | MySQL Tutorial    | DBMS stands for DataBase ...             |\n|  5 | MySQL vs. YourSQL | In the following database comparison ... |\n+----+-------------------+------------------------------------------+\n2 rows in set (0.00 sec)\n\nmysql> SELECT * FROM articles\n    WHERE MATCH (title,body)\n    AGAINST ('database' WITH QUERY EXPANSION);\n+----+-----------------------+------------------------------------------+\n| id | title                 | body                                     |\n+----+-----------------------+------------------------------------------+\n|  5 | MySQL vs. YourSQL     | In the following database comparison ... |\n|  1 | MySQL Tutorial        | DBMS stands for DataBase ...             |\n|  3 | Optimizing MySQL      | In this tutorial we will show ...        |\n|  6 | MySQL Security        | When configured properly, MySQL ...      |\n|  2 | How To Use MySQL Well | After you went through a ...             |\n|  4 | 1001 MySQL Tricks     | 1. Never run mysqld as root. 2. ...      |\n+----+-----------------------+------------------------------------------+\n6 rows in set (0.00 sec)\n```\n\n# 预先分词\nngram 分词是按照词长度来分的，比如当 ngram_token_size=2 时，'分词是按照词长'会被分成'分词 是按 照词 长'这样。效果不是特别好我们更想要自然的分词方法。我的做法是可以先用分词器分好词，比如结巴分词的 cut_for_search，然后用空格分开后保存到专门的列里，这个列的索引使用默认英文模式就行。查询的时候也分好词，这样就能更准确的找到结果了。\n\n可以用我封装的[结巴分词服务](/posts/1540123748)来实现分词接口。***不过要注意，要设置ft_min_word_len=2（对应 MyISAM），innodb_ft_min_token_size=2（对应 InnoDB），否则两个字的词搜不到。***\n\n# 注意\n1. 如果索引是 (title,body)，则不能只搜索 title 或 body\n2. 有时候我们要去掉表里的某一行，不是删除，而是做一个标记，例如 isDeleted。由于全文索引是单独的索引，不能同时包含 isDeleted 列，所以数据量大的话，建议单独建表来存放，而不是在原表上建立索引\n3. 不要使用 MyISAM，遇到一些坑\n\n--------------------------------\n参考资料：  \nMySQL中文支持设置 https://dev.mysql.com/doc/refman/5.7/en/fulltext-search-ngram.html  \nBOOLEAN MODE https://dev.mysql.com/doc/refman/5.7/en/fulltext-boolean.html\n","tags":["mysql"]},{"title":"用javascript做爬虫的正确姿势","url":"/posts/1551423297/","content":"之前写过[用PHP做爬虫的正确姿势](/posts/1538110935/)和[用python做爬虫的正确姿势](/posts/1529320519/)。但是从上一篇文章[php异步编程](/posts/1547608999/)我们知道，在有大量的网络请求等待的情况下，异步是提高系统并发能力的手段。爬虫由于有大量的网络请求，nodejs 天然的异步成为了做爬虫的最佳选择。这篇文章介绍相应的库。\n\n第一个是请求库，我选择的是[axios](https://github.com/axios/axios)。\n\n第二个是dom解析库[cheerio](https://github.com/cheeriojs/cheerio)。这个基本就是 jQuery 的翻版。由于 jQuery 本身也是 javascript 实现的，所以 cheerio 比之前的 PHP 和 python 版本实现的更好。\n\n用 javascript 做爬虫还有一个好处，就是如果页面里面有 json，不需要分割出 json，只需要给整个<script></script>段执行 eval()，然后返回想要的变量即可。当然这时候要注意改变 this 的作用域，避免污染全局变量。\n\n--------------------------------\n篇外废话：现在的后端架构基本上是一个比较简单的语言来实现应用层，加一个速度快的语言来实现数据层。javascript 因为跟 php 差不多简单，再加上本身就是异步，实现了高效的io，是比 php 更好的应用层选择。","tags":["最佳实践","javascript"]},{"title":"用ulimit增加fd以提升服务连接数","url":"/posts/1550135408/","content":"之前的文章[《php异步编程》](/posts/1547608999/)中介绍了 php 在常驻系统的情况下，怎么通过异步操作来减少等待时间，增加并发数。但是系统不管是接受客户端的长链接请求（web socket）还是建立上游的链接，都需要打开 file descriptors（文件描述符，简称fd）。系统对 fd 数量是有限制的，增加 fd 数量，就能显著增加并发数。\n\nulimit 命令可以查看和修改每个用户对系统使用的指标，先来看一下 ulimit 怎么使用\n\n```sh\n$ ulimit -a\n-t: cpu time (seconds)         unlimited\n-f: file size (blocks)         unlimited\n-d: data seg size (kbytes)     unlimited\n-s: stack size (kbytes)        8192\n-c: core file size (blocks)    0\n-m: resident set size (kbytes) unlimited\n-u: processes                  192276\n-n: file descriptors           21000\n-l: locked-in-memory size (kb) unlimited\n-v: address space (kb)         unlimited\n-x: file locks                 unlimited\n-i: pending signals            192276\n-q: bytes in POSIX msg queues  819200\n-e: max nice                   30\n-r: max rt priority            65\n-N 15:                         unlimited\n```\n\n## 推荐的 unlimit 设置\nulimit 分为“硬”和“软”两个指标，“硬”指标限制用户可以开启的进程数，“软”指标限制实际处理运行的进程数（我也不是太清除）。用 -H 和 -S 来查看和修改。下面是 MongoDB 推荐的设置：\n- -f (file size): unlimited\n- -t (cpu time): unlimited\n- -v (virtual memory): unlimited\n- -l (locked-in-memory size): unlimited\n- -n (open files): 64000\n- -m (memory size): unlimited\n- -u (processes/threads): 64000\n\n大部分参数都是不限制，只给了我们最关心的 open files 和 processes/threads 限制，因此是比较通用的。linux 默认的 open files 只有1000，加大是非常有必要的。至于64000是不是最合适的值，还需要压测后才能知道。\n\n## 使用 Upstart 的 linux\n```sh\nlimit fsize unlimited unlimited    # (file size)\nlimit cpu unlimited unlimited      # (cpu time)\nlimit as unlimited unlimited       # (virtual memory size)\nlimit memlock unlimited unlimited  # (locked-in-memory size)\nlimit nofile 64000 64000           # (open files)\nlimit nproc 64000 64000            # (processes/threads)\n```\n\n## 使用 systemd 的 linux\n```sh\n[Service]\n# Other directives omitted\n# (file size)\nLimitFSIZE=infinity\n# (cpu time)\nLimitCPU=infinity\n# (virtual memory size)\nLimitAS=infinity\n# (locked-in-memory size)\nLimitMEMLOCK=infinity\n# (open files)\nLimitNOFILE=64000\n# (processes/threads)\nLimitNPROC=64000\n```\n\n修改后记得重启服务或系统\n\n-----------------------------\n参考资料  \nhttps://docs.mongodb.com/manual/reference/ulimit/","tags":["运维"]},{"title":"php异步编程","url":"/posts/1547608999/","content":"# 前言\n我对 php 异步的知识还比较混乱，写这篇是为了整理，可能有错。\n\n传统的 php-fpm 一个进程执行一个请求，要达到多少并发，就要生成多少个进程。更糟糕的是每次请求都需要重新编译执行，导致并发一直上不来。因此出现了 Swoole 和 WorkerMan 两个国内流行的常驻内存框架[1]。这两个框架原理都是通过事件循环，让程序一直停留在内存，等待外部请求，达到高并发。\n\n# 为什么需要异步\n## 先来看一个例子\n在工作目录下新建文件 slowServer.php\n```php\n<?php\nsleep(5); // 5秒后才能返回请求\necho 'done';\n```\n开启服务\n```sh\n$ php -S localhost:8081 slowServer.php\n```\n\n开另一个终端，安装依赖\n```sh\n$ pecl install event # 安装 event 扩展\n$ composer require workerman/workerman\n$ composer require react/http-client:^0.5.9\n```\n\n新建文件 worker.php\n```php\nrequire_once __DIR__ . '/vendor/autoload.php';\nuse Workerman\\Worker;\nuse Workerman\\Connection\\AsyncTcpConnection;\nuse Amp\\Artax\\Response;\n\n$http_worker = new Worker(\"http://0.0.0.0:8082\");\n\n$http_worker->count = 1; // 只开一个进程\n\n$http_worker->onMessage = function($connection, $host) {\n    echo 1;\n    $data = file_get_contents('http://localhost:8081');\n    $connection->send($data);\n};\n\nWorker::runAll();\n```\n开启服务器\n```sh\nphp worker.php start\n```\n\n在浏览器开启两个标签，都打开网址 http://localhost:8082 。这时可以看到终端输出“1”，过了一会儿又输出“1”，原因是8081服务器在处理第一个请求的时候阻塞在了等待8081返回之中，等第一个请求结束后，才开始处理第二个请求。也就是说请求是一个一个执行的，要达到多少个并发，就要建立多少个进程，跟 php-fpm 一样。现在修改一下代码\n\n```php\n$http_worker->onMessage = function($connection, $host) {\n    echo 1;\n    $loop    = Worker::getEventLoop();\n    $client  = new \\React\\HttpClient\\Client($loop);\n    $request = $client->request('GET', 'http://localhost:8081');\n    $request->on('error', function(Exception $e) use ($connection) {\n        $connection->send($e);\n    });\n    $request->on('response', function ($response) use ($connection) {\n        $response->on('data', function ($data) use ($connection) {\n            $connection->send($data);\n        });\n    });\n    $request->end();\n};\n```\n现在打开服务，再在浏览器发起请求，发现第二个“1”在请求后就马上输出了，而这时第一个请求还没结束。这表明进程不再阻塞，并发量取决于 cpu 和 内存，而不是进程数。\n\n## 为什么需要异步\n通过上面的例子已经很明白了，reactphp 框架通过把 http 请求变成异步，让 onMessage 函数变成非阻塞，cpu 可以去处理下一个请求。即从 cpu 循环等待 8081 返回，变成了 epoll 等待。\n\n**异步的意义在于把 cpu 从 io 等待中解放出来，可以处理其他计算任务。** 如果你想知道怎么用框架实现异步，看到这里就可以了。WorkerMan 配合 ReactPHP 或者自身的 AsyncTcpConnection 已经可以满足很多 io 请求异步化的需求。下面继续讨论这些框架是怎么做到异步的。\n\n## 哪些地方应该被做成异步\n通过上面的例子已经知道一旦执行到不需要 cpu，但是要等待 io 的时候，应该把 io 的过程做成异步。\n\n# 实现事件循环\n上面的例子是通过 reactphp 把 http 请求变成了异步，其实 WorkerMan 框架本身也是异步的，下面来看看 WorkerMan 是怎么使 onMessage 函数可以异步接受请求。先来新建下面这个文件 react.php\n```php\n<?php\n$context = stream_context_create();\n$socket = stream_socket_server('tcp://0.0.0.0:8081', $errno, $errmsg, STREAM_SERVER_BIND | STREAM_SERVER_LISTEN,$context); // 注册一个 fd（file descriptor)\n\nfunction react($socket){\n    $new_socket = stream_socket_accept($socket, 0, $remote_address);\n    echo 1;\n}\n\n$eventBase = new EventBase();\n$event = new Event($eventBase, $socket, Event::READ | Event::PERSIST, 'react', $socket); // 注册一个事件，检测 fd 有没有写入内容\n$event->add();\n$eventBase->loop(); // 开始循环\n```\n开始执行\n```\n$ php react.php\n```\n在另一个终端执行\n```sh\ntelnet 127.0.0.1 8081\n```\n这时就会看到第一个终端输出'1'。\n\n我之前写过一篇文章[《php使用epoll》](/posts/1529483141)，是这篇文章的基础。那篇文章里事件回调是通过定时来实现，即\n```php\n$event->add($seconds);\n```\n\n而这里，事件回调是通过检测 fd 是否有写入内容来实现，这个过程不需要 cpu 参与。当 fd 有内容写入时，会调函数 'react'，这时开始使用 cpu。如果这时候进程执行另一个异步请求，比如用 reactphp 框架请求一个网页，那么程序会让出 cpu，此时如果有另一个请求进来，就可以回调执行另一个 'react' 函数。由此提高了并发量。\n\n# 协程\n## 生成器 Generater\n这是生成器的 PHP 官方文档 http://php.net/manual/zh/language.generators.php\n```php\n<?php\nfunction gen_one_to_three() {\n    for ($i = 1; $i <= 3; $i++) {\n        //注意变量$i的值在不同的yield之间是保持传递的。\n        yield $i;\n    }\n}\n\n$generator = gen_one_to_three();\nforeach ($generator as $value) {\n    echo \"$value\\n\";\n}\n```\n生成器就是每次程序执行到 yield 的时候保存状态，然后返回 $i，是否继续执行 gen_one_to_three 里的循环，取决于主程序是否继续调用\n\n## 什么是协程\n上面的程序另一种写法是\n```php\n<?php\n$i = 1;\nfunction gen_one_to_three() {\n    global $i;\n    if ($i<=3){\n        return $i++;\n    }\n}\n\nwhile ($value = gen_one_to_three()) {\n    echo \"$value\\n\";\n}\n```\n由此可见，协程就是一种对函数的封装，使其变成一种可以被中断的函数，行为更像是子进程或子线程，而不是函数。协程的具体写法这里不细写，因为协程的写法十分复杂，可能需要再做一层封装才能好用。\n\n## 协程与异步\n既然协程可以被中断，那么只要在程序发起请求后发起事件循环，然后用 yield 返回，然后程序继续执行主程序部分，等事件返回后触发函数，执行 Generatot::next() 或 Generator::send() 来继续执行协程部分。封装好后就好像没有异步回调函数一样，和同步函数很像。\n\n现在已经有 [ampphp](amphp.org) 和 [swoole](www.swoole.com) 两个框架封装了协程，有兴趣可以了解一下。\n\n----------------------------------------\n1. 国外还有 https://amphp.org 和 https://reactphp.org 这两个框架","tags":["php"]},{"title":"我的PHP编译参数","url":"/posts/1544584259/","content":"由于 PHP 高度依赖第三方插件，导致编译 PHP 变成一个难题。线上环境要求一致，不允许使用 yum 或 apt 来安装，只能在编译环境编译好后复制到线上，因此每一个 PHP 程序员都应该有一份自己的编译参数。这篇文章介绍我的参数。\n\n已升级到 php 7.4\n\n```sh\n# 首先编译环境要先安装好\n$ yum install libcurl-devel libjpeg-turbo-devel libpng-devel libxml2-devel openssl-devel zlib-devel libsqlite3x-devel oniguruma-devel\n\n# 然后开始编译安装\n# --prefix 是安装的目录\n$ ./configure --prefix=/data/server/php \\\n--enable-fpm \\\n--enable-ftp \\\n--enable-pcntl \\\n--enable-mbstring \\\n--enable-sockets \\\n--enable-sysvmsg \\\n--enable-sysvsem \\\n--enable-sysvshm \\\n--enable-shmop \\\n--enable-pdo \\\n--enable-bcmath \\\n--enable-cli \\\n--with-curl \\\n--with-openssl \\\n--enable-gd \\\n--with-pdo-mysql \\\n--with-zlib\n\n$ make && make install\n```\n\n其他选项\n```php\n$ yum install libwebp-devel libXpm-devel\n$ ./configure \\\n--enable-embed \\ # 允许打包进别的程序\n--with-webp-dir \\ # 支持webp图片格式\n--with-xpm-dir \\ # 支持xpm图片格式\n```","tags":["php"]},{"title":"lumen和workerman结合会遇到的问题","url":"/posts/1544255132/","content":"# $_FILE\nCLI 模式不支持 move_uploaded_file() 函数，因此 $_FILE 内容会和默认的不一样，需要手动处理。参考 http://doc.workerman.net/web-server.html\n\n# 报错\n由于 CLI 模式不支持 header() 函数，需要使用 WorkerMan 自带的 Http::header() 代替。我的做法是在\n> app/Exceptions/Handler.php\n\nrender() 函数加上 Http::header()\n\n# Authentiate 中间件\n默认的 app/Http/Middleware/Authentiate.php 出错会返回\n```php\nreturn response('Unauthorized.', 401);\n```\n改成\n```php\nabort(401);\n```\n即可\n\n# Auth Guard 保留登录信息\n如果使用了 Auth 中间件，程序会一直保留登录信息，不管谁登录都返回第一个用户。我的做法是复制默认的 RequestGuard.php 到\n> app/Services/Auth/RequestGuard.php\n\n并增加函数\n```php\npublic function logout()\n{\n    $this->user = null;\n}\n```\n\n然后在\n> app/Providers/AuthServiceProvider.php\n\n里增加这个 guard\n```php\npublic function boot()\n{\n    $this->app['auth']->extend('api', function($app, $name, array $config) {\n        return new RequestGuard(function ($request) {\n            if ($request->input('apiToken')) {\n                $user = new User;\n                return $user->getByApiToken($request->input('apiToken'));\n            }\n        },\n        $app['request'],\n        $app['auth']->createUserProvider());\n    });\n}\n```\n\n然后修改\n> app/Http/Middleware/Authenticate.php\n\n```php\npublic function handle($request, Closure $next, $guard = null)\n{\n    $guard = $this->auth->guard($guard);\n    $guard->setRequest($request); // 这里是为了每次请求都重新设置一遍参数\n    if ($guard->guest()) {\n        return response('Unauthorized.', 401);\n    }\n\n    return $next($request);\n}\n```\n\n最后在每次请求完后执行一次\n```php\napp('auth')->logout();\n```\n清理登录信息\n\n# lumen和event扩展冲突\n如果系统里安装了 event 扩展，Lumen 在使用 artisan 或者 bootstrap/app.php 里打开了 $app->withFacades()，那么系统会报\n\n> Cannot declare class Event, because the name is already in use\n\nLaravel 不知道会不会报错，估计也会。\n\n这时候在 Console/Kernel.php 里加入\n```php\nprotected $aliases = false;\n```\n就可以了。代价是不能使用 Facades 了。","tags":["php"]},{"title":"kubernetes基本操作","url":"/posts/1543981565/","content":"kubernetes 官方提供了非常好的交互学习平台 https://kubernetes.io/docs/tutorials/ ，这篇文章是当作一个命令参考，毕竟这些命令不常用，容易忘。\n\n# 基本概念\n- Cluster 集群，一个集群里有一个 Master 和数个 Node\n- Node 通常拿一台物理机座位图一个 Node，也可以用虚拟机\n- Pod 是一个 docker 实例，一个 Node 里有一个或多个 Pod\n- Deployment 一个发布，可以包含一个或多个 Pod\n- Service deployment 暴露出来的服务，内置了负载分发\n\n# 创建集群\n```sh\nminikube start # \b创建集群\n\n$ kubectl get nodes # 查看所有 nodes\nNAME       STATUS    ROLES     AGE       VERSION\nminikube   Ready     <none>    19s       v1.10.0\n```\n\n# 发布应用\n```sh\n$ kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080 # 启动一个应用\ndeployment.apps/kubernetes-bootcamp created\n\n$ kubectl get deployments # 查看所有应用\nNAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp   1         1         1            1           50s\n\n$ kubectl proxy # 转发本地端口到 pod 的端口\n```\n\n# 查看应用\n```sh\n$ kubectl get pods # 查看所有 pods\nNAME                                   READY     STATUS    RESTARTS   AGE\nkubernetes-bootcamp-5c69669756-85r9w   0/1       Pending   0          1s\n\n$ kubectl describe pods # \b\b查看 pods 详情\nName:           kubernetes-bootcamp-5c69669756-85r9w\nNamespace:      default\nNode:           minikube/172.17.0.11\nStart Time:     Wed, 05 Dec 2018 05:55:14 +0000\nLabels:         pod-template-hash=1725225312\n                run=kubernetes-bootcamp\nAnnotations:    <none>\nStatus:         Running\nIP:             172.18.0.4\nControlled By:  ReplicaSet/kubernetes-bootcamp-5c69669756\nContainers:\n  kubernetes-bootcamp:\n    Container ID:   docker://a7a117005de01756ff3eb0800b91ef089810db413961c86d14fdf9cd8c451754\n    Image:          gcr.io/google-samples/kubernetes-bootcamp:v1\n    Image ID:       docker-pullable://gcr.io/google-samples/kubernetes-bootcamp@sha256:0d6b8ee63bb57c5f5b6156f446b3bc3b3c143d233037f3a2f00e279c8fcc64af\n    Port:           8080/TCP\n    Host Port:      0/TCP\n    State:          Running\n  .\n  .\n  .\n\n$ kubectl logs kubernetes-bootcamp-5c69669756-85r9w # pod 的访问日志\n$ kubectl exec kubernetes-bootcamp-5c69669756-85r9w env # \b在 pod 里执行 shell（查看环境变量）\n\b$ kubectl exec -ti kubernetes-bootcamp-5c69669756-85r9w bash # 登录到 pod 里\n```\n\n# 暴露应用\n## \b创建服务\n```sh\n$ kubectl expose deployment/kubernetes-bootcamp --type=\"NodePort\" --port 8080 # 暴露服务\n\n$ kubectl get services\nNAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\nkubernetes            ClusterIP   10.96.0.1        <none>        443/TCP          5m\nkubernetes-bootcamp   NodePort    10.102.235.226   <none>        8080:32115/TCP   4m\n\n$ kubectl describe services/kubernetes-bootcamp # 查看服务详情\nName:                     kubernetes-bootcamp\nNamespace:                default\nLabels:                   run=kubernetes-bootcamp\nAnnotations:              <none>\nSelector:                 run=kubernetes-bootcamp\nType:                     NodePort\nIP:                       10.102.235.226\nPort:                     <unset>  8080/TCP\nTargetPort:               8080/TCP\nNodePort:                 <unset>  32115/TCP\nEndpoints:                172.18.0.4:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n\n$curl 172.17.0.49:32115 # 服务已经暴露在32115端口\nHello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-5c69669756-hh4k7 | v=1\n```\n\n## 使用 label\n```sh\n$ kubectl describe deployment # 查看服务发布\nName:                   kubernetes-bootcamp\nNamespace:              default\nCreationTimestamp:      Wed, 05 Dec 2018 06:07:06 +0000\nLabels:                 run=kubernetes-bootcamp\nAnnotations:            deployment.kubernetes.io/revision=1\nSelector:               run=kubernetes-bootcamp\nReplicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  run=kubernetes-bootcamp\n  Containers:\n   kubernetes-bootcamp:\n    Image:        gcr.io/google-samples/kubernetes-bootcamp:v1\n    Port:         8080/TCP\n.\n.\n.\n\n$ kubectl get pods -l run=kubernetes-bootcamp # 只列出某个 label 的 pods\n$ kubectl get services -l run=kubernetes-bootcamp # 只列出某个 label 的 services\n$ kubectl label pod $POD_NAME app=v1 # 给 deployment 改 label\n```\n\n## 删除 services\n```sh\n$ kubectl delete service -l run=kubernetes-bootcamp # 删除 services\n```\n删除 services 只会删除转发，其对应的 pod 还在运行，还可以用 kubectl exec 进行交互\n\n# 扩展应用\n## 扩展发布\n```sh\n$ kubectl scale deployments/kubernetes-bootcamp --replicas=4 # 把 deployment 扩展为4个实例\n\n$ kubectl get deployments\nNAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp   4         4         4            4           3m\n\n$ kubectl get pods -o wide\nNAME                                   READY     STATUS    RESTARTS   AGE       IP           NODE\nkubernetes-bootcamp-5c69669756-4lzwf   1/1       Running   0          2m        172.18.0.7   minikube\nkubernetes-bootcamp-5c69669756-hbrb8   1/1       Running   0          3m        172.18.0.3   minikube\nkubernetes-bootcamp-5c69669756-rr92t   1/1       Running   0          2m        172.18.0.6   minikube\nkubernetes-bootcamp-5c69669756-z4ld6   1/1       Running   0          2m        172.18.0.5   minikube\n```\n\n## 缩减发布\n```sh\n$ kubectl scale deployments/kubernetes-bootcamp --replicas=2 # 把 deployment 缩减为2个实例\n```\n\n# 更新应用\n## 替换镜像\n```sh\n$ kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2 # 换镜像\n\n$ kubectl rollout status deployments/kubernetes-bootcamp # 查看新镜像配置状态\ndeployment \"kubernetes-bootcamp\" successfully rolled out\n\n$ kubectl describe pods\nName:           kubernetes-bootcamp-7799cbcb86-prj8w\nNamespace:      default\nNode:           minikube/172.17.0.81\nStart Time:     Wed, 05 Dec 2018 06:33:29 +0000\nLabels:         pod-template-hash=3355767642\n                run=kubernetes-bootcamp\nAnnotations:    <none>\nStatus:         Running\nIP:             172.18.0.9\nControlled By:  ReplicaSet/kubernetes-bootcamp-7799cbcb86\nContainers:\n  kubernetes-bootcamp:\n    Container ID:   docker://76d31785dc318d21ba1c822c64f24c7f58701dfe761d2c1cb8df03002d568732\n    Image:          jocatalin/kubernetes-bootcamp:v2 # 镜像已经替换\n    Image ID:       docker-pullable://jocatalin/kubernetes-bootcamp@sha256:fb1a3ced00cecfc1f83f18ab5cd14199e30adc1b49aa4244f5d65ad3f5feb2a5\n.\n.\n.\n```\n\n## 回滚\n```sh\n$ kubectl rollout undo deployments/kubernetes-bootcamp # 回滚\n```","tags":["运维"]},{"title":"百度地图全国市区商圈和地铁线路","url":"/posts/1542940944/","content":"从百度地图和高德地图中提炼出了对应的接口，方便iOS直接调用。\n\n1.获取全国地铁城市：\n\nhttp://map.baidu.com/?qt=subwayscity&t=123457788\n\n2.根据获取的城市code查询地铁线路详情\n\nhttp://map.baidu.com/?qt=bsi&c=citycode&t=123457788\n\n3.百度地图行政区及商圈接口分析：\n参数： \nqt=sub_area_list  固定参数\next=1  固定参数 \nareacode 地区代码(中国是1，湖北省是15，武汉市是218，武昌区是2788)\nlevel 查询深度 1 2 3\nbusiness_flag 是否查商圈（注意，这个参数只有在areacode为区时查商圈时传1；其它情况传0，否则查询不到数据）\n\n所有 省-市县-区    \nhttp://api.map.baidu.com/shangquan/forward/?qt=sub_area_list&ext=1&level=3&areacode=1&business_flag=0\n\n武汉市的区\nhttp://api.map.baidu.com/shangquan/forward/?qt=sub_area_list&ext=1&level=1&areacode=218&business_flag=0\n\n洪山区的商圈\nhttp://api.map.baidu.com/shangquan/forward/?qt=sub_area_list&ext=1&level=1&areacode=2403&business_flag=1\n\n弊端：\n1.此接口返回的数据始终有一些冗余的热门城市数据。\n2.查商圈的时候返回了商圈的区域坐标，数据量大，废流量。\n3.无法同时返回某个市的所有区的商圈，只能一个区一个区的查询。\n\n高德地图行政区与商圈API分析：\n参数：\nsubdistrict  期望返回多少级下级行政区信息，可选值：0、1、2、3\nkey 申请的数据接口密钥\ns=rsv3  不知道干嘛，不能缺\noutput  返回数据类型，默认是 json ，不传也可以\nkeywords  搜索关键字\n\n武汉市的所有区\nhttp://restapi.amap.com/v3/config/district?subdistrict=2&key=778e8bd7e977163d8b3ded18de20099c&s=rsv3&output=json&keywords=武汉市\n\n高德获取商圈\nhttp://report.amap.com/ajax/districtRank.do?linksType=3&cityCode=110000\n\n--------------------- \n参考资料：  \nhttps://blog.csdn.net/tanqian351/article/details/80509942  \nhttps://blog.csdn.net/qq_912917507/article/details/81085535","tags":["数据"]},{"title":"tar常用命令","url":"/posts/1541569442/","content":"```sh\n$ tar cf etcbak.tar etc/  # 把 etc/ 打包成一个tar\n$ tar xf etcbak.tar -C ./        # 解开一个tar 到当前目录\n$ tar czf etcbak.tar.gz etc/ # 把 etc/ 打包压缩一个 tar\n$ tar zxf etcbak.tar.gz -C ./  # 解压一个tar 到当前目录\n```\n\n- v 显示详情。例如：cvf, zxvf\n- C 指定目录。不加默认当前目录","tags":["常用命令"]},{"title":"unix/linux chmod 权限计算器","url":"/posts/1541565980/","content":"<form name=\"chmod\">\n<table border=\"0\" align=\"center\" cellpadding=\"4\" cellspacing=\"0\" class=\"datatable\" style=\"font:normal 12px Verdana\" ;=\"\">\n    <tbody><tr align=\"LEFT\" valign=\"MIDDLE\"> \n        <td class=\"adHeadline\">Permissions:&nbsp; </td>\n        <td>\n        <input type=\"text\" name=\"t_total\" value=\"751\" size=\"4\" onkeyup=\"octalchange()\">\n        </td>\n        <td>&nbsp; \n        <input type=\"text\" name=\"sym_total\" value=\"\" size=\"12\" readonly=\"1\" style=\"border: 0px none; font-family: &quot;Courier New&quot;, Courier, mono;\">\n        </td>\n    </tr>\n    </tbody>\n</table>\n<br>\n<table border=\"0\" align=\"center\" cellpadding=\"4\" cellspacing=\"0\" class=\"datatable\" style=\"font:normal 12px Verdana\">\n    <tbody><tr bgcolor=\"#009900\"> \n        <td width=\"60\" align=\"left\"> </td>\n        <td width=\"55\" align=\"center\" style=\"color:white\"><b>owner </b></td>\n        <td width=\"55\" align=\"center\" style=\"color:white\"><b>group </b></td>\n        <td width=\"55\" align=\"center\" style=\"color:white\"><b>other </b></td>\n    </tr>\n    <tr bgcolor=\"#dddddd\"> \n        <td width=\"60\" align=\"left\" nowrap=\"\" bgcolor=\"#FFFFFF\">read</td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#EEEEEE\"> \n        <input type=\"checkbox\" name=\"owner4\" value=\"4\" onclick=\"calc_chmod()\">\n        </td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#ffffff\">\n        <input type=\"checkbox\" name=\"group4\" value=\"4\" onclick=\"calc_chmod()\">\n        </td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#EEEEEE\"> \n        <input type=\"checkbox\" name=\"other4\" value=\"4\" onclick=\"calc_chmod()\">\n        </td>\n    </tr>\n    <tr bgcolor=\"#dddddd\"> \n        <td width=\"60\" align=\"left\" nowrap=\"\" bgcolor=\"#FFFFFF\">write</td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#EEEEEE\"> \n        <input type=\"checkbox\" name=\"owner2\" value=\"2\" onclick=\"calc_chmod()\">\n        </td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#ffffff\">\n        <input type=\"checkbox\" name=\"group2\" value=\"2\" onclick=\"calc_chmod()\">\n        </td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#EEEEEE\"> \n        <input type=\"checkbox\" name=\"other2\" value=\"2\" onclick=\"calc_chmod()\">\n        </td>\n    </tr>\n    <tr bgcolor=\"#dddddd\"> \n        <td width=\"60\" align=\"left\" nowrap=\"\" bgcolor=\"#FFFFFF\">execute</td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#EEEEEE\"> \n        <input type=\"checkbox\" name=\"owner1\" value=\"1\" onclick=\"calc_chmod()\">\n        </td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#ffffff\">\n        <input type=\"checkbox\" name=\"group1\" value=\"1\" onclick=\"calc_chmod()\">\n        </td>\n        <td width=\"55\" align=\"center\" bgcolor=\"#EEEEEE\"> \n        <input type=\"checkbox\" name=\"other1\" value=\"1\" onclick=\"calc_chmod()\">\n        </td>\n    </tr>\n    </tbody>\n</table>\n</form>\n\n<script>\nfunction octalchange() \n{\n\tvar val = document.chmod.t_total.value;\n\tvar ownerbin = parseInt(val.charAt(0)).toString(2);\n\twhile (ownerbin.length<3) { ownerbin=\"0\"+ownerbin; };\n\tvar groupbin = parseInt(val.charAt(1)).toString(2);\n\twhile (groupbin.length<3) { groupbin=\"0\"+groupbin; };\n\tvar otherbin = parseInt(val.charAt(2)).toString(2);\n\twhile (otherbin.length<3) { otherbin=\"0\"+otherbin; };\n\tdocument.chmod.owner4.checked = parseInt(ownerbin.charAt(0)); \n\tdocument.chmod.owner2.checked = parseInt(ownerbin.charAt(1));\n\tdocument.chmod.owner1.checked = parseInt(ownerbin.charAt(2));\n\tdocument.chmod.group4.checked = parseInt(groupbin.charAt(0)); \n\tdocument.chmod.group2.checked = parseInt(groupbin.charAt(1));\n\tdocument.chmod.group1.checked = parseInt(groupbin.charAt(2));\n\tdocument.chmod.other4.checked = parseInt(otherbin.charAt(0)); \n\tdocument.chmod.other2.checked = parseInt(otherbin.charAt(1));\n\tdocument.chmod.other1.checked = parseInt(otherbin.charAt(2));\n\tcalc_chmod(1);\n};\n\nfunction calc_chmod(nototals)\n{\n  var users = new Array(\"owner\", \"group\", \"other\");\n  var totals = new Array(\"\",\"\",\"\");\n  var syms = new Array(\"\",\"\",\"\");\n\n\tfor (var i=0; i<users.length; i++)\n\t{\n\t  var user=users[i];\n\t\tvar field4 = user + \"4\";\n\t\tvar field2 = user + \"2\";\n\t\tvar field1 = user + \"1\";\n\t\t//var total = \"t_\" + user;\n\t\tvar symbolic = \"sym_\" + user;\n\t\tvar number = 0;\n\t\tvar sym_string = \"\";\n\t\n\t\tif (document.chmod[field4].checked == true) { number += 4; }\n\t\tif (document.chmod[field2].checked == true) { number += 2; }\n\t\tif (document.chmod[field1].checked == true) { number += 1; }\n\t\n\t\tif (document.chmod[field4].checked == true) {\n\t\t\tsym_string += \"r\";\n\t\t} else {\n\t\t\tsym_string += \"-\";\n\t\t}\n\t\tif (document.chmod[field2].checked == true) {\n\t\t\tsym_string += \"w\";\n\t\t} else {\n\t\t\tsym_string += \"-\";\n\t\t}\n\t\tif (document.chmod[field1].checked == true) {\n\t\t\tsym_string += \"x\";\n\t\t} else {\n\t\t\tsym_string += \"-\";\n\t\t}\n\t\n\t\t//if (number == 0) { number = \"\"; }\n\t  //document.chmod[total].value = \n\t\ttotals[i] = totals[i]+number;\n\t\tsyms[i] =  syms[i]+sym_string;\n\t\n  };\n\tif (!nototals) document.chmod.t_total.value = totals[0] + totals[1] + totals[2];\n\tdocument.chmod.sym_total.value = \"-\" + syms[0] + syms[1] + syms[2];\n}\n</script>\n\n--------------------------------------\n在UNIX系统家族里，文件或目录权限的控制分别以读取（Read)，写入(Write)，执行(Execute)3种一般权限来区分，另有3种特殊权限可供运用，再搭配拥有者与所属群组管理权限范围。您可以使用CHMOD指令去变更文件与目录的权限，设置方式采用文字或数字代号皆可。符号连接的权限无法变更，如果您对符号连接修改权限，其改变会作用在被连接的原始文件。权限范围的表示法如下：\n- u：User，即文件或目录的拥有者。\n- g：Group，即文件或目录的所属群组。\n- o：Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围。\n- a：All，即全部的用户，包含拥有者，所属群组以及其他用户。\n- 有关权限代号的部分，列表如下：\n- r：读取权限，数字代号为“40”\n- w：写入权限，数字代号为“2”\n- x：执行或切换权限，数字代号为“10”\n- -：不具任何权限，数字代号为“0”\n\n--------------------------------------\n转自：http://mistupid.com/internet/chmod.htm","tags":["在线工具"]},{"title":"推荐我的结巴分词http服务","url":"/posts/1540123748/","content":"[结巴分词](https://github.com/fxsjy/jieba)是一个非常好用的分词组件。但是只支持 python 语言。其他语言想要使用的话，只能使用第三方开发的版本。由于第三方的版本不是没有实现全部功能，就是文档不全，不然就是版本落后，非要使用的话，其实不是特别有安全感。\n\n鉴于结巴分词的接口非常简单，常用的函数只有4个，于是我用 Flask 实现了一个分词的 http 服务，地址在 [jiebahttp](https://github.com/questionlin/jiebahttp)。提供下面4个接口：\n```\n/cut?sentence=&cut_all=&HMM=\n/cut_for_search?sentence=&HMM=\n/posseg_cut?sentence=&HMM=\n/tokenize?sentence=&mode=&HMM\n```\n分别对应结巴的 cut, cut_for_search, posseg.cut, tokenize 4 个函数。同时支持 GET 和 POST 请求。有了 jiebahttp，其他语言就不用引入不放心的第三方库，也能方便的使用了。\n\n题外话，Elastic Stack 和 MongoDB 的成功早就告诉我们，一个开源库想要真正好用，不能依赖第三方来实现跨语言版本，而是要自己实现远程调用服务。","tags":["安利"]},{"title":"SQL用join还是分多次查询","url":"/posts/1539158031/","content":"这是一个老生常谈的问题了，大家都知道 join 表太多不好，阿里的规范里提到不可以 join 超过3个表。这篇文章通过例子探讨下3个表以内应该用 join 还是多次查询。先说结论，推荐使用 join 语句。\n\n首先打开 mysql 的计时功能\n```sql\nmysql> set profiling = 1;\nmysql> show variables like \"%pro%\";\n+------------------------------------------+-------+\n| Variable_name                            | Value |\n+------------------------------------------+-------+\n| check_proxy_users                        | OFF   |\n| have_profiling                           | YES   |\n| mysql_native_password_proxy_users        | OFF   |\n| performance_schema_max_program_instances | -1    |\n| profiling                                | ON    |\n| profiling_history_size                   | 15    |\n| protocol_version                         | 10    |\n| proxy_user                               |       |\n| sha256_password_proxy_users              | OFF   |\n| slave_compressed_protocol                | OFF   |\n| stored_program_cache                     | 256   |\n+------------------------------------------+-------+\n```\n确保 profiling 值为 ON\n\n现在查2000条数据，获得合并查询的时间\n```sql\nmysql> select * from report_order left join order_form on report_order.order_id = order_form.order_id limit 2000;\n```\n\n然后分开查询\n```sql\nmysql> select * from report_order limit 2000;\nmysql> select * from order_form where order_id in (123,123...);\n```\n\n然后查看时间\n```sql\nmysql> show profiles;\n+----------+------------+-------------------------------------------------------------------------------------------------------------------+\n| Query_ID | Duration   | Query                                                                                                             |\n+----------+------------+-------------------------------------------------------------------------------------------------------------------+\n|        7 | 0.05155450 | select * from report_order left join order_form on report_order.order_id = order_form.order_id limit 2000         |\n|        8 | 0.01129025 | select * from report_order limit 2000                                                                             |\n|        9 | 0.08883325 | select * from order_form where order_id in (123,234,345....)                                                      |\n|       10 | 0.00051300 | select * from order_form where order_id = '123123'                                                                |\n+----------+------------+-------------------------------------------------------------------------------------------------------------------+\n```\n\n可以看到，使用 join 的语句7耗时小于多次查询的语句8+9之和，因此在 join 表不多的情况下推荐使用 join。\n\n另外，对于应该使用 in 还是多次查询的问题，可以看到使用 in 的语句9耗时远远小于不使用的语句10*2000，因此推荐使用 in。","tags":["mysql"]},{"title":"http2与服务端配置","url":"/posts/1538191275/","content":"# http2 与 http1 的主要区别\n在于以下几点：\n- http2 使用一小块一小块的二进制帧传输\n- http2 文件可以设置优先级\n- http2 header 部分会被压缩\n- http2 服务端可以主动推送文件\n\n# 服务端配置\n## nginx 配置\nhttp2 要求服务器支持 https，在之前的文章[《HTTPS服务器配置》](/posts/1528164470)中已经介绍了怎么配置 https，下面给一个比较常用的 nginx http2 配置\n```nginx\n# http 跳转到 https\nserver {\n    listen         80;\n    listen    [::]:80;\n    server_name    example.com;\n    return         301 https://$server_name$request_uri;\n}\n\nserver {\n    # 在这里加上 http2 就可以开启 http2 支持\n    listen 443 ssl http2 default_server;\n    listen [::]:443 ssl http2 default_server;\n\n    server_name example.com;\n\n    ssl_certificate /etc/nginx/ssl/example.com.crt;\n    ssl_certificate_key /etc/nginx/ssl/example.com.key;\n    ssl_session_timeout  5m;\n\n    ssl_ciphers HIGH:!aNULL:!MD5;\n    ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2;\n    ssl_prefer_server_ciphers   on;\n\n    location / {\n        try_files $uri $uri/ =404;\n\n        root /var/www/html;\n        index index.html index.htm index.nginx-debian.html;\n\n        # 这里是服务端推送文件配置，如果没有文件需要推送，可以不加\n        http2_push /style.css;\n        http2_push /example.png;\n    }\n}\n```\n\n## PHP 服务端推送\n推送文件是要经常改动的，但我们又不希望经常改动 nginx 配置文件，这时候可以通过后端程序实现。做法是在 http \b头部添加 link 字段：\n> Link: </styles.css>; rel=preload; as=style\n> Link: </example.png>; rel=preload; as=image\n\n对应的 PHP 代码是：\n```php\n<?php\nheader(\"Link: <{$uri}>; rel=preload; as=image\",false);\n```\n\n相应 nginx 配置添加\n```nginx\nserver {\n    listen 443 ssl http2;\n    # ...\n    location = / {\n        http2_push_preload on;\n        # nginx 接 swoole 时需要加这行转发，接 php-fpm 时不需要\n        proxy_pass http://upstream;\n    }\n}\n```\n\n\n\n各种语言可以参考 [Go](https://ops.tips/blog/nginx-http2-server-push/), [Node](https://blog.risingstack.com/node-js-http-2-push/), [PHP](https://blog.cloudflare.com/using-http-2-server-push-with-php/) 的实现示范。\n\n----------------------\n参考资料：  \nnginx容器教程：http://www.ruanyifeng.com/blog/2018/02/nginx-docker.html  \nHow To Set Up Nginx with HTTP/2 Support on Ubuntu 16.04：https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-with-http-2-support-on-ubuntu-16-04  \nUsing HTTP/2 Server Push with PHP：https://blog.cloudflare.com/using-http-2-server-push-with-php/  \nHTTP/2 服务器推送（Server Push）教程：http://www.ruanyifeng.com/blog/2018/03/http2_server_push.html","tags":["http"]},{"title":"用PHP做爬虫的正确姿势","url":"/posts/1538110935/","content":"之前写过一篇[《用python做爬虫的正确姿势》](/posts/1529320519)。但我用 python 还不是那么顺手，这篇文章介绍下 php 爬虫的最佳实践。\n\n# 抓取\n一个爬虫程序至少需要抓取和解析两个部分，抓取部分我使用的是 [guzzle](https://github.com/guzzle/guzzle)。特点也是封装了会话（session），自动更新 cookies。\n\n```sh\ncomposer require guzzlehttp/guzzle\n```\n\n爬虫基本上都是网络请求，传统的阻塞方案非常浪费时间和计算能力，高级玩家可以使用这个基于 swoole 的异步抓取库[saber](https://github.com/swlib/saber)\n\n```sh\ncomposer require swlib/saber\n```\n\n# 解析\n解析我使用的是 [dom-crawler](https://github.com/symfony/dom-crawler)。语法类似 jQuery，上手比较快。在浏览器 console 里复制元素的 css 选择器或者 xpath 路径，粘贴到代码里即可。这里要注意浏览器会给选择器添加元素，例如 tbody，复制出来是 table > tbody > tr。但其实 html 里没有 tbody 这个元素。手动去掉就好了。\n\n```sh\ncomposer require symfony/dom-crawler\n```\n\ndom-crawler 来自 php 宝库 symfony，底层依赖他们的另一个库 [css-selector](https://github.com/symfony/css-selector)，可以将 css 选择器转换成 xpath 路径。如果你只需要找到元素，那么把 xpath 传给 [DOMXPath](https://secure.php.net/manual/en/class.domxpath.php) 或 [SimpleXMLElement](https://secure.php.net/manual/en/class.simplexmlelement.php) 这两个扩展可以更快。\n\n以下是不能使用的 css 选择器：\n- 链接状态: :link, :visited, :target\n- 用户行为: :hover, :focus, :active\n- UI 状态: :invalid, :indeterminate (但是， :enabled, :disabled, :checked 和 :unchecked 是可用的)\n- 伪元素: (:before, :after, :first-line, :first-letter)\n- 带星号的: \\*:first-of-type, \\*:last-of-type, \\*:nth-of-type, \\*:nth-last-of-type, \\*:only-of-type. (带元素名是可以的 (例如 li:first-of-type) 但带 \\* 的不行.\n\n# 保存\n再加一个封装好的数据库接口[Medoo](https://medoo.in/)，支持多种数据库，小巧方便。\n```sh\ncomposer require catfan/medoo\n```","tags":["php","最佳实践"]},{"title":"git子模块","url":"/posts/1537840874/","content":"大多数现在语言都有自己的包管理器，比如 php 的 composer，和 nodejs 的 npm。但是如果语言没有包管理器，或者想要的库没有打包，又不想手动更新，该怎么办呢？答案是 git 子模块。下面来一步一步建一个子模块。\n\n# 添加子模块\n```sh\n# 首先建一个仓库\n$ mkdir ljj_test\n$ cd ljj_test\n$ git init\n\n# 添加一个子模块\n$ git submodule add https://github.com/questionlin/php-view.git\nCloning into '/Users/simonlin/Documents/workshop/ljj_test/php-view'...\nremote: Enumerating objects: 46, done.\nremote: Total 46 (delta 0), reused 0 (delta 0), pack-reused 46\nUnpacking objects: 100% (46/46), done.\n\n# 查看一下\n$ git status\nOn branch master\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached <file>...\" to unstage)\n\n\tnew file:   .gitmodules\n\tnew file:   php-view\n```\n这时目录下会多出我们的子模块 php-view 和一个 .gitmodules 文件，这个文件里保存了子模块的映射关系。**这个操作在子目录下也可行。**\n\n# 使用子模块\n## 下载子模块\n```sh\n# 进入到 git 仓库目录\n$ cd ljj_test\n$ git submodule init\n# 下载文件\n$ git submodule update\n\n# 或者也可以用命令\n$ git clone --recursive https://github.com/chaconinc/MainProject\n```\n\n## 切换分支\n```sh\n$ git config -f .gitmodules submodule.php-view.branch (branch name)\n```\n\n## 更新\n```sh\n$ git submodule update --remote (module name)\n```\n这个命令会更新所有子模块，如果只想更新特定子模块，后面加上子模块名称\n\n## 删除子模块\n删除子模块的代码，然后删除 .gitmodules 里面的相关信息。\n\n----------------------------------\n参考资料：  \nhttps://git-scm.com/book/zh/v2/Git-工具-子模块","tags":["git"]},{"title":"手把手做一个php扩展","url":"/posts/1537782733/","content":"# 搭建环境\n首先确保你本地有 php 环境。然后下载 php 源码。\n\n```sh\n# 其实只需要里面的几个文件，所以下载 zip 包也行。\n$ git clone https://github.com/php/php-src.git\n$ cd php-src/ext\n# 用模版新建一个项目，名为 rjson\n$ ./ext_skel.php --ext rjson\n$ cd rjson\n$ phpize\n$ ./configure --with-php-config=/usr/local/bin/php-config\n$ make\n$ make test\n$ make install\n```\n\n现在 rjson.so 已经在扩展目录下了，需要在 php.ini 最底部加上\n\n```\nextension=rjson.so\n```\n\n看看扩展加载了没有\n\n```sh\n$ php -m | grep rjson\nrjson\n```\n\n新建一个文件 a.php\n```php\n<?php\necho rjson_test2('ljj');\n```\n执行看看\n```sh\n$ php a.php\nHello ljj\n```\n我们看到模版自带的测试函数已经可以执行了\n\n# 开始编写\n打开文件 rjson.c，可以找到 rjson_test1 和 rjson_test2 的定义。我们照着写一个 rjson_test3\n```c\n// 在下面这个数组里增加一行，第二个参数是函数参数的定义，这里省略\nstatic const zend_function_entry rjson_functions[] = {\n    PHP_FE(rjson_test3,     NULL)\n}\n\n// 最外层增加rjson_test3，可以写在 rjson_test2 后面\nPHP_FUNCTION(rjson_test3)\n{\n\tzend_string *retval;\n\tretval = strpprintf(0, \"I'm %s\", \"ljj\");\n\tRETURN_STR(retval);\n}\n```\n然后再 make install\n\n修改 a.php\n```php\necho rjson_test3();\n```\n执行\n```\n$ php a.php\nI'm ljj\n```\n到此，一个没有参数的函数就完成了。写 php 扩展的时候要用到很多 php 自己定义的 c 函数或者宏指令。比如 RETURN_STR() 不能返回 char*，只能返回 zend_string*。这些地方参考《PHP7内核剖析》。\n\n-------------------------------\n参考资料：  \nmac 系统下开发一个PHP扩展：https://blog.csdn.net/imbibi/article/details/79354464  \n用C/C++扩展你的PHP：http://www.laruence.com/2009/04/28/719.html  \n《PHP7内核剖析》","tags":["php"]},{"title":"机器学习获得的两种结果及其用法","url":"/posts/1537430575/","content":"# 第一种结果——逻辑\n先来回顾一下[上一篇文章](/posts/1537256287)，文章中我们获得了三个特征：\n1. 用户特征\n2. 广告特征\n3. 用户和广告的关系表\n\n我们使用CountVectorizer，OneHotEncoder，LabelEncoder，将所有特征压成一个\b list，然后使用 lightGBM 模型来训练\n```python\nimport lightgbm as lgb\nclf = lgb.LGBMClassifier(\n    boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n    max_depth=-1, n_estimators=1500, objective='binary',\n    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n    learning_rate=0.05, min_child_weight=50, random_state=2018, n_jobs=-1\n)\nclf.fit(train_x, train_y, eval_set=[(train_x, train_y)], eval_metric='auc',early_stopping_rounds=100)\n\nlabel = clf.predict(test_x)\n```\n最后得到的 label 是一个包含-1\b或1的 list。在生产环境中我们会不断的扫描新用户和新广告的特征，提取后用这个模型预测，把结果中为1的广告(aid)保存下来，最后投放给对应的用户(uid)。这是机器学习中一般的结果。\n\n# 第二种结果——线性\n在参考资料 elasticsearch-spark-recommender 中，作者介绍了如何用 elasticsearch 和 spark 来做协同过滤推荐系统。\b例子有两个特征：\n1. 电影特征（年份、类型）\n2. 用户对电影的打分\n\n例子中用 spark 提供的最小二乘机来训练模型，然后把得到的特征数组合并成字符串保存到 elasticsearch 中（文章里介绍了把spark 读写 es 的插件）\n\n```python\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql.functions import col\n# 训练\nals = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", regParam=0.01, rank=20, seed=12)\nmodel = als.fit(ratings_from_es)\n```\n\n每个电影的 document 中会多一行\n```\nvector: '1.0348|2.329487|8.3456435|5.293874'\n```\n当用户打开一个电影的网页，系统得到这部电影的特征 vector，然后输入 elasticsearch 进行搜索，es 会以'|'分隔字符串，然后无序匹配，得到匹配数字（其实是字符串）最多的电影返回给用户。这样一个协同过滤推荐系统就完成了。\n\n## 控制结果精度，得到邻近推荐\n上面的例子，结果是很多浮点数的组合，但是一些算法得出的结果是一个浮点数。假设你根据用户的特征，得到的结果是0.123456789，而你需要给用户推荐相似的结果，那么应该减少结果的位数，比如取0.12345，然后匹配所有前6为相同的结果。取多少位应该根据具体数据量来。比如精确到6位得到的推荐结果挺多，但精确到7位就非常少了，那么取6位就比较合适。\n\n----------------------------------\n参考资料：  \nMachine-Learning：https://github.com/Jack-Cherish/Machine-Learning  \nelasticsearch-spark-recommender：https://github.com/IBM/elasticsearch-spark-recommender","tags":["机器学习"]},{"title":"MySQL的in条件与锁表","url":"/posts/1537425757/","content":"MySQL 在 select 的时候，如果 where 里面有 in 条件的话，系统会判断范围会不会太大，如果太大的话，则会跳过索引，直接查表。而影响这个范围的参数，就是 eq_range_index_dive_limit。\n\n这本来没什么，预估到，或者在生产环境遇到慢查询的时候，再优化这个参数和 sql 即可。**可是，innodb 的锁是加在索引上的。当 update 的时候，如果系统也跳过索引，就会把锁加在主键上，造成锁表。**下面是一个例子。\n\n```mysql\nmysql> select * from t;\n+----+------+------+\n| a  | b    | c    |\n+----+------+------+\n|  0 |    0 |    0 |\n|  1 |    1 |    1 |\n|  3 |    3 |    1 |\n|  5 |    5 |    1 |\n|  7 |    7 |    1 |\n|  9 |    9 |    0 |\n| 10 |   10 |    0 |\n+----+------+------+\n\nmysql> explain select c from t where b in (3,5);\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                 |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+\n|  1 | SIMPLE      | t     | NULL       | range | b             | b    | 5       | NULL |    2 |   100.00 | Using index condition |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+\n\nmysql> explain update t set c=1 where b in(3,5);\n+----+-------------+-------+------------+-------+---------------+------+---------+-------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+---------------+------+---------+-------+------+----------+-------------+\n|  1 | UPDATE      | t     | NULL       | range | b             | b    | 5       | const |    2 |   100.00 | Using where |\n+----+-------------+-------+------------+-------+---------------+------+---------+-------+------+----------+-------------+\n```\n当 b 的范围是 (3,5) 的时候，select 和 update 都使用了b 这个索引。\n\n```mysql\nmysql> explain select c from t where b in (3,5,7);\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | t     | NULL       | ALL  | b             | NULL | NULL    | NULL |    7 |    42.86 | Using where |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+\n\nmysql> explain update t set c=1 where b in(3,5,7);\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\n|  1 | UPDATE      | t     | NULL       | index | b             | PRIMARY | 4       | NULL |    7 |   100.00 | Using where |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+\n```\n当 b 的范围是 (3,5,7) 的时候，select 没有使用索引，直接查表。update 使用了主键。\n\n如果这里\n```sql\nupdate t set c=1 where b in (3,5,7);\n```\n是一个事务，同时开另一个事务\n```sql\nupdate t set c=1 where a=0;\n```\n这时第一个 sql 会锁表，第二个 sql 就会进入等待。注意这里还不是 gap lock 的情况。\n\n\n--------------------------------\n参考：  \n简述 mysql 的 eq_range_index_dive_limit 参数作用：https://blog.csdn.net/java_zone/article/details/53383876","tags":["mysql"]},{"title":"特征工程初探","url":"/posts/1537256287/","content":"# 数据原型\n广告特征 adFeature.csv\n```python\n    aid  advertiserId  campaignId  creativeId  creativeSize  adCategoryId  \\\n0   177          8203       76104     1500666            59           282   \n1  2050         19441      178687      245165            53             1   \n2  1716          5552      158101     1080850            35            27   \n3   336           370        4833      119845            22            67   \n4   671         45705      352827      660519            42            67   \n\n   productId  productType  \n0          0            6  \n1          0            6  \n2        113            9  \n3        113            9  \n4          0            4\n```\n\n用户特征 user_feature_sample.csv\n```python\n   Unnamed: 0    LBS  age appIdAction appIdInstall  carrier  \\\n0           0  950.0    4         NaN          NaN        1   \n1           1  803.0    2         NaN          NaN        1   \n2           2  927.0    1         NaN          NaN        3   \n3           3  486.0    4         NaN          NaN        3   \n4           4  112.0    5         NaN          NaN        3   \n\n   consumptionAbility       ct  education  gender    ...     \\\n0                   2      3 1          7       2    ...      \n1                   1      3 1          2       1    ...      \n2                   1      3 1          5       1    ...      \n3                   1      1 3          7       1    ...      \n4                   2  3 1 4 2          6       1    ...      \n\n                                           interest5  \\\n0  52 100 72 131 116 11 71 12 8 113 28 73 6 132 9...   \n1                                                NaN   \n2  77 72 80 116 101 13 1 109 8 50 6 42 76 9 46 36...   \n3  100 80 92 37 116 13 47 4 71 8 50 28 98 115 6 4...   \n4        131 116 13 8 6 132 42 9 59 18 58 64 129 103   \n\n                                  kw1                             kw2  kw3  \\\n0  664359 276966 734911 103617 562294  11395 79112 115065 77033 36176  NaN   \n1  338851 361151 542834 496283 229952     80263 39618 53539 180 38163  NaN   \n2  746140 695808 126355 771775 411511  105115 71378 41409 74061 44005  NaN   \n3   283399 402245 734509 654027 32061  74010 32918 67882 116802 20957  NaN   \n4  562294 157603 589706 657719 495672   62764 97803 89066 55545 74061  NaN   \n\n  marriageStatus   os                    topic1                    topic2  \\\n0             11    2   9826 105 8525 5488 7281  9708 5553 6745 7477 7150   \n1           5 13    1  4391 9140 5669 1348 4388  9401 7724 1380 8890 7153   \n2          13 10    1  1502 5488 9826 2187 8088  5005 9154 2756 5612 4209   \n3             11  1 2  1619 7342 3064 9213 8525   810 2438 5659 1844 9262   \n4             11    1    477 9826 5808 644 2747  5483 2199 5424 1511 7751   \n\n  topic3       uid  \n0    NaN  26325489  \n1    NaN   1184123  \n2    NaN  76072711  \n3    NaN  63071413  \n4    NaN  81294159  \n```\n用户特征里出现了空值 NaN，以及用空格分开的一对多的值，在下一段介绍怎么处理\n\n用户-广告关系 train.csv\n```python\n    aid       uid  label\n0   699  78508957     -1\n1  1991   3637295     -1\n2  1119  19229018     -1\n3  2013  79277120     -1\n4   692  41528441     -1\n```\n\n# 特征提取\n代码参考的是参考资料里的 baseline 的代码，稍做改动\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom scipy import sparse\n\nuser_feature.fillna('-1')\ndata = pd.merge(train, ad_feature, on='aid', how='left')\ndata = pd.merge(data, user_feature, on='uid', how='left')\ndata.dropna()\n\n# 只有数字的数据适合用 one hot\none_hot_feature=['LBS','age','carrier','consumptionAbility','education','gender','house','os','ct','marriageStatus','advertiserId','campaignId', 'creativeId','adCategoryId', 'productId', 'productType']\n# 这些是关系型的数据，是用空格分开的数字，可以用词向量来处理\nvector_feature=['appIdAction','appIdInstall','interest1','interest2','interest3','interest4','interest5','kw1','kw2','kw3','topic1','topic2','topic3']\n\nfor f in one_hot_feature:\n    data[f] = LabelEncoder().fit_transform(data[f])\n\ntrain_x=train[['creativeSize']]\ntest_x=train[['creativeSize']]\nfor f in one_hot_feature:\n    enc.fit(data[f].values.reshape(-1,1))\n    train_a = enc.transform(train[f].values.reshape(-1,1))\n    train_x = sparse.hstack((train_x, train_a))\n\ncv = CountVectorizer()\nfor f in vector_feature:\n    cv.fit(data[f])\n    train_a=cv.trainsform(data[f])\n    train_x=sparse.hstack((train_x, train_a))\n```\n## 数字的特征提取\n对于纯数字的特征，要先 LabelEncoder().fit_transform() 后再 OneHotEncoder().fit_transform()。\n\nLanbelEncoder 会给值重新赋值，这样可以忽略值的大小。例如\n```python\nIn [3]: LabelEncoder().fit_transform([111,0.2,3000,42,25])\nOut[3]: array([3, 0, 4, 2, 1])\n```\n\n## 关系的特征提取\n用户特征分为三层\n1. 第一层是广告和用户的信息\n2. 第二层是广告和用户的关系，这里用pd.merge 合并成一个二维数组\n3. 第三层是用户和其他信息的关系，是字符串格式，内容是用空格隔开的数字，被当成单词后会按词向量处理，即忽略顺序。\n\n第三层处理完后用 sparse.hstack 压成一个二维数组，就成了最终训练用的特征。\n\n## 特殊的关系特征\n用户特征里面有一类\n```python\n['os','ct']\n```\n这类值是用空格隔开的数字，但是数字只有1位。例子里用 LabelEncoder，会被当成整个字符串，显然不合适。用 CountVectorizer 则会报\n```python\nValueError: empty vocabulary; perhaps the documents only contain stop words\n```\n我的做法是去掉空格（不去也一样）后用 CountVectorizer(analyzer='char')\n\n## 关系的数量\n关系特征里面还有一项是数量，比如 interest1，有些人只有一个，有些人有很多，更高分的选手把这项也计算出来作为特征。\n\n----------------------------------\n参考资料：  \n2018腾讯广告算法大赛baseline：https://github.com/YouChouNoBB/2018-tencent-ad-competition-baseline","tags":["机器学习"]},{"title":"sql的引号与索引","url":"/posts/1536648139/","content":"**先说结论，sql 的 where 值部分，都要加上引号。**即 where a=x 改成 where a='x'。\n\n当列类型是数字时，不管值加不加引号，都会走索引。但如果列类型是字符串时，如果不加引号，就不会走索引。字符串不加引号的情况一般不会出现，以下情况会出现：某一列一开始打算用来存放字符串，但实际上存放的都是数字，久而久之开发人员以为此列就是用来存放数字，便不加引号。","tags":["mysql"]},{"title":"豆瓣API","url":"/posts/1535854293/","content":"# 图书\n## 搜索图书\nGET  https://api.douban.com/v2/book/search\n\n参数 | 意义 | 备注\n-|-|-\nq | 查询关键字 | q和tag必传其一\ntag | 查询的tag | q和tag必传其一\nstart | 取结果的offset | 默认为0\ncount | 取结果的条数 | 默认为20，最大为100\n\n返回：返回status=200\n\n```json\n{\n      \"start\": 0,\n      \"count\": 10,\n      \"total\": 30,\n      \"books\" : [Book, ]\n    }\n注：对于登录用户，若搜索结果图书在当前用户的图书收藏中，会在对应搜索结果信息中附加当前用户对此书的收藏信息，改部分的 Book 数据结构如下：\n\n{\n    … (图书信息的其他部分)\n    \"current_user_collection\": {\n        \"status\":\"read\",\n        \"rating\": {\n            \"max\":5,\n            \"value\":\"5\",\n            \"min\":0\n        },\n        \"updated\":\"2012-11-2012:08:04\",\n        \"user_id\":\"33388491\",\n        \"book_id\":\"6548683\",\n        \"id\":605519800\n    }\n}\n```\n## 根据 id 获取图书信息\nGET  https://api.douban.com/v2/book/:id\n\n返回图书信息，返回status=200\n\n对于授权用户，返回数据中会带有该用户对该图书的收藏信息：\n```json\n{\n    … (图书信息的其他部分)\n    \"current_user_collection\": {\n        \"status\":\"read\",\n        \"rating\": {\n            \"max\":5,\n            \"value\":\"5\",\n            \"min\":0\n        },\n        \"updated\":\"2012-11-2012:08:04\",\n        \"user_id\":\"33388491\",\n        \"book_id\":\"6548683\",\n        \"id\":605519800\n    }\n}\n```\n\n## 通过 isbn 获取图书信息\nGET  https://api.douban.com/v2/book/:isbn\n\n# 电影\n## 搜索电影\nGET https://api.douban.com/v2/movie/search?q=张艺谋\n\n参数 | 描述 | 备注\n-|-|-\nq | 关键词 | q和tag必传其一\ntag | tag | q和tag必传其一\nstart | start | 0\ncount | count | -\n\n## 通过 id 获取电影\nGET https://api.douban.com/v2/movie/25849049\n\n## 通过 imdb 获取电影\nGET https://api.douban.com/v2/movie/imdb/:imdb\n\n# 音乐\n## 搜索音乐\nGET  https://api.douban.com/v2/music/search\n\n参数 | 描述 | 备注\n-|-|-\nq | 查询关键字 | q和tag必传其一\ntag | 查询的tag | q和tag必传其一\nstart | 取结果的offset | 默认为0\ncount | 取结果的条数 | -\n\n返回：返回status=200，\n```json\n{\n    \"start\": 0,\n    \"count\": 10,\n    \"total\": 30,\n    \"musics\" : [Music, ]\n}\n```\n\n## 获取音乐信息\nGET  https://api.douban.com/v2/music/:id\n\n返回音乐信息，返回status=200\n\n## 小组\n0. 请求的前缀是： https://api.douban.com/v2 \n1. 获取小组基本信息：/group/:id \n如：https://api.douban.com/v2/group/husttgeek/ \n2. 获取话题列表： /group/:id/topics \n如：https://api.douban.com/v2/group/husttgeek/topics \n3. 新发话题估计是POST到上面那个地址，没测试 \n4. 获取某话题评论列表： /group/topic/:id/comments \n如：https://api.douban.com/v2/group/topic/33488193/comments \n5. 发表评论估计是POST到上面那个地址，没测试 \n\n------------------------------\n参考：  \n一个可用的 apikey=0df993c66c0c636e29ecbb5344252a4a  \n豆瓣官方客户端：https://github.com/douban/douban-client","tags":["数据"]},{"title":"redis搭建集群","url":"/posts/1535610189/","content":"# 集群与主从的区别\n主从模式中，客户端可以从任何一个服务端读取，分散了读的压力，但是只能对特定的一个服务端做写操作。redis 提供了 sentinel 模式监控主服务的状态，如果主服务挂了，会选择一台从服务作为主服务。可是如果住服务是因为写压力过大，那么相同配置的从服务被选为主之后，毫无疑问也会因为压力太大而挂掉。而且 redis 所有数据都是保存在内存里，如果数据太多，一台服务器放满了，也不能用主从模式。这个时候可以用集群方案来解决。\n\nredis 集群方案里，系统由多个主从服务组成，每个服务端都可以读写，服务端会根据哈希算法，分配数据到特定的服务器上。系统内不再有单点压力。\n\n# 过一遍官方例子\n## 在官网下载源码后编译\n```sh\n$ gem install redis # 安装 ruby 依赖\n$ wget http://download.redis.io/releases/redis-4.0.11.tar.gz\n$ tar xzf redis-4.0.11.tar.gz\n$ cd redis-4.0.11\n$ make\n```\n这里确保 src/redis-server, src/redis-cli 两个生成成功。然后进入 utils/create-cluster，执行\n```sh\n$ ./create-cluster start #生成6个实例\n$ ./create-cluster create #将6个实例配置为集群\n```\n\n## 用客户端测试集群\n官方例子生成了6个实例，分别使用 30001-30006 6个端口。\n\n开一个客户端，连接第一个端口\n```sh\n$ redis-cli -c -p 30001\n127.0.0.1:30001> set ljj 1\nOK\n```\n开另一个客户端，连接第二个端口\n```sh\n$ redis-cli -c -p 30002\n127.0.0.1:30002> get ljj\n-> Redirected to slot [1799] located at 127.0.0.1:30001\n\"1\"\n127.0.0.1:30001> get ljj\n\"1\"\n127.0.0.1:30001> set ljj2 2\nOK\n```\n这里发现客户端已经被转到了30001这个端口。之后用客户端分别连接每个端口，执行 get 和 set 操作，发现 **在任何一个客户端都是可以执行set 和 get 操作的，系统会\b判断值应该被存储在哪个服务，然后转接过去**。\n\n## 最后清理现场\n```sh\n$ ./create-cluster stop #停止所有实例\n$ ./create-cluster clean #删除所有生成的文件\n```\n\n# 手动生成集群\n## 生成实例\n先来分析一下 create-cluster 的代码。当执行 start 的时候，实际上是执行了\n```sh\nredis-server --port $PORT --cluster-enabled yes --cluster-config-file nodes-${PORT}.conf --cluster-node-timeout 2000 --appendonly yes --appendfilename appendonly-${PORT}.aof --dbfilename dump-${PORT}.rdb --logfile ${PORT}.log --daemonize yes\n```\n$PORT 是30001-30006。如果目录下没有 nodes-${PORT}.conf 配置文件，redis 会自己生成一个，并写入信息。现在先手动生成实例 30001-30004。\n```sh\n$ ps aux | grep redis\nsimon            52453   0.1  0.1  4301948   2232   ??  Ss   11:21上午   0:00.08 ../../src/redis-server *:30001 [cluster]\nsimon            52474   0.1  0.1  4301948   2208   ??  Ss   11:21上午   0:00.02 ../../src/redis-server *:30004 [cluster]\nsimon            52472   0.1  0.1  4310140   2256   ??  Ss   11:21上午   0:00.03 ../../src/redis-server *:30003 [cluster]\nsimon            52470   0.1  0.1  4301948   2204   ??  Ss   11:21上午   0:00.04 ../../src/redis-server *:30002 [cluster]\nsimon            52476   0.0  0.0  4267752    876 s001  S+   11:22上午   0:00.00 grep redis\n```\n## 连接各节点\n只要连接并操作一个一个服务端即可\n```sh\n127.0.0.1:30001> CLUSTER MEET 127.0.0.1 30002\nOK\n127.0.0.1:30001> CLUSTER MEET 127.0.0.1 30003\nOK\n127.0.0.1:30001> CLUSTER MEET 127.0.0.1 30004\nOK\n```\n\n## 查看集群状态\n查看集群状态\n```sh\n127.0.0.1:30001> cluster info\ncluster_state:fail\ncluster_slots_assigned:0\ncluster_slots_ok:0\ncluster_slots_pfail:0\ncluster_slots_fail:0\ncluster_known_nodes:4\ncluster_size:0\ncluster_current_epoch:3\ncluster_my_epoch:1\ncluster_stats_messages_ping_sent:213\ncluster_stats_messages_pong_sent:213\ncluster_stats_messages_meet_sent:3\ncluster_stats_messages_sent:429\ncluster_stats_messages_ping_received:213\ncluster_stats_messages_pong_received:216\ncluster_stats_messages_received:429\n```\n\n查看集群内所有节点\n```sh\n127.0.0.1:30001> cluster nodes\n735e799f68bf21aa6af679a55f28f69740e2251a 127.0.0.1:30004@40004 master - 0 1535779344092 3 connected\n69a812b0dfc02dee94bd03a8e1ff453728409e5a 127.0.0.1:30001@40001 myself,master - 0 1535779343000 1 connected 0-8192\nb2897dbc560a9774018559d49eb277ae75bd685b 127.0.0.1:30003@40003 master - 0 1535779343790 0 connected 8193-16383\nac391224d51ccd316809f88e2d59b645213a1e66 127.0.0.1:30002@40002 master - 0 1535779343790 2 connected\n```\n\n## 分配哈希槽\nredis集群有16384个哈希槽，要把所有数据映射到16384槽，需要批量设置槽\n```sh\nredis-cli -p 30001 cluster addslots {0..8192}\nredis-cli -p 30003 cluster addslots {8193..16383}\n```\n\n## 做主从映射\n我的配置是 30001主->30002从，30003主->30004从\n```sh\n127.0.0.1:30002> CLUSTER REPLICATE 69a812b0dfc02dee94bd03a8e1ff453728409e5a\n127.0.0.1:30004> CLUSTER REPLICATE b2897dbc560a9774018559d49eb277ae75bd685b\n```\n\n## 总结\n到此 redis 集群已经搭建好了。现在执行 cluster info，cluster_state 已经是 ok 了。\n\n看得出还是挺麻烦的，推荐使用官方的脚本 redis-trib.rb。当执行 create-cluster create 的时候，是执行了\n```sh\n../../src/redis-trib.rb create --replicas 1 127.0.0.1:30001 127.0.0.1:3002 127.0.0.1:3003 127.0.0.1:3004 127.0.0.1:3005 127.0.0.1:3006\n```\n--replicas 1 表示每个主对应一个从。\n\n# 集群更改\n## 转移插槽（slot）\n```sh\nsrc/redis-trib.rb reshard 127.0.0.1:30001\nHow many slots do you want to move (from 1 to 16384)? 1000 #转移的插槽数\nWhat is the receiving node ID? b2897dbc560a9774018559d49eb277ae75bd685b #接收的节点\nPlease enter all the source node IDs. #从指定节点转移还是从其他所有节点转移\n  Type 'all' to use all the nodes as source nodes for the hash slots.\n  Type 'done' once you entered all the source nodes IDs.\nSource node #1:all\n```\n以上插槽就搬运好了。如果要把一个节点里的所有插槽转移到另一个节点，可以简单的执行这个命令\n```sh\n./redis-trib.rb reshard --from <node-id> --to <node-id> --slots <number of slots> --yes <host>:<port>\n```\n\n## 集群扩容\n首先启动两个新的服务 30005主，30006从。\n\n将30005加入集群\n```sh\nsrc/redis-trib.rb add-node 127.0.0.1:30005 127.0.0.1:30001 #引入主节点\nsrc/redis-trib.rb add-node --slave --master-id 03ccad2ba5dd1e062464bc7590400441fafb63f2 127.0.0.1:30006 127.0.0.1:30001 #引入从节点\n```\n其中 03ccad2ba5dd1e062464bc7590400441fafb63f2 是30005的 cluster node id。然后将其他节点的插槽转移到这个节点就好了。\n\n## 集群缩减\n将主节点的插槽全部转移到别的主节点，然后执行\n```sh\nsrc/redis-trib.rb del-node 127.0.0.1:30005 03ccad2ba5dd1e062464bc7590400441fafb63f2\n```\n其中 03ccad2ba5dd1e062464bc7590400441fafb63f2 是节点 cluster node id\n\n# 集群模式的缺陷\n1. 键的批量操作支持有限，比如mset, mget，如果多个键映射在不同的槽，就不支持了\n2. 键事务支持有限，当多个key分布在不同节点时无法使用事务，同一节点是支持事务\n3. 键是数据分区的最小粒度，不能将一个很大的键值对映射到不同的节点\n4. 不支持多数据库，只有0，select 0\n5. 复制结构只支持单层结构，不支持树型结构。  \n6. **集群不能少于3个主节点，否则主从切换会失败**\n\n----------------------------\n参考资料：  \n官方教程 https://redis.io/topics/cluster-tutorial  \nredis集群高可用 https://www.cnblogs.com/leeSmall/p/8414687.html","tags":["redis"]},{"title":"Elasticsearch搭建集群","url":"/posts/1535600327/","content":"# 配置文件\n## Elasticsearch 集群中的三种角色\n\n```\n1. 此时节点可以成为任何角色\nnode.master: true #可选为主节点\nnode.data: true #可存储数据\n2. 此时节点从不选举为主节点,只用来存储数据,可作为负载器\nnode.master: false\nnode.data: true\n3. 此时节点成为主节点,且不存储任何数据,并保有空闲资源,可作为协调器\nnode.master: true\nnode.data: false\n4. 此时节点既不称为主节点,又不成为数据节点,那么可将他作为搜索器,从节点中获取数据,生成搜索结果等\nnode.master: false\nnode.data: false\n```\n\n## 本地第一台配置\n我的两个服务都在本地，所以要用端口来区分\nelasticsearch.yml\n```\ncluster.name: es-ljj\nnode.name: node-1\nhttp.port: 9200 #搜索访问的端口\ntransport.tcp.port: 9300 #节点之间通信的端口\nnode.master: true\nnode.data: true\ndiscovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9301\"] #所有节点的地址\n```\n\n## 本地第二台配置\nelasticsearch.yml\n```\ncluster.name: es-ljj\nnode.name: node-2\nhttp.port: 9201 #搜索访问的端口\ntransport.tcp.port: 9301 #节点之间通信的端口\nnode.master: true\nnode.data: true\ndiscovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9301\"] #所有节点的地址\n```\n\n## 检测是否生效\n这里两个服务都配置了node.master: true，所以先启动的会被选为 master，而后进来的，data 目录下如果已经有其他数据，则会加入失败。\n\n这时我们对两个服务进行操作\n```\n$curl -X PUT '127.0.0.1:9200/users'\n$curl -X PUT '127.0.0.1:9201/pages'\n```\n然后查看是否已经生效\n```\n$curl -X GET '127.0.0.1:9200/_cat/indices?v'\n$curl -X GET '127.0.0.1:9201/_cat/indices?v'\n```\n两台返回的都是\n```\nhealth status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   users 5JUXi3KKRtyMRvWvLlwaqg   5   1          0            0      1.2kb           650b\ngreen  open   pages FyR1lz32QYyhJeC-U3_UgQ   5   1          0            0       520b           260b\n```\n表示集群已经可以使用了\n\n# 动态配置\n如果我们要在集群加入一台新服务，或者移除一个老服务，需要修改每个节点配置里的 discovery.zen.ping.unicast.hosts，然后重启每个节点。如果是希望临时修改配置配置，让新的配置马上生效，等到合适的时间再重启每个节点，可以参考 es 提供的[集群配置接口](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html)。\n\n# 集群健康\n集群健康可以通过 [head 插件](https://github.com/mobz/elasticsearch-head)来监控，也可以使用 es 提供的[集群状态接口](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-state.html)。\n\n---------------------------------------\n参考资料：  \nElasticsearch5.2.1集群搭建，动态加入节点，并添加监控诊断插件 https://blog.csdn.net/gamer_gyt/article/details/59077189  \n集群配置接口 https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html","tags":["elasticsearch"]},{"title":"服务器动态扩容与php-fpm配置","url":"/posts/1534671620/","content":"对于非 sass 类的应用的容量规划，参考底部《服务器容量规划》。简单的说就是估出总量，然后根据80%的压力落在20%时间的原则，估出QPS，然后给每台机器留30%计算能力，最后得出需要的总机器数。但是对于 sass 应用，商家即使告诉你什么时候会有大活动，他们也估不出会有多少点击量。这个时候就需要另一套配置方法。这套方法是建立在云服务上的，毕竟大部分公司不但不起7x24小时维护。\n\n首先要配置出尽量多的服务器，然后关闭这些服务器。对于很多云服务商来说，这些离线的主机是不收费的。\n\n然后需要一个报警功能，当现存的服务器压力达到预警值的时候或可以自动启动上面关着的服务器，或向运维发出告警，由运维来启动。一些云服务器有告警功能，没有的话只能由本地脚本来完成。因为对外部检测服务来说服务器还是可访问的，而对日志收集器来说，出现错误日志可能已经晚了。\n\n然后就是要评估出服务行业的压力普遍集中的时间，比如出行行业是上下班，周末则要往后延。\n\n下面给一个 php-fpm 配置压力部分的说明（也是一般服务唯一需要配置的部分），详细的说明看底部官方中文文档\n\n> pm  \n> 设置进程管理器如何管理子进程。可用值：static，ondemand，dynamic。必须设置。\n> \n> static - 子进程的数量是固定的（pm.max_children）。\n> \n> ondemand - 进程在有需求时才产生（当请求时才启动。与 dynamic 相反，在服务启动时 pm.start_servers 就启动了。\n> \n> dynamic - 子进程的数量在下面配置的基础上动态设置：pm.max_children，pm.start_servers，pm.min_spare_servers，pm.max_spare_servers。\n\n**对于 pm，如果服务器没有弹性扩容方案，也不用给其他程序预留容量的话，选择\"static\"这个最合适。而\"ondemand\"最不推荐，因为等到有请求再新建进程，请求会等待较长时间。**\n\n> pm.max_children  \n> pm 设置为 static 时表示创建的子进程的数量，pm 设置为 dynamic 时表示最大可创建的子进程的数量。必须设置。\n> \n> 该选项设置可以同时提供服务的请求数限制。类似 Apache 的 mpm_prefork 中 MaxClients 的设置和 普通PHP FastCGI中的 PHP_FCGI_CHILDREN 环境变量。\n> \n> pm.start_servers  \n> 设置启动时创建的子进程数目。仅在 pm 设置为 dynamic 时使用。默认值：min_spare_servers + (max_spare_servers - min_spare_servers) / 2。\n> \n> pm.min_spare_servers  \n> 设置空闲服务进程的最低数目。仅在 pm 设置为 dynamic 时使用。必须设置。\n> \n> pm.max_spare_servers  \n> 设置空闲服务进程的最大数目。仅在 pm 设置为 dynamic 时使用。必须设置。\n> \n> pm.max_request  \n> 设置每个子进程重生之前服务的请求数。对于可能存在内存泄漏的第三方模块来说是非常有用的。如果设置为 '0' 则一直接受请求，等同于 PHP_FCGI_MAX_REQUESTS 环境变量。默认值：0。\n\n**由于php是有内存垃圾回收机制的，所以这个值是可以设的比较大，不过具体还是要看项目。**\n\n> request_terminate_timeout  \n> 设置单个请求的超时中止时间。该选项可能会对 php.ini 设置中的 'max_execution_time' 因为某些特殊原因没有中止运行的脚本有用。设置为 '0' 表示 'Off'。可用单位：s（秒），m（分），h（小时）或者 d（天）。默认单位：s（秒）。默认值：0（关闭）。\n\n**默认不限时间是不合理的。如果一个进程花掉太长时间执行，即使程序没有出错，也会很快耗尽服务器资源。这里推荐的是 30s**\n\n---------------------------------\n参考资料：  \n服务器容量规划：https://ljj.pub/posts/1531898775/  \nphp-fpm配置说明：http://php.net/manual/zh/install.fpm.configuration.php","tags":["运维","php"]},{"title":"一种带权重的随机选择","url":"/posts/1532591893/","content":"之前有过这样的需求，抽奖活动，奖品按一定权重随机抽取，例如：\n\n| 奖品 | a | b | c | d | e |\n|-|-|-|-|-|-|\n| 权重 | 12 | 32 | 32 | 12 | 12 |\n\n之前的做法是把每个奖品按照权重，重复加进一个数据，即：\n```\n[a,a,a,a...b,b,b,b,b...c,c,c,c,c...d,d,d,d...e,e,e...]\n```\n里面有12个a,32个b以此类推。然后用 array_rand() 选出一个。\n\n这种方法首先会的到一个很大的数组，然后循环添加奖品也很费时。今天重新思考这个问题，可以用下面的方法：\n1. 将所有权重相加得到总和\n2. 以总和为最大值得到一个随机数\n3. 循环查找随机数在数组里的\b区间，进而得到结果\n\n```php\n<?php\n$gift = ['a'=>12,'b'=>32,'c'=>32,'d'=>12,'e'=>12];\n$sum = array_sum($gift);\n$rand = mt_rand(1,$sum);\n$i=0;\n$the_gift='';\nforeach($gift as $key=>$weight){\n    $i += $weight;\n    if($rand < $i){\n        $the_gift = $key;\n        break;\n    }\n}\nvar_dump($the_gift);\n```\n虽然这个算法里也有循环，但是通常礼物\b不会很多，计算量非常小。\n\n最后给一个用 map 实现的方法，缺点是要用权重作为key，所以每个权重不能相同。\b\bhttps://www.cnblogs.com/exmyth/p/7100749.html","tags":["算法"]},{"title":"RPC的基友——事务管理器","url":"/posts/1532519316/","content":"关于事务管理器，在之前的文章[《分布式事务之mysql两阶段提交》](/posts/1529896095/)有介绍。简单的来说，就是独立于业务逻辑，专门负责执行数据库事务的服务。事务管理器对于 RPC 之重要，可以说没有事务管理器，就没有分布式 RPC。\n\n# 为什么事务管理器重要\n首先我来梳理一下没有事务管理器的情况下，RPC 服务怎么调用数据库事务。分布式数据库的情况下需要一台事务管理器管理分布式事务中每台数据库事务的状态。\n\n如果只有一台数据库。每个 RPC 都有自己的连接，所以 RPC 之间无法共享事务。这时考虑以下两种情况：\n\n1. 每个 RPC 能访问所有表\n    - rpc-1 开启了一个事务，同时调用 rpc-2，rpc-2 开启了另一个事务。如果1和2的事务访问同一个表的同一行数据，就会造成死锁。这种情况虽然可以避免，但是排查有难度。\n2. 每个 RPC 只能访问自己的表\n    - 如果每个 RPC 只能访问自己的表，那但凡 RPC 间的调用，都会变成分布式事务。这样不但代码量会变得很大，而且效率太低。不推荐这样配置。\n\n因此，**只有一台数据库的情况下，我推荐每个 RPC 都能访问所有的数据表，通过测试来避免死锁。**只有这一种情况可以不用事务管理器，其他情况都需要。\n\n# 如何实现事务管理器\n如果只有一个数据库，可以自己实现一个事务管理器，rpc-1 先从事务管理器获得事务 id，被调 rpc-2 通过事务 id，获得 rpc-1 的数据库连接。这时的事务管理器就是一个数据库连接池。这里要注意单点问题。\n\n对于分布式的情况，可以用 XA 事务，但是效率不高。可以考虑 TCC 事务，参考[《分布式事务之TCC补偿型事务》](/posts/1530843273/)。\n","tags":["分布式"]},{"title":"大型服务器的架构","url":"/posts/1532314825/","content":"这里只按照我所知道的最大型架构来。\n\n|-|-|-|-|-|\n|-|-|-|-|-|\n|[DNS负载均衡](#DNS负载均衡) |\n|[负载分发](#负载分发) |\n|[网关 + web/API 服务器](#网关+web/API服务器)|\n|RPC服务器 | [服务注册](#服务注册)\n|[数据库](#数据库) | 缓存 | [消息队列](#消息队列) | 搜索引擎 | [第三方\b接口](#第三方接口)\n|[日志收集](#日志收集)|\n\n# 技术\n## DNS负载均衡\nDNS 负载均衡是把多个 A/CNAME 记录配置在 DNS 服务器上的一种均衡的办法。优点是不用另外配置服务器，缺点是规则生效慢，不宜多配。例如阿里巴巴华东节点就只配了4条记录。\n\n## 负载分发\n将请求分发到各台服务器的主力服务器。\b常见的负载分发服务器有 HAProxy, nginx, LVS。\n\n通过负载分发出去的请求，为了保留用户 SESSION，一种方法是对用户id hash/取模，同一个用户的请求一直导向同一台服务器。但这种方法经常造成服务器使用不均，极不推荐。推荐的做法是把 SESSION 放在缓存服务器上，请求携带 token 一路往下传。\n\n负载分发服务器虽然可以通过检测下游服务是否可用来动态更新分发规则，但本身有单点问题虽然可以用脚本和 keepalived \b灾后抢救，但仍不能保证完全高可用。不知道有什么更好的替代。\n\nlvs 是4层网络，nginx 是7层，所以 nginx 可以对应用层的数据做判断。\n\n## 网关+web/API服务器\nweb/API服务器是放业务逻辑代码的地方，可以在上层放一层网关，也可以把网关代码和应用代码放一起。由于 API 是对外的，尤其是有第三方使用的情况下，除了要检查数据正确性外，还要注意 API 请求本身。网关应该拦截过于频繁的请求。如果有携带 token，且 token 随时间变化的话，一样的 token 可只放行第一个。\n\n由于要经常改动，此层最合适的语言是 PHP 和 javascript(nodejs)。\n\n## 服务注册\nzookeeper 获得通知后要重新订阅才能再获得通知，所以不适合直接做注册中心。所以推荐 [Apollo](https://github.com/ctripcorp/apollo)\n\n## 数据库\n在 MySQL 正式支持集群以前，还是只能搭建主从服务器，然后用一定的算法生成 id。常见的 id 生成算法是数据库id+时间哈希，是情况还可以增加 RPC id、版本号等信息。集群会失去顺序，这个时候可以考虑同一个用户的数据只写入同一台服务器。下面贴一个蚂蚁金服的 id 生成策略：\n\n|位置|1-8|9|10|11-13|14-16|...|10-9|8-1|\n| - | - |-|-| -    | -   | - | -  | - |\n|示例|20180101|1|1|001|001|...|00|12345678|\n|说明| 8位日期 |数据版本|系统版本|系统标识码|业务标识码|自定义扩展位|用户分片位|sequence空间，可支持每天每个分表1亿笔业务，循环使用|\n\n对于超大型服务，MySQL 的主从复制速度不能满足的情况下，可以考虑 OceanBase / PhxSQL，\b他们用 paxos 算法实现了分布式情况下数据库的快速同步。\n\n## 消息队列\n队列服务器有两种用处：\n1. 把耗时多的服务放在队列里，由另一个服务异步运行\n2. 有些数据对顺序要求很高，放在队列里，把并行转为串行\n\n常见的队列服务有 kafka / RabbitMQ / RocketMQ，新版的 redis 也提供队列服务。\n\n## 第三方接口\n第三方接口由于在异地，经常会出现请求错误。这时如果时间允许的话可以睡眠若干秒后直接重试，否则放入消息队列。\n\n## 日志收集\nElastic Stack(ELK) 是现在市面上最方便的日志收集和查询的工具。日志收集除了能做产品分析外，还能给新服务上线做蓝绿测试。即先在一台权重比较低的服务器上线新版，一段时间后如果日志没有报错，再在其他服务器上新。报警服务也可以架设在日志收集服务之上。\n\n## 定时任务\n[xxl-job](https://github.com/xuxueli/xxl-job)\n\n# 后台\n## 服务器性能指标查看\n[grafana](https://github.com/grafana/grafana)\n\n## 接口文档管理\n[yapi](https://github.com/YMFE/yapi)","tags":["分布式","最佳实践"]},{"title":"redis数据结构备注","url":"/posts/1531967914/","content":"# Geo\nGeo 命令用来把经纬度转换成 [Geohash](https://ljj.pub/posts/1531668376/)。\n\n一般用途：\n- 获得地图上一个点附近 x米内的所有点\n\n# Hashes\n哈希表。以前会把数据序列化后作为字符串存储，现在可以直接存进 hash 里。缺点是只有一级，所以多级的情况还是要序列化。\n\n一般用途：\n- 数据库里的数据原封不动存进 hash\n\n# HyperLogLog\nHyperLogLog 的用途是输入大量的字符串，最后得到去重字符串的数量。和 Sets 的区别是速度飞快，而且空间小很多，可能只有千分之一。缺点是数据存入后会做不可逆运算，因此只能统计数量，不能再取出数据。\n\n一般用途：\n- 统计 UV\n\n# Lists\n列表。以前会用来作为消息队列，现在推荐使用 Streams。\n\n一般用途：\n- 有序的队列\n\n# Sets\n去重的无序列表。如果要维护一个去重的列表。缺点是无序。\n\n一般用途：\n- 分布式的情况下，维护一个去重表\n\n# Sorted Sets\n有序的去重列表。同样是去重的列表，可以给每个值加一个权重，得到一个顺序。\n\n一般用途：\n- 按照需要的顺序存储数据库的主键。作为数据库索引的补充。\n\n# Streams\n专门的消息队列，比 List 快很多，用来代替 Kafka, RabbitMQ 等。\n\n一般用途：\n- 消息队列\n\n# Strings\n最基本的字符串\n\n一般用途：\n- 加锁 SET key value EX 5 NX。SET 和 EX 一起操作，保证锁超时的原子性。\n- 存储序列化的数据，比如 json\n\n# Bitmap\n图是建立在 String 上的，提供直接对每一位的操作。图的操作直观上就是 offset 上的值是 0 还是 1\n\n一般用途：\n- 统计用户一年登录了哪些天 SETBIT $uid $day 1。$offset 是一年中的第几天\n- 查看用户是否在线 SETBIT KEY $uid 1。这里 $uid 只能是数字\n- 布隆过滤器。旧版可以找插件来实现\n\n# 隐藏结构：Radix\nRadix 是 redis 内部用来存储 key 的数据结构，类似 trie 字典树，但是经过压缩（字母合并）。因此可以直接拿 redis 的 key 做字典树来用。\n\n---------------------------\n参考资料：  \n[HyperLogLog wiki](https://en.wikipedia.org/wiki/HyperLogLog)  \n[steams](https://redis.io/topics/streams-intro)","tags":["redis"]},{"title":"PHP event 和 libevent 扩展的关系","url":"/posts/1531918053/","content":"PHP event 和 libevent 扩展都是对 libevent 的封装，前者有 stable 版本且一直在更新而后者只有 beta 版本。本来肯定要选 event 扩展，可是它的 pecl 页面上赫然写着依赖 libevent 扩展。陷入混乱的我给作者写了封邮件，**结论是：大胆选 event 扩展**。以下是邮件原文：\n\n> Hi,\n> \n> event extension is an alternative to libevent extension.\n> \n> You can see \"libevent\" package listed as a dependency on\n> https://pecl.php.net/package/event, but in reality \"libevent\"\n> extension is declared as **conflicting** package in package.xml:\n> \n>       <package>\n>         <name>libevent</name>\n>         <channel>pecl.php.net</channel>\n>         <min>0.0.2</min>\n>         <conflicts/>\n>         <providesextension>libevent</providesextension>\n>       </package>\n> \n> I can't recall why. But you definitely don't need libevent extension\n> in order to use \"event\".\n> \n> On Wed, 18 Jul 2018 11:28:21 +0800 (CST)\n> \"Simon Lin\" <boyquestion@163.com> wrote:\n> \n> Hi,\n> \n> I'm just confused that what is the relation between event package and\n> libevent package? The pecl page shows event package has stable\n> versions while libevent package does not. If event package depends on\n> libevent package, is event package still stable?\n> \n> \n> \n> \n> Sincerely,\n> Simon Lin\n> \n> -- \n> Ruslan Osmanov","tags":["php"]},{"title":"服务器容量规划","url":"/posts/1531898775/","content":"# 单机 QPS 评估\nQPS 是值每秒处理请求量。http 请求一般使用 apache bench 工具 ab 评估。参数说明：\n```\n格式：ab [options] [http://]hostname[:port]/path\n\n-n requests Number of requests to perform\n//本次测试发起的总请求数\n\n-c concurrency Number of multiple requests to make\n//一次产生的请求数（或并发数）\n\n-t timelimit Seconds to max. wait for responses\n//测试所进行的最大秒数，默认没有时间限制。\n\n-r Don't exit on socket receive errors.\n// 抛出异常继续执行测试任务 \n\n-p postfile File containing data to POST\n//包含了需要POST的数据的文件，文件格式如“p1=1&p2=2”.使用方法是 -p 111.txt\n\n-T content-type Content-type header for POSTing\n//POST数据所使用的Content-type头信息，如 -T “application/x-www-form-urlencoded” 。 （配合-p）\n\n-v verbosity How much troubleshooting info to print\n//设置显示信息的详细程度 – 4或更大值会显示头信息， 3或更大值可以显示响应代码(404, 200等), 2或更大值可以显示警告和其他信息。 -V 显示版本号并退出。\n\n-C attribute Add cookie, eg. -C “c1=1234,c2=2,c3=3” (repeatable)\n//-C cookie-name=value 对请求附加一个Cookie:行。 其典型形式是name=value的一个参数对。此参数可以重复，用逗号分割。\n提示：可以借助session实现原理传递 JSESSIONID参数， 实现保持会话的功能，如-C ” c1=1234,c2=2,c3=3, JSESSIONID=FF056CD16DA9D71CB131C1D56F0319F8″ 。\n\n-w Print out results in HTML tables\n//以HTML表的格式输出结果。默认时，它是白色背景的两列宽度的一张表。\n```\n\n返回：\n```sh\n$ab -n1000000 -c100 -k http://127.0.0.1:1234/\nThis is ApacheBench, Version 2.3 <$Revision: 1528965 $>\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\nLicensed to The Apache Software Foundation, http://www.apache.org/\n\nBenchmarking 127.0.0.1 (be patient)\nCompleted 100000 requests\nCompleted 200000 requests\nCompleted 300000 requests\nCompleted 400000 requests\nCompleted 500000 requests\nCompleted 600000 requests\nCompleted 700000 requests\nCompleted 800000 requests\nCompleted 900000 requests\nCompleted 1000000 requests\nFinished 1000000 requests\n\n\nServer Software:        workerman/3.1.4\nServer Hostname:        127.0.0.1\nServer Port:            1234\n\nDocument Path:          /\nDocument Length:        5 bytes\n\nConcurrency Level:      100\nTime taken for tests:   7.240 seconds\nComplete requests:      1000000\nFailed requests:        0\nKeep-Alive requests:    1000000\nTotal transferred:      73000000 bytes\nHTML transferred:       5000000 bytes\nRequests per second:    138124.14 [#/sec] (mean)\nTime per request:       0.724 [ms] (mean)\nTime per request:       0.007 [ms] (mean, across all concurrent requests)\nTransfer rate:          9846.74 [Kbytes/sec] received\n\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:        0    0   0.0      0       5\nProcessing:     0    1   0.2      1       9\nWaiting:        0    1   0.2      1       9\nTotal:          0    1   0.2      1       9\n\nPercentage of the requests served within a certain time (ms)\n  50%      1\n  66%      1\n  75%      1\n  80%      1\n  90%      1\n  95%      1\n  98%      1\n  99%      1\n 100%      9 (longest request)\n```\n解释：\n```\nDocument Path:测试页面\nDocument Length: 页面大小\nConcurrency Level: 测试的并发数\nTime taken for tests:整个测试持续的时间\nComplete requests:完成的请求数量\nFailed requests: 失败的请求数量\nWrite errors: 0\nTotal transferred: 整个过程中的网络传输量\nHTML transferred: 整个过程中的HTML内容传输量\nRequests per second: 最重要的指标之一，相当于LR中的每秒事务数，后面括号中的mean表示这是一个平均值\nTime per request: 最重要的指标之二，相当于LR中的平均事务响应时间，后面括号中的mean表示这是一个平均值\nTime per request: 每个连接请求实际运行时间的平均值\nTransfer rate: 平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题\n```\n**其中 Failed requests 一旦大于0就表示服务已经达到饱和，Requests per second 是估算出来的 QPS。**\n\n# 单机容量评估\n应用服务器单机的处理能力估算公式\n```\nTPC-C = ∑ (每秒钟服务处理量 * 标准的服务性能比率) / (1 - 冗余率)\n```\n比如 A 应用同时提供 serviceX 和 serviceY，在一秒内需要同时处理 serviceX 1000 笔和 serviceY 2000 笔，每个 serviceX 的标准的服务性能比率为 0.5，每个 serviceY 的标准的服务性能比率为 2，考虑 30% 的系统冗余率，那该应用服务器单机处理能力(tpmc) = ((1000 * 0.5) + (2000 * 2)) / (1 – 30%) = 6428。\n\n每个应用服务器根据自己系统提供的服务以及访问量计算出单机的处理能力。 存储服务器单机的处理能力除了考虑请求处理能力的估算外，还需要考虑硬盘的容量，主要估算的方法为每条数据库记录需要的硬盘空间，秒级需要提供的并发访问数，提供该并发能力持续的时间，估算的公式为\n```\n∑(SQL 每秒钟处理量 * SQL 记录需要的空间) * 时间\n```\n计算出在日常和活动峰值期间需要的硬盘容量，为了保障数据库空间够用，需要冗余 30% 的硬盘空间。 网络设备的容量估算主要涉及网络的 IP 资源、网络上行和下行带宽容量、网络延迟，评估的方法主要是根据业务峰值需要的网络流量进行带宽合并计算，按网络流量的上限估算网络带宽容量，IP 资源根据整体业务需要的 VM 资源数量来估算。\n\n# 集群容量评估\n首先估算峰值请求，根据2/8原则，即80%压力会集中在20%的时间里，得到一个峰值 QPS。然后根据总的容量要求计算出每个应用服务器、存储服务器需要达到的容量要求，最后根据服务器需要达到的容量除以单机的容量，得出每一个服务器需要的机器数量，按照计算出来的机器数量给对应的服务器扩容，以达到业务指标要求的容量。\n\n------------------------\n参考资料：  \n[分布式系统架构技术分析（二）](https://mp.weixin.qq.com/s/Tw6dZmj9fhjhhhN4TN8mKw)","tags":["运维"]},{"title":"用geohash来做地理距离计算","url":"/posts/1531668376/","content":"在知道 geohash 之前，对于查找附近的人这种需求，我只知道用自己的经纬度和对方的经纬度经过勾股定理来计算距离，但因为这样的方法实在是太慢没法用，最后还是用了第三方的 API 来获得结果。这片文章就来介绍一下 geohash。\n\ngeohash 是对经纬度做一系列计算，最后的到一个字符串，经纬度越精确，字符串越长，而距离越近的两点，字符串左边相同的字符就越多。例如使用 redis 的 geohash 命令得到上海人民广场地铁站的 geohash 是 wtw3sqgg0v0，上海博物馆是 wtw3sqh3ng0，老西门地铁站是 wtw3ss61250。可以看到人民广场离博物馆比较近，前6位字母是一样的，而距离较远的老西门则只有前5位一样了。这个算法可以设定精确度，越精确字符串越长。\n\n现在已经很清楚了，对于位置固定不变的东西，可以在 MySQL 保存 geo\u001chash 后用 Like 'xxx%' 来查找，缓存可以用 redis 的 \bgeoadd 和 geohash。但如果需求是一个位置实时在变的出租车，我们不是要在缓存找到出租车的 geohash，而是要根据近似的 geohash 来找到出租车的信息。可以用 redis 的 GEORADIUSBYMEMBER 命令，将数据库 id 作为 key。\n\nGeohash 具体算法实现这里就不写了，可以看维基百科(https://en.wikipedia.org/wiki/Geohash)。使用 geohash 虽然能快速的得到附近的物品，却不能得到距离。如果需要距离，可以取出经纬度后再计算。\n\n最后推荐一个 [geohash 的 PHP 扩展](https://github.com/taogogo/geohash-php-extention)\n","tags":["算法"]},{"title":"Elasticsearch基本操作","url":"/posts/1531467381/","content":"这篇文章的意义一来是给写 API 一个参考，二来是紧急情况控制台排查。因为浏览器和 postman 都不支持 GET 后面跟数据，所以所有命令都以 curl 形式给出。\n\n# 安装\n详细的安装过程就不写了，无非安装 java 后安装 elasticsearch。这里提一下，可以使用清华的镜像（https://mirrors.tuna.tsinghua.edu.cn/elasticstack/6.x/yum/6.3.1/elasticsearch-6.3.1.rpm） 。如果你的开发机内存小，修改 /etc/elasticsearch/jvm.option 以下两项：\n```\n-Xms128m\n-Xmx128m\n```\n128m 是你要分配的内存。\n\n# Index\n在 Elasticsearch 里 Index 代表代表一个数据库。\n\n## 查看所有 Index：\n```sh\n$curl -X GET '127.0.0.1:9200/_cat/indices?v'\n```\n\n## 新建 Index\n```sh\n$curl -X PUT '127.0.0.1:9200/users'\n```\n返回\n```json\n{\n    \"acknowledged\": true,\n    \"shards_acknowledged\":true,\n    \"index\":\"users\"\n}\n```\n返回的数据里有 acknowledged: true 即表示操作成功。这时候查看所有 Index 可以看到 users 库。\n\n## 删除 Index\n```sh\n$curl -X DELETE '127.0.0.1:9200/users'\n```\n\n# Type\nType 类似于库(Index) 里的表，用于对 Document 分类。下面的命令查看 Index 里所有的 Type:\n```sh\n$curl '127.0.0.1:9200/_mapping?pretty'\n``` \n\n# Document\nDocument 是实际写入的数据。下面以 Index: users, Type: m 为例演示怎么操作数据。\n\n## 添加数据，修改数据\n原型：\n```\nPUT /{index}/{type}/{id}\n```\n\n例子：\n```sh\n$curl -X PUT '127.0.0.1:9200/users/m/id1' -H'Content-Type:application/json' -d '\n{\n    \"name\": \"ljj\",\n    \"age\": \"30\"\n}\n'\n```\nurl 里的“id1”是给定的 id。也可以不给，相应 method 改成 POST，返回的 _id 字段是服务给的 id。\n\n## 删除数据\n原型：\n```\nDELETE /{index}/{type}/{id}\n```\n例子：\n```sh\n$curl -X DELETE '127.0.0.0:9200/users/m/id1'\n```\n\n# 查询\n\n## 已知 id\n原型：\n```\nGET /{index}/{type}/{id}\n```\n例子：\n```sh\n$curl '127.0.0.1:9200/users/m/id1?pretty'\n```\n\n## 简易查询\n```sh\n# 查询\n$curl '127.0.0.1:9200/users/_search?q=ljj&pretty'\n# 统计\n$curl '127.0.0.1:9200/users/_count?q=ljj&pretty'\n$curl '127.0.0.1:9200/_search?q=name:ljj&from=1&size=1&_source=name,age'\n```\n**q 规定了字段，from 规定偏移，size 规定返回条数，_source 规定返回的字段。**\n\n可以看到，Index 和 Type 都是可以去掉的，加上则规定了范围。返回的结果里包含 Index 和 Type。\n\n## 复杂查询\n```sh\n$curl '127.0.0.1:9200/users/_search' -H'Content-Type:application/json' -d '\n{\n    \"query\" : {\n        \"match\": {\n            \"name\": \"ljj othername\"\n        }\n    },\n    \"from\": 1,\n    \"size\": 1\n}\n'\n```\n**query 规定了匹配规则，match 规定了字段，from 规定偏移，size 规定返回条数。**\n\nname 里面的空格表示 or 的关系。如果需要 and 则使用下面的参数:\n```json\n{\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"match\": {\"name\": \"ljj\"}\n                },\n                {\n                    \"match\": {\"name\": \"othername\"}\n                }\n            ]\n        }\n    }\n}\n```\n\n## 聚合\n聚合相当于 SQL 里的 group by 语句\n\n下面给出一种特别的情况，comment_label 里面是数组，数据类似于\n```json\n{\n    \"comment_obj\":\"58c3f340936edfa7323ec801\",\n    \"eval_star\":4,\n    \"comment_label\":[\n        \"aaa\",\n        \"bbb\"\n    ]\n}\n```\n使用下面的语句查询\n```json\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": { //精确匹配，这里用 term 而不是 match\n            \"comment_obj\": \"58c3f340936edfa7323ec801\"\n          }\n        },\n        {\n            \"range\": {\n                \"eval_star\":{\n                    \"gte\":3\n                }\n            }\n        }\n      ]\n    }\n  },\n  \"aggs\": {//使用 aggs 关键词，也可以用 aggregations\n    \"comment_label\": {\n      \"terms\": {\n        \"field\": \"comment_label\"\n      }\n    }\n  },\n  \"size\": 0 //size=0 表示只返回统计值，不然还会返回匹配到的文档\n}\n```\n返回的值类似\n```json\n{\n    \"took\":2,\n    \"timed_out\":false,\n    \"_shards\":{\n        \"total\":5,\n        \"successful\":5,\n        \"skipped\":0,\n        \"failed\":0\n    },\n    \"hits\":{\n        \"total\":{\n            \"value\":1,\n            \"relation\":\"eq\"\n        },\n        \"max_score\":null,\n        \"hits\":[\n\n        ]\n    },\n    \"aggregations\":{\n        \"comment_label\":{\n            \"doc_count_error_upper_bound\":0,\n            \"sum_other_doc_count\":0,\n            \"buckets\":[\n                {\n                    \"key\":\"aaa\",\n                    \"doc_count\":1\n                },\n                {\n                    \"key\":\"bbb\",\n                    \"doc_count\":1\n                }\n            ]\n        }\n    }\n}\n```\n已经统计出了所有 comment_obj=\"58c3f340936edfa7323ec801\",eval_star>3 时，所有 comment_label 内值出现次数\n\n现在增加难度，语句嵌套 group by，匹配多个 comment_obj\n```json\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"terms\": {//匹配多个时，使用 terms\n            \"comment_obj\": [\"58c3f340936edfa7323ec801\"]\n          }\n        },\n        {\n            \"range\": {\n                \"eval_star\":{\n                    \"gte\":3\n                }\n            }\n        }\n      ]\n    }\n  },\n  \"aggs\": {\n      \"comment_obj\":{\n          \"terms\": {\n              \"field\": \"comment_obj\"\n          },\n          \"aggs\":{\n            \"comment_label\": {\n              \"terms\": {\n                \"field\": \"comment_label\"\n              }\n            }\n          }\n      }\n  },\n  \"size\": 0\n}\n```\n返回类似\n```json\n{\n    \"took\":142,\n    \"timed_out\":false,\n    \"_shards\":{\n        \"total\":5,\n        \"successful\":5,\n        \"skipped\":0,\n        \"failed\":0\n    },\n    \"hits\":{\n        \"total\":{\n            \"value\":1,\n            \"relation\":\"eq\"\n        },\n        \"max_score\":null,\n        \"hits\":[\n\n        ]\n    },\n    \"aggregations\":{\n        \"comment_obj\":{\n            \"doc_count_error_upper_bound\":0,\n            \"sum_other_doc_count\":0,\n            \"buckets\":[\n                {\n                    \"key\":\"58c3f340936edfa7323ec801\",\n                    \"doc_count\":1,\n                    \"comment_label\":{\n                        \"doc_count_error_upper_bound\":0,\n                        \"sum_other_doc_count\":0,\n                        \"buckets\":[\n                            {\n                                \"key\":\"5f40d73b2fee3a6d338db1ba\",\n                                \"doc_count\":1\n                            },\n                            {\n                                \"key\":\"5f40d7452fee3a4e509130fb\",\n                                \"doc_count\":1\n                            }\n                        ]\n                    }\n                }\n            ]\n        }\n    }\n}\n```\n看到返回值已经按照 comment_obj, comment_label 两极嵌套\n\n# 诊断\n## 集群里文档数量\n```sh\n$curl -XGET '127.0.0.1:9200/_count?pretty' -d '\n{\n    \"query\": {\n        \"match_all\": {}\n    }\n}\n'\n```\n\n## 集群健康\n```sh\ncurl -XGET '127.0.0.1:9200/_cluster/health'\n```\n返回以下数据\n```json\n{\n    \"cluster_name\": \"elasticsearch\",\n    \"status\": \"green\",\n    \"timed_out\": false,\n    \"number_of_nodes\": 1,\n    ...\n}\n```\n其中 status 是我们最感兴趣的，它有一下含义\n\n颜色 | 意义\n:-|:-\ngreen | 所有主要分片和复制分片都可用\nyallow | 所有主要分片可用，但不是所有复制分片都可用\nred | 不是所有主要分片都可用\n\n\n-------------------------------\n参考资料：  \n\b[全文搜索引擎 Elasticsearch 入门教程](http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html)  \n[官方文档](https://www.elastic.co/guide/index.html)  \n《Elasticsearch 权威指南》","tags":["elasticsearch","运维"]},{"title":"http简易指南","url":"/posts/1530930262/","content":"# HTTP 报文内容\nHTTP 报文是由一行一行的简单纯文本字符串组成的，不是二进制代码。下面是一个简单例子：\n\n请求：\n\n.|内容\n-|-\n起始行(start line) | GET /test/hi-there.php HTTP/1.0\n首部(header) | Accept: text/*<br>Accept-Language: en,zh\n\n响应：\n\n.|内容\n-|-\n起始行(start line) | HTTP/1.0 200 OK\n首部(header) | Content-type: text/plain<br>Content-length: 19\n主体(body)   | Hi! I'm a message!\n\n起始行和首部，由一个回车符（ASCII 13）和一个换行符（ASCII 10）作为结束。\n\n# 起始行\n## 常用 HTTP 方法\n请求报文起始行里的 *GET* 就是 HTTP 方法，其余方法参考下表：\n\n方法 | 描述 | 是否包含主体\n-|-|-\nGET | 从服务器获取一份文档 | 否\nHEAD | 只从服务器获取文档的首部 | 否\nPOST | 向服务器发送需要处理的数据 | 是\nPUT | 将请求的主体部分存储在服务器上 | 是\nTRACE | 对可能经过代理服务器传输到服务器上去的报文进行追踪 | 否\nOPTIONS | 决定可以在服务器上执行哪些方法 | 否\nDELETE | 从服务器上删除一份文档 | 否\n\n## HTTP 状态码\n响应报\b文起始行里的 *200* 就是 HTTP 状态吗，其他状态码参考下表：\n\n整体范围 | 已定义范围 | 分类 | 描述\n-|-|-|-\n100 ~ 199 | 100 ~ 101 | 信息提示 | 这一类型的状态码，代表请求已被接受，需要继续处理。这类响应是临时响应，只包含状态行和某些可选的响应头信息，并以空行结束。\n200 ~ 299 | 200 ~ 206 | 成功 | 这一类型的状态码，代表请求已成功被服务器接收、理解、并接受\n300 ~ 399 | 300 ~ 305 | 重定向 | 这类状态码代表需要客户端采取进一步的操作才能完成请求。通常，这些状态码用来重定向，后续的请求地址（重定向目标）在本次响应的 Location 域中指明。其中301是永久重定向，302是临时重定向。\n400 ~ 499 | 400 ~ 415 | 客户端错误 | 这类的状态码代表了客户端看起来可能发生了错误，妨碍了服务器的处理。其中401是未授权，404是找不到请求资源。\n500 ~ 599 | 500 ~ 505 | 服务端错误 | 这类状态码代表了服务器在处理请求的过程中有错误或者异常状态发生，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理。\n\n# 首部\nHTTP 首部字段有很多，而且\b可以添加自定义的字段，这里只列几个比较常见或重要的。\n\n首先要说明很多字段值可以加一个质量值 **\"q\"**，定义各个值的权重，例如这个首部：\n> Accept-Language: en;q=0.5, fr;q=0.0, nl;q=1.0, tr;q=0.0\n\nq 值的范围从 0.0 ～ 1.0（0.0是优先级最低，而1.0是优先级最高的）。注意偏好的排序不重要，只有 q 值才是重要的。\n\n## Accept\n客户端用 Accept 首部来通知服务器可以接受哪些媒体类型。\n\n- **类型**：请求首部\n- **注释**：可以用\"*\"通配符。例如\"*/*\",\"image/*\"\n- **举例**：Accept: text/*, image/*\n\n## Accept-Charset\n客户端用 Accept-Charset 通知服务器可以接受哪些字符集。\n\n- **类型**：请求首部\n- **注释**：和\b Accept 一样支持通配符\n- **举例**：Accept-Charset: utf-8\n\n## Accept-Encoding\n客户端用 Accept-Encoding 首部来告诉服务器可以接受哪些编码方式。\n\n- **类型**：请求首部\n- **举例**：Accept-Encoding: gzip;q=1.0, compress;q=0.5\n\n## Cache-Control\n\n- **类型**：通用首部\n- **举例**：Cache-Control: no-cache\n\n## Connection\n在 HTTP/1.0 中 默认关闭 Keep-Alive 模式，要通过 Connection: Keep-Alive 打开。在 HTTP/1.1 中默认开启了 Keep-alive 模式，通过加入 Connection: close 才关闭。\n\n- **类型**：通用首部\n- **举例**：Connection: close\n\n## Content-Encoding\nContent-Encoding \b首部用于说明是否对某对象进行过编码。\n\n- **类型**：实体首部\n- **举例**：Content-Encoding: compress, gzip\n\n## Content-Length\nContent-Length 首部说明实体**主体**部分的长度。HEAD 请求响应中如果有这个首部，表示如果发送的话，实体主体的长度。\n\n- **类型**：\b实体首部\n- **举例**：Content-Length: 2417\n\n## Content-Type\nContent-Type 首部说明了报文中对象的媒体类型。\n\n- **类型**：实体首部\n- **举例**：Content-Type: text/html; charset=utf-8\n\n## \bCookie, Cookie2\nCookie 用来改变 Cookie，Cookie2 是对 Cookie 的扩展\n\n- **类型**：扩展请求首部\n- **举例**：Cookie: name=\"ljj\"\n\n## Date\nDate 首部给出了报文创建的日期和时间。\n\n- **类型**：通用首部\n- **举例**：\bDate: Tue, 3 Oct 1997 02:15:31 GMT\n\n## ETag\nETag 首部为保文中包含的实体提供了实体标记。实体标记实际上就是一种标识资源的方式。\n\n- **类型**：实体首部\n- **举例**：ETag: \"11e92a-457b-31345aa\"\n\n## Location\n服务器可以通过 Location 首部将客户端导向某个资源地址。浏览器收到这个首部将会跳转。\n\n- **类型**：响应首部\n- **举例**：Location: http://www.ljj.pub\n\n## Set-Cookie, Set-Cookie2\nSet-Cookie 首部是 Cookie 的搭档，规定了 Cookie 的作用域和其他一些信息。Set-Cookie2 是对 Set-Cookie 的扩展。\n\n- **类型**：\b扩展响应首部\n- **举例**：Set-Cookie: \bname=ljj; domain=\"ljj.pub\"; path=/posts/\n\n例子里 name=ljj 是强制的，其他都是可选的\n\n## User-Agent\n客户端用 User-Agent 首部来表示其类型\n\n- **类型**：\b请求首部\n- **举例**：User-Agent: Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0)\n\n另外\b\b说明一个，Age（秒）, Cache-Control, Expire（日期） 是设定为计算缓存生命周期的，但现在更好的做法是永久缓存，然后给 URL 加版本号的方法更新文件。\n\n# HTTP 与 WebSocket\nWebSocket 是在 HTTP 基础上的协议，需要浏览器支持。\bWebSocket \b允许客户端和服务器通过长链接双工通信，即\b两边可以不断的向另一边发送信息而不用重新连接。没有 WebSocket 协议之前如果服务器要不断向浏览器发送信息，就要打开长链接（Connection: Keep-Alive，默认打开），而且只能服务器向浏览器发送。而且由于服务端保持长链接开销很大，通常通过客户端隔一段时间请求来实现。\n\n-------------------------\n参考资料：\n《HTTP权威指南》\nhttp状态码：https://baike.baidu.com/item/HTTP状态码/5053660?fr=aladdin","tags":["http"]},{"title":"分布式事务之TCC补偿型事务","url":"/posts/1530843273/","content":"# 原理\n之前的一篇[博客](/posts/1529896095/)已经提过通过 MySQL 提供的 XA 事务来实现分布式事务。但很多人发现它性能不好，一些大公司的做法是引入 TCC 事务模型。TCC 事务模型是补偿型事务的一种实现，分为 Try/ Confirm/ Cancel 三个阶段。在解释 TCC 前，现在考虑一个现实中分布式的例子：\n\n假设你要做飞机从上海转机去北京，要求到上海和到北京都有对应时间的机票，只要有一张没有，就两张都不买了。这时候你打电话给航空公司 A，预约保留机票，再打电话给航空公司 B，如果 B 有票的话，再打给 A 确认购票，如果 B 没有票的话，也要打给 A 取消预约。\n\n这个例子里面，向两个公司确认机票对应 Try 阶段，购票对应 Confirm 阶段，取消对应 Cancel 阶段。**因此 TCC 模型就是用业务逻辑实现了数据库的事务逻辑。** 整个逻辑的一个主要方面是确认操作是否可以失败。如果保证成功，则整个操作是一个补偿操作[2]，即隐式确认，明确取消。而 Cancel 阶段就是补偿操作里的补偿部分。一个现实中的例子是，企业通过电话要求客户忽略该信件可以补偿给客户的邮寄信件。\n\nTry/ Confirm/ Cancel 三个阶段对应的数据库操作可以参考下面这个简单的例子：\n\n```sql\n# try\nINSERT RESERVATION\n\n# confirm\nUPDATE RESERVATION SET STATUS='CONFIRMED'\n\n# cancel\nUPDATE RESERVATION SET STATUS='CANCELED'\n\n```\n\n# 实现\n阿里的实现是增加一个事务管理\b器，先由主业务发起主事务，然后向每个子业务（远程服务）发起 Try 确认资源。如果资源确认通过的话，再把 Confirm 和 Cancel 的请求代码交给事务管理器，由事务管理器完成后续工作\n\n例如我花20元下单买东西。\n## Try阶段\n1. 生成订单，状态为UNPAY\n2. 支付过程，100-20=80，预扣字段设为20\n3. 库存设置为100-1=99，预扣字段设置为1\n\n## Confirm阶段\n1. 修改订单状态为PAY\n2. 修改用户账号余额，将预扣字段的20块清零\n3. 将库存数量的预扣字段设置为0\n\n## Cancel阶段\n1. 修改订单状态为CANCEL\n2. 把预扣的金额补回到用户的金额里面。80+20=100\n3. 将库存预扣部分补回到原本的99+1=100件\n\n# 隔离\n由于只使用了版本号（状态）区分事务的阶段，这就造成了事务还在进行中的时候，如果需要读数据，要么读不到最终状态的数据，要么无法读取，返回错误。这个时候需要引入快照。事务进行的时候，保存之前的快照，读的时候，需要从快照里读。\n\n# 实现难点\n1. 因为完全用业务逻辑实现，每个子事务都要提供三个接口，代码量稍大；\n2. 事务要求隔离性（Isolation），即一个事务进行的时候，其他请求读到的应该是原来的数据，这个可以用冗余数据增加版本号来解决；\n3. 如果事务管理器挂了，怎么保证事务继续执行？\n4. Confirm / Cancel 操作要实现幂等性，即事务管理器失败重启，重新执行的时候，重复上一次的操作不会出错；\n\n--------------------------\n参考资料：\nhttp://www.enterpriseintegrationpatterns.com/patterns/conversation/TryConfirmCancel.html  \n补偿操作：http://www.enterpriseintegrationpatterns.com/patterns/conversation/CompensatingAction.html  \nhttps://cdn.ttgtmedia.com/searchWebServices/downloads/Business_Activities.pdf  \nTCC Java 实现：https://cloud.tencent.com/developer/article/1049345  \n[分布式事务中的一致性和隔离性](https://blog.csdn.net/weixin_33877092/article/details/92562466)","tags":["分布式"]},{"title":"git命令参考","url":"/posts/1530499706/","content":"# 查看 commit 历史\n```sh\ngit log\n```\n\n# 显示本地执行过的 git 命令\n就像 shell 的 history 一样\n```sh\ngit reflog\n```\n\n# 撤销某个 commit/reflog，并重新添加一个 commit/reflog\n```sh\ngit revert <commit-id>/<reflog-id>\n```\n只会撤销指定 commit 的改变，不影响后面的 commit。  \n如果 commit 来自另一个分支，因为添加了新的 commit，再次 merge 时，文件不会合并。\n\n# 回滚到某个 commit/reflog，并删除后面的 commit/reflog\n和revert的区别：reset命令会抹去某个commit id之后的所有commit\n```sh\ngit reset <commit-id>/<reflog-id> #默认就是-mixed参数，回滚 commit 和 add，不回滚文件\ngit reset HEAD^ #回滚到上一个 commit\ngit reset --mixed HEAD~1 #和上一个一样，HEAD~ 后跟往回退几步\ngit reset --hard <commit-id>/<reflog-id> #会滚到指定 commit，文件会改变，线上紧急回滚时用\n```\ngit reset 参数默认是 --mixed，会回滚 commit 和 add，保留文件。平时使用默认就可以了。线上运维使用 --hard 回滚代码。\n\ngit reset commit-id 和 reflog-id 的区别：  \n通常我们都是在新分支上开发，然后合并(merge)到发布分支，因此在发布分支，只要使用\n```sh\ngit reset <reflog-id>\n```\n就可以回滚 merge 操作，即开发分支上所有的 commit。非常适合线上回滚代码。\n\n这里给一个快速回滚到上一条 reflog 的代码：\n```sh\ngit reflog |awk 'NR==2{print $1}'|xargs git reset --hard\n```\n\n# 切换分支\n```sh\ngit checkout <branch-name>\n```\n放弃文件修改也可以用这个命令，但如果文件名和分支名相同的话就会搞混。所以放弃文件修改统一加上 --\n\n# 放弃文件修改\n```sh\ngit checkout -- <file-name>\ngit checkout <stash@n> -- <file-name> #从stash中拿出某个文件的修改\n```\n\n# 查看 commit/reflog 之间的文件区别\n```sh\n$ git diff #查看当前修改和上一次提交的区别\n$ git diff -- <file-name> #指定文件和上一次修改的区别\n$ git diff <commit-id>/<reflog-id> <commit-id>/reflog-id> #查看提交/操作之间的区别\n$ git diff <commit-id>/<reflog-id> -- <file-name> #指定文件提交/操作之间的区别\n```\n\n# 在当前分支基础上新建分支\n```sh\n$ git checkout -b <branch-name>\n```\n\n# 分支改名\n```sh\n$ git branch -m old_branch new_branch\n```\n\n# 拉取远程分支\n```sh\n$ git checkout -b <本地分支名> origin/<远程分支名>\n```\n\n# 删除分支\n```sh\n# 本地\n$ git branch -d <branch-name>\n# 远程\n$ git push origin --delete <branch-name>\n```\n\n# 合并分支\n```sh\n$ git merge <branch-name>\n```\n\n# 只下载最新代码\n```sh\n$ git clone --depth=1 <url>\n```\n只下载最新代码而不带历史数据，加速下载\n\n# fork 后和原仓库同步\n```sh\n$ git remote add upstream URL # 把原仓库添加为 upstream\n$ git fetch upstream\n$ git merge upstream/master\n```\n\n# 重命名\n```sh\n$ git branch -m oldName name # m = move\n```\n\n--------------------------\n参考资料：  \nhttp://www.bootcss.com/p/git-guide/\nhttps://github.com/521xueweihan/git-tips#回到远程仓库的状态","tags":["git"]},{"title":"tmp目录文件莫名消失及后续","url":"/posts/1530180519/","content":"有一个 WorkerMan 程序，会把 pid 放在 /tmp 目录下，过一段时间不知道为什么这个文件就消失了，然后命令行的控制就不起作用了。网上查了之后知道 linux 系统除了用户的 crontab 外，还有一些定时任务在 /etc/cron.* 系列目录下。而且有专门清除 /tmp 目录的任务，配置文件在 /usr/lib/tmpfiles.d/tmp.conf。pid 文件是不能 /tmp 下了。跟运维沟通后得知 linux 有个专门放 pid 文件的目录是 /var/run。\n\n改完程序后还不能重启进程，最好可以 reload。从运维那里得知一般程序 reload 可以用\n```sh\nkill -HUP pid\n```\n这个命令。试了以后发现不行，主程序被杀死了。看程序里面用的是 SIGUSR1 这个信号，即要执行\n```sh\nkill -USR1 pid\n```\nSIGUSR1 信号是程序自定义的信号，至于 WorkerMan 收到这个信号执行了什么，就是另一篇文章的事了。\n\n**所以这里给出结论：SIGHUP 信号的解释是挂起，大多数服务器进程都会进行复位操作并重新加载配置文件。但不适用我们自己写的程序。**","tags":["运维"]},{"title":"分布式事务之mysql两阶段提交","url":"/posts/1529896095/","content":"## 两阶段提交\n分布式事务即跨数据库事务，要求分布式系统中每个用到的服务器的事务一起提交或一起回滚。为了做到这点，一个解决方法是引入两阶段提交。\n\n两阶段提交简称 2PC，全称 Two Phase Commitment Protocol。要实现两阶段提交需要这两个管理器：\n- **资源管理器（resource manager）**：即数据库，用来管理数据，可以实现本地事务。在2PC里扮演参与者角色\n- **事务管理器（transaction manager）**：协调每个资源管理器的事务。在2PC里扮演协调者角色\n\n两阶段提交协议分为两个步骤：\n1. **准备(prepare)阶段**：即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向transaction manager报告已准备就绪。 \n2. **提交(commit/rollback)阶段**：当transaction manager确认所有参与者都ready后，向所有参与者发送commit命令。 \n\n## MySQL XA事务及其基本语法\nMySQL 提供了 XA 事务来支持二段式提交，但它本身不是事务管理器。XA 事务基本语法如下：\n\nXA {START|BEGIN} xid [JOIN|RESUME] 启动xid事务 (xid 必须是一个唯一值; 不支持[JOIN|RESUME]子句) \nXA END xid [SUSPEND [FOR MIGRATE]] 结束xid事务 ( 不支持[SUSPEND [FOR MIGRATE]] 子句) \nXA PREPARE xid 准备、预提交xid事务 \nXA COMMIT xid [ONE PHASE] 提交xid事务 \nXA ROLLBACK xid 回滚xid事务 \nXA RECOVER 查看处于PREPARE 阶段的所有事务\n\n## php 调用 MySQL XA 事务实现分布式事务\n首先确保 mysql 开启 XA 事务支持\n```sql\nSHOW VARIABLES LIKE '%XA%'\n```\n不是的话执行\n```sql\nSET innodb_support_xa = ON\n```\n示例代码如下：\n```php\n<?php\n$dbtest1 = new mysqli(\"172.20.101.17\",\"public\",\"public\",\"dbtest1\")or die(\"dbtest1 连接失败\");\n$dbtest2 = new mysqli(\"172.20.101.18\",\"public\",\"public\",\"dbtest2\")or die(\"dbtest2 连接失败\");\n\n//为XA事务指定一个id，xid 必须是一个唯一值。\n$xid = uniqid(\"\");\n\n//两个库指定同一个事务id，表明这两个库的操作处于同一事务中\n$dbtest1->query(\"XA START '$xid'\");//准备事务1\n$dbtest2->query(\"XA START '$xid'\");//准备事务2\n\ntry {\n    //$dbtest1\n    $return = $dbtest1->query(\"UPDATE member SET name='唐大麦' WHERE id=1\") ;\n    if($return == false) {\n       throw new Exception(\"库dbtest1@172.20.101.17执行update member操作失败！\");\n    }\n\n    //$dbtest2\n    $return = $dbtest2->query(\"UPDATE memberpoints SET point=point+10 WHERE memberid=1\") ;\n    if($return == false) {\n       throw new Exception(\"库dbtest1@172.20.101.18执行update memberpoints操作失败！\");\n    }\n\n    //阶段1：$dbtest1提交准备就绪\n    $dbtest1->query(\"XA END '$xid'\");\n    $dbtest1->query(\"XA PREPARE '$xid'\");\n    //阶段1：$dbtest2提交准备就绪\n    $dbtest2->query(\"XA END '$xid'\");\n    $dbtest2->query(\"XA PREPARE '$xid'\");\n\n    //阶段2：提交两个库\n    $dbtest1->query(\"XA COMMIT '$xid'\");\n    $dbtest2->query(\"XA COMMIT '$xid'\");\n} \ncatch (Exception $e) {\n    //阶段2：回滚\n    $dbtest1->query(\"XA ROLLBACK '$xid'\");\n    $dbtest2->query(\"XA ROLLBACK '$xid'\");\n    die($e->getMessage());\n}\n\n$dbtest1->close();\n$dbtest2->close();\n```\n\n## 两阶段提交的问题\n2PC存在同步阻塞、单点问题、脑裂等问题，此外还有数据一致性问题。如果第二阶段参与者和协调者同时挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。\n\n这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行commit或者roolback操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是commit那还好，和其他的机器保持一致了，万一他执行的是roolback操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！\n\n## 三阶段提交(3PC)及其问题\n3PC最关键要解决的就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。在第一阶段，只是询问所有参与者是否可可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback。\n\n3PC的问题在于，在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。\n\n所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。\n\n--------------------------\n参考资料：\nhttps://blog.csdn.net/soonfly/article/details/70677138\nhttps://blog.csdn.net/yyd19921214/article/details/68953629","tags":["mysql","分布式"]},{"title":"php使用epoll","url":"/posts/1529483141/","content":"之前[这篇](/posts/1528164527/)文章介绍了select, poll, epoll 的区别，已经知道 epoll 是最佳选择，也知道了 libevent 是对这三者的封装。这篇文章介绍怎么用 php 和 libevent 来实现一个 epoll 程序。\n\n首先是必要的扩展\n1. php 要支持 pcntl\n2. 系统已经装好 livevent\n3. 安装 php 扩展 event。另一个扩展 libevent 已经很久没更新了。\n\n先来实现一个纯 PHP 循环向进程发送信号的程序\n```php\n<?php\n// 给当前php进程安装一个alarm信号处理器\n// 当进程收到alarm时钟信号后会作出动作\npcntl_signal( SIGALRM, function(){\n  echo \"tick.\".PHP_EOL;\n} );\n// 定义一个时钟间隔时间，1秒钟吧\n$tick = 1;\nwhile( true ){\n  // 当过了tick时间后，向进程发送一个alarm信号\n  pcntl_alarm( $tick );\n  // 分发信号，呼唤起安装好的各种信号处理器\n  pcntl_signal_dispatch();\n  // 睡个1秒钟，继续\n  sleep( $tick );\n}\n```\n\n代码保存成 timer.php，然后 php timer.php 运行下，如果不出问题应该能跑起来。但是性能不好。下面是一个用 Event 扩展的实现：\n```php\n<?php\n// 初始化一个EventConfig\n$eventConfig = new EventConfig();\n// 根据EventConfig初始化一个EventBase\n$eventBase = new EventBase( $eventConfig );\n// 初始化一个定时器event\n$timer = new Event( $eventBase, -1, Event::TIMEOUT | Event::PERSIST, function(){\n  echo microtime( true ).\" : 起飞！\".PHP_EOL;\n} );\n// tick间隔为0.05秒钟，我们还可以改成0.5秒钟甚至0.001秒，也就是毫秒级定时器\n$tick = 0.05;\n// 将定时器event添加（可以不传 $tick）\n$timer->add( $tick );\n// eventBase进入loop状态\n$eventBase->loop();\n```\n\n这种定时器是持久的定时器（每隔X时间一定会执行一次），如果想要一次性的定时器（隔X时间后就会执行一次，执行过后再也不执行了），那么将上述代码中的“Event::TIMEOUT | Event::PERSIST”修改为“Event::TIMEOUT”即可。\n\n需要重点说明的是new Event()这行代码了，我把原型贴过来给大家看下：\n```\npublic Event::__construct ( EventBase $base , mixed $fd , int $what , callable $cb [, mixed $arg = NULL ] )\n```\n- 第一个参数是一个eventBase对象即可\n- 第二个参数是文件描述符，可以是一个监听socket、一个连接socket、一个fopen打开的文件或者stream流等。如果是时钟时间，则传入-1。如果是其他信号事件，用相应的信号常量即可，比如SIGHUP、SIGTERM等等\n- 第三个参数表示事件类型，依次是Event::READ、Event::WRITE、Event::SIGNAL、Event::TIMEOUT。**其中，加上Event::PERSIST则表示是持久发生，而不是只发生一次就再也没反应了。比如Event::READ | Event::PERSIST就表示某个文件描述第一次可读的时候发生一次，后面如果又可读就绪了那么还会继续发生一次。**\n- 第四个参数就熟悉的很了，就是事件回调了，意思就是当某个事件发生后那么应该具体做什么相应\n- 第五个参数是自定义数据，这个数据会传递给第四个参数的回调函数，回调函数中可以用这个数据。\n\n如果你有一些自定义用户数据传递给回调函数，可以利用new Event()的第五个参数，这五个参数可以给回调函数用，如下所示：\n```php\n<?php\n$timer = new Event( $eventBase, -1, Event::TIMEOUT | Event::PERSIST, function() use( &$custom ){\n  //echo microtime( true ).\" : 起飞！\".PHP_EOL;\n  print_r( $custom );\n}, $custom = array(\n  'name' => 'woshishui',\n) );\n```\n\n通过以上的案例代码可以总结一下日常流程：\n1. 创建EventConfig（非必需）\n2. 创建EventBase\n3. 创建Event\n4. 将Event挂起，也就是执行了Event对象的add方法，不执行add方法那么这个event对象就无法挂起，也就不会执行\n5. 将EventBase执行进入循环中，也就是loop方法\n\n以上就是怎么用 Event 扩展来实现一个 epoll 循环程序。可以点下面的参考资料来看验证方法，和如果用 epoll + socket 实现一个 http 服务器。\n\n--------------------------\n参考资料：\n[advanced-php](https://github.com/elarity/advanced-php/blob/master/13.%20PHP%20socket初探%20---%20硬着头皮继续libevent（二）.md)","tags":["php"]},{"title":"php进程间通信和共享内存","url":"/posts/1529460697/","content":"## 前言\n进程间通信简称 IPC，全称 InterProcess Communication。常见的进程间通信方式有：管道（分无名和有名两种）、消息队列、信号量、共享内存和socket。\n\n## 管道和FIFO\n管道是最初的 IPC 形式，我们平时使用命令 ps aux | grep php，这里的 | 就是管道。管道最大的局限是没有名字，从而只能由有亲缘关系的进程使用。这一点在 FIFO 出现后得到改进。因而 FIFO 有时也称为命名管道（named pipe）。管道一般是半双工的，但有些系统实现了全双工。\n\nphp 使用命名管道通信，创建一个管道的函数叫做posix_mkfifo()，管道创建完成后其实就是一个文件，然后就可以用任何与读写文件相关的函数对其进行操作了，代码大概演示一下：\n```php\n<?php\n// 管道文件绝对路径\n$pipe_file = __DIR__.DIRECTORY_SEPARATOR.'test.pipe';\n// 如果这个文件存在，那么使用posix_mkfifo()的时候是返回false，否则，成功返回true\nif( !file_exists( $pipe_file ) ){\n  if( !posix_mkfifo( $pipe_file, 0666 ) ){\n    exit( 'create pipe error.'.PHP_EOL );\n  }\n}\n// fork出一个子进程\n$pid = pcntl_fork();\nif( $pid < 0 ){\n  exit( 'fork error'.PHP_EOL );\n} else if( 0 == $pid ) {\n  // 在子进程中\n  // 打开命名管道，并写入一段文本\n  $file = fopen( $pipe_file, \"w\" );\n  fwrite( $file, \"helo world.\" );\n  exit;\n} else if( $pid > 0 ) {\n  // 在父进程中\n  // 打开命名管道，然后读取文本\n  $file = fopen( $pipe_file, \"r\" );\n  // 注意此处fread会被阻塞\n  $content = fread( $file, 1024 );\n  echo $content.PHP_EOL;\n  // 注意此处再次阻塞，等待回收子进程，避免僵尸进程\n  pcntl_wait( $status );\n}\n```\n运行结果如下：\n```\n$ php fifo.php\nhello world\n```\n管道的唯一限制为：\nOPEN_MAX  一个进程在任意时刻打开的最大描述符数（Posix 要求至少为16）；  \nPIPE_BUF  可原子地写往一个管道或 FIFO 的最大数据量（Posix 要求至少为512）\n\n## 消息队列\n这里的消息队列是存储于系统内核中（不是用户态）的一个链表，因而在一个进程发出消息时，不需要另外某个进程等待，这与管道相反。一般我们外部程序使用一个key来对消息队列进行读写操作。在PHP中，是通过msg_*系列函数完成消息队列操作的。\n```php\n<?php\n// 使用ftok创建一个键名，注意这个函数的第二个参数“需要一个字符的字符串”\n$key = ftok( __DIR__, 'a' );\n// 然后使用msg_get_queue创建一个消息队列\n$queue = msg_get_queue( $key, 0666 );\n// 使用msg_stat_queue函数可以查看这个消息队列的信息，而使用msg_set_queue函数则可以修改这些信息\n//var_dump( msg_stat_queue( $queue ) );  \n// fork进程\n$pid = pcntl_fork();\nif( $pid < 0 ){\n  exit( 'fork error'.PHP_EOL );\n} else if( $pid > 0 ) {\n  // 在父进程中\n  // 使用msg_receive()函数获取消息\n  msg_receive( $queue, 0, $msgtype, 1024, $message );\n  echo $message.PHP_EOL;\n  // 用完了记得清理删除消息队列\n  msg_remove_queue( $queue );\n  pcntl_wait( $status );\n} else if( 0 == $pid ) {\n  // 在子进程中\n  // 向消息队列中写入消息\n  // 使用msg_send()向消息队列中写入消息，具体可以参考文档内容\n  msg_send( $queue, 1, \"hello world\" );\n  exit;\n}\n```\n运行结果如下：\n```\n$ php msg.php\nhello world\n```\n\n## 同步与信号量\n为了同步多个进程的活动，就要允许在进程间共享数据。如果要多个进程读写同一个数据，就要引入锁。在多线程的情况下，本身有共享数据缓冲区，上锁与解锁非常简单。对于多进程上锁与解锁，可以使用信号量(semaphore)。\n\n对于多线程，php 有 pthreads 扩展，不过这个扩展需要将 php 编译成线程安全（ZTS）版本，具体参考其 [github 页面](https://github.com/krakjoe/pthreads)。这里给出一个 pthreads 互斥锁(mutex)和条件等待(cond)的演示，**但是注意，这两个类在最新版里已经删除，新版使用 synchronized 函数。这里之所以还使用旧版，是因为旧版更接近原 c 语言的用法**\n```php\n<?php\n/** 不可以使用 new 关键字，因为互斥量不是 PHP 对象 **/\n$mutex = Mutex::create();\n$cond = Cond::create();\n$condition = false;\nfunction produce()\n{\n  global $condition,$mutex,$cond;\n  Mutex::lock($mutex);\n  echo \"pth2\\n\";\n  $condition = true;\n  Cond::signal($cond);\n  // Cond::broadcast($cond);\n  Mutex::unlock($mutex);\n}\n\nfunction comsume()\n{\n  global $condition,$mutex,$cond;\n  Mutex::lock($mutex);\n  while(!$condition){\n    Cond::wait($cond, $mutex);\n  }\n  echo \"pth1\\n\";\n  Mutex::unlock($mutex);\n}\n\n// 线程2\ncomsume();\n// 线程1\nproduce();\n\n/** 永远不要忘记销毁你创建的条件变量及互斥量 **/\nCond::destroy($cond);\n/** 销毁一个处于加锁状态的互斥量的操作是无效的 **/\nMutex::unlock($mutex);\n/** 永远不要忘记销毁你创建的互斥量 **/\nMutex::destroy($mutex);\n```\n运行结果如下，pth2永远在pth1前，即两个线程通过 mutex 和 cond 的结合使其线程间同步\n```\npth2\npth1\n```\n\n题外话：如果没有 mutex，signal 可能在 wait 之前执行，这样 wait 永远等不到 signal。mutex 和 cond 都是锁死等待，之所以需要 cond 是因为 Cond::wait() 后线程会释放锁，进入休眠，不再循环判断条件。在Cond::wait() 释放 mutex 之前，线程依靠 while() 保证程序不会执行到 echo。\n\n对于信号量，php 提供 sem_acquire(), sem_get(), sem_release(), sem_remove() 4个函数。因为信号量一般和共享内存一起使用，所以代码在下一节共享内存中演示。\n\n## 共享内存\n共享内存是最快是进程间通信方式，因为n个进程之间并不需要数据复制，而是直接操控同一份数据。实际上信号量和共享内存是分不开的，要用也是搭配着用。*NIX的一些书籍中甚至不建议新手轻易使用这种进程间通信的方式，因为这是一种极易产生死锁的解决方案。共享内存顾名思义，就是一坨内存中的区域，可以让多个进程进行读写。这里最大的问题就在于数据同步的问题，比如一个在更改数据的时候，另一个进程不可以读，不然就会产生问题。所以为了解决这个问题才引入了信号量，信号量是一个计数器，是配合共享内存使用的，一般情况下流程如下：\n- 当前进程获取将使用的共享内存的信号量\n- 如果信号量大于0，那么就表示这块儿共享资源可以使用，然后进程将信号量减1\n- 如果信号量为0，则进程进入休眠状态一直到信号量大于0，进程唤醒开始从1\n\n一个进程不再使用当前共享资源情况下，就会将信号量减1。这个地方，信号量的检测并且减1是原子性的，也就说两个操作必须一起成功，这是由系统内核来实现的。\n\n```php\n<?php\n// sem key\n$sem_key = ftok( __FILE__, 'b' );\n$sem_id = sem_get( $sem_key );\n// shm key\n$shm_key = ftok( __FILE__, 'm' );\n$shm_id = shm_attach( $shm_key, 1024, 0666 );\nconst SHM_VAR = 1;\n$child_pid = [];\n// fork 2 child process\nfor( $i = 1; $i <= 2; $i++ ){\n  $pid = pcntl_fork();\n  if( $pid < 0 ){\n    exit();\n  } else if( 0 == $pid ) {\n\t// 获取锁\n\tsem_acquire( $sem_id );\n\tif( shm_has_var( $shm_id, SHM_VAR ) ){\n\t  $counter = shm_get_var( $shm_id, SHM_VAR );\n\t  $counter += 1;\n\t  shm_put_var( $shm_id, SHM_VAR, $counter );\n\t} else {\n\t  $counter = 1;\n\t  shm_put_var( $shm_id, SHM_VAR, $counter );\n\t}\n\t// 释放锁，一定要记得释放，不然就一直会被阻锁死\n  sem_release( $sem_id );\n  // 释放后删除\n  sem_remove( $sem_id );\n\texit;\n  } else if( $pid > 0 ) {\n    $child_pid[] = $pid;\n  }\n}\nwhile( !empty( $child_pid ) ){\n  foreach( $child_pid as $pid_key => $pid_item ){\n    pcntl_waitpid( $pid_item, $status, WNOHANG );\n\tunset( $child_pid[ $pid_key ] );\n  }\n}\n// 休眠2秒钟，2个子进程都执行完毕了\nsleep( 2 );\necho '最终结果'.shm_get_var( $shm_id, SHM_VAR ).PHP_EOL;\n// 记得删除共享内存数据，删除共享内存是有顺序的，先remove后detach，顺序反过来php可能会报错\nshm_remove( $shm_id );\nshm_detach( $shm_id );\n```\n运行结果如下：\n```\n$ php shm.php\n最终结果2\n```\n\n确切说，如果不用sem的话，上述的运行结果在一定概率下就会产生1而不是2。但是只要加入sem，那就一定保证100%是2，绝对不会出现其他数值。\n\n## php 守护进程和 socket 通信\n进程间通信的前提是 php 需要是守护进程，不然还没收到信息就退出了。php 守护进程需要用到 pcntl_fork() 生成子进程。socket 通信需要用到 socket_ 系列函数。这两个参考资料中的 advanced-php 已经有详细介绍，这篇文章就不写了。也可以看官方文档了解。\n\n--------------------------\n参考资料：\n《unix网络编程：第二卷》\n[advanced-php](https://github.com/elarity/advanced-php)\n[PCNTL函数](http://php.net/manual/zh/book.pcntl.php)\n[Sockets函数](http://php.net/manual/zh/book.sockets.php)\n[posix函数](http://php.net/manual/zh/ref.posix.php)\n[Semaphore函数](http://php.net/manual/zh/book.sem.php)","tags":["php"]},{"title":"mysql运维","url":"/posts/1529389113/","content":"# 备份与还原\n```sh\n# 备份数据库\nmysqldump [-h主机名 -P端口] -u用户名 -p密码 数据库名 [表名]> 文件名.sql\n\n# 还原\nmysql [-h主机名] -\bu用户名 -p密码 数据库名 < 文件名.sql\n```\n\n# 状态查看\n## SHOW STATUS\nshow status 命令会显示每个服务器变量和值，可以执行以下命令单个查看：\n```\nshow status where Variable_name like 'Conne%'\n```\n以下是一些重要的：\n\n1. 线程和连接统计\n- Connections, Max_used_connections, Threads_connected\n- Aborted_clients, Aborted_connects\n- Bytes_received, Bytes_sent\n- Slow_lanuch_threads, Threads_cached, Threads_created,\nThreads_running\n\n如果Aborted_connects不为0，可能意味着网络有问题或某人尝试连接但失败（可能用户指定了错误的密码或无效的数据库，或某个监控系统正在打开TCP的3306端口来检测服务器是否活着）。如果这个值太高，可能有严重的副作用：导致MySQL阻塞一个主机。\n\n2. 二进制日志状态\nBinlog_cache_use和Binlog_cache_disk_use状态变量显示了在二进制日志缓存中有多少事务被存储过，以及多少事务因超过二进制日志缓存而必须存储到一个临时文件中。\n\n3. SELECT类型\nSelect_*\b 变量是特定类型 SELECT 查询的计数器。其中Select_scan表示全表扫描，Select_range_check 和 Select_full_join 表示\b无索引的联接。这三个开销较大。\n\n4. 表锁\nTable_locks_immediate和Table_locks_waited变量可告诉你有多少锁被立即授权，有多少锁需要等待。但请注意，它们只是展示了服务器级别锁的统计，并不是存储引擎级的锁统计。\n\n## SHOW ENGINE INNODB STATUS\n显示 InnoDB 引擎的信息，只有一列。因为不是专业运维，这里只介绍几个需要了解的段。\n\n1. LATEST DETECTED DEADLOCK\n只有当前服务器内有死锁时才会出现，内容是死锁的上下文\n\n## SHOW PROCESSLIST\n进程列表是当前连接到MySQL的连接或线程的清单。**这个命令可以看哪些线程持有锁**\n\n--------------------------\n参考资料：《高性能MySQL》","tags":["运维","mysql"]},{"title":"mysql explain 中各列的意义","url":"/posts/1529374970/","content":"\n## select_type 列\n这一列显示是哪种类型的 SELECT。最外层是 PRIMARY，其他部分标记如下：\n- SUBQUERY  \n  包含在SELECT列表中的子查询中的SELECT（换句话说，不在FROM子句中）\n- DERIVED  \n  包含在 FROM 子句的子查询中的SELECT。MySQL 会产生一个临时表。\n- UNION  \n  在 UNION 中的第二个和随后的 SELECT。\n- UNION RESULT  \n  用来从UNION的匿名临时表检索结果的SELECT被标记为UNION RESULT\n\n## table 列\n这一列显示了对应行正在访问哪个表。\n\n当在FROM子句中有子查询时，table列是<derivedN>的形式，其中N是子查询的id。这总是“向前引用”——换言之，N指向EXPLAIN输出中后面的一行。\n\n当有UNION时，UNION RESULT的table列包含一个参与UNION的id列表。这总是“向后引用”，因为UNION RESULT出现在UNION中所有参与行之后。\n\n## type 列\n访问类型，就是 MySQL 决定如何查找表中的行。下面一次从最差到最优：\n- ALL  \n  全表扫描\n- index  \n  索引扫描，也要扫描全表，只是按照索引次序进行而不是行，避免了排序。\n- range  \n  范围查询是一个有限制的索引扫描。WHERE 里带 BETWEEN 或 > <的查询。\n- ref  \n  索引访问。叫 ref 是因为索引要跟某个参考值比较。ref_or_null 是 ref 的一个变体，它意味着 MySQL 必须进行第二次查找以找出 NULL 条目。\n- eq_ref  \n  使用主键或唯一索引\n- const, system  \n  MySQL 对语句优化后，变量被转为常量\n- NULL  \n  只通过索引，不用访问数据表\n\n## possible_keys 列\n这一列显示了查询可以使用哪些索引，不一定真的用到。\n\n## key 列\n这一列显示了 MySQL 决定采用那个索引。\n\n## key_len 列\n该列显示了索引的字节数，不是表中数据的字节数。\n\n## ref 列\n这一列显示了之前的表在key列记录的索引中查找值所用的列或常量。\n\n## rows 列\n这一列是 MySQL 估计为了找到目标要读取的行数。不是最终目标行数。\n\n## filtered 列\nrows 占总行数的比例\n\n## Extra 列\n- Using index  \n  表示 MySQL 使用覆盖索引，不需要访问数据表\n- Using where  \n  WHERE 条件使用了索引\n- Using temporary  \n  使用了临时表\n- Using filesort  \n  使用了外部索引排序\n- Range checked for each record (index map: N)  \n  没有好用的索引\n\n\n--------------------------\n参考资料：《高性能MySQL》","tags":["mysql"]},{"title":"用python做爬虫的正确姿势","url":"/posts/1529320519/","content":"已经用 python 做了不知道多少爬虫了，看看网上关于这个题材的文章都已经很老了，这篇文章介绍下我的做法。\n\n一个爬虫程序至少需要抓取和解析两个部分，抓取我使用的是 [requests](https://github.com/requests/requests)。这个库除了封装 get, post 请求外，尤其方便的是封装了会话( session )，自动更新 cookies。对抓取需要登录的网站特别好用。\n\n解析我使用的是 [pyquery](https://github.com/gawel/pyquery)。这个库对 jQuery 达到了很高的模仿，熟悉 jQuery 的人上手非常快。通常我都是在浏览器的 console 里复制 html 元素的 css 选择器或者 xpath 路径。这里要注意浏览器会给选择器添加元素，例如 tbody，复制出来是 table > tbody > tr。但其实 html 里没有 tbody 这个元素。手动去掉就好了。\n\n----------------------\n此外 python 还有一个重量级的爬虫库叫 scrapy。这个以前会用，现在已经很少用了。如果是大工程可以考虑。","tags":["最佳实践","python"]},{"title":"golang开发环境搭建","url":"/posts/1529303379/","content":"### 安装\nMac 下安装 Go 编译器只要执行\n```sh\nbrew install go\n```\n就可以了。各 linux 也可以使用自己的包管理器直接安装\n\n### 工作空间\n首先找一个地方放我们的工作空间，比如我选的是$HOME/Documents/gowork。这个目录的位置不能是 Go 安装目录。\n```sh\n$ mkdir $HOME/Documents/gowork\n```\nGo代码必须放在工作空间内。它其实就是一个目录，其中包含三个子目录：\n- src 目录包含Go的源文件，它们被组织成包（每个目录都对应一个包），\n- pkg 目录包含包对象，\n- bin 目录包含可执行命令。\n\n下面是一个例子：\n```\nbin/\n    hello       # 编译好的二进制文件，可执行命令\npkg/\n    darwin_amd64/\n        github.com/questionlin/\n            stringutil.a      # 编译好的包对象\nsrc/\n    github.com/questionilin/\n        hello/\n            hello.go        # 源代码\n            hello_test.go   # 测试文件源代码\n        stringutil/\n            reverse.go      # 包源码\n\n```\n\n### \bGOPATH 环境变量\n执行下面的命令\n```sh\n$ export GOPATH=$HOME/gowork\n$ export PATH=$PATH:$GOPATH/bin\n```\n\n### 第一个程序\n我在 github 的用户名是 questionlin，我要做的第一个程序叫 hello。执行命令\n```sh\n$ mkdir -p $GOPATH/src/github.com/questionlin/hello\n$ cd $GOPATH/src/github.com/questionlin/hello\n$ touch hello.go\n```\n写入一下代码\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tfmt.Printf(\"Hello, world.\\n\")\n}\n```\n执行一下命令编译。这个命令在任何目录都可以执行，不需要在工作空间\n```sh\n$ go install github.com/questionlin/hello\n```\n如果在工作空间可以省略路径\n```sh\n$ cd $GOPATH/src/github.com/questionlin/hello\n$ go install\n```\n现在执行看看\n```sh\n$ $GOPATH/bin/hello\nHello, world.\n```\n\n### 第一个库\n首先创建目录：\n```sh\n$ mkdir $GOPATH/src/github.com/questionlin/stringutil\n$ cd $GOPATH/src/github.com/questionlin/stringutil\n$ touch reverse.go\n```\n写入一下内容\n```go\n// stringutil 包含有用于处理字符串的工具函数。\npackage stringutil\n\n// Reverse 将其实参字符串以符文为单位左右反转。\nfunc Reverse(s string) string {\n\tr := []rune(s)\n\tfor i, j := 0, len(r)-1; i < len(r)/2; i, j = i+1, j-1 {\n\t\tr[i], r[j] = r[j], r[i]\n\t}\n\treturn string(r)\n}\n```\n使用 go build 来编译:\n```sh\n$ go build github.com/questionlin/stringutil\n```\n如果你在该包的源码目录中，只需执行：\n```sh\n$ go build\n```\n修改原来的 hello.go 文件，加入这个包：\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/questionlin/stringutil\"\n)\n\nfunc main() {\n\tfmt.Printf(stringutil.Reverse(\"!oG ,olleH\"))\n}\n```\n然后在编译一次 hello：\n```sh\n$ go install github.com/questionlin/hello\n```\n现在再运行一次\n```sh\n$ hello\nHello, Go!\n```\n完成以上步骤后，你的工作区间应该是像最上面介绍工作空间那章里一样\n\n\n### 包名\nGo源文件中的第一个语句必须是\n```go\npackage 名称\n```\n这里的 名称 即为导入该包时使用的默认名称。 （一个包中的所有文件都必须使用相同的 名称。）\n\nGo的约定是包名为导入路径的最后一个元素：作为 “crypto/rot13” 导入的包应命名为 rot13。\n\n可执行命令必须使用 package main。\n\n### 测试\nGo拥有一个轻量级的测试框架，它由 go test 命令和 testing 包构成。\n\n你可以通过创建一个名字以 _test.go 结尾的，包含名为 TestXXX 且签名为 func (t *testing.T) 函数的文件来编写测试。 测试框架会运行每一个这样的函数；若该函数调用了像 t.Error 或 t.Fail 这样表示失败的函数，此测试即表示失败。\n\n我们可通过创建文件 $GOPATH/src/github.com/questionlin/stringutil/reverse_test.go 来为 stringutil 添加测试，其内容如下：\n```go\npackage stringutil\n\nimport \"testing\"\n\nfunc TestReverse(t *testing.T) {\n\tcases := []struct {\n\t\tin, want string\n\t}{\n\t\t{\"Hello, world\", \"dlrow ,olleH\"},\n\t\t{\"Hello, 世界\", \"界世 ,olleH\"},\n\t\t{\"\", \"\"},\n\t}\n\tfor _, c := range cases {\n\t\tgot := Reverse(c.in)\n\t\tif got != c.want {\n\t\t\tt.Errorf(\"Reverse(%q) == %q, want %q\", c.in, got, c.want)\n\t\t}\n\t}\n}\n```\n接着使用 go test 运行该测试：\n```sh\n$ go test github.com/questionlin/stringutil\nok  \tgithub.com/questionlin/stringutil 0.165s\n```\n\n\n最后给一个墙内能用的 golang 学习教程：\nhttps://tour.go-zh.org/list\n\n参考：https://go-zh.org/doc/\n","tags":["golang"]},{"title":"linux硬盘满了怎么清理","url":"/posts/1528685621/","content":"1. 使用 df -h 查看硬盘剩余空间\n2. 使用 du --max-depth=1 -h 一级一级查看硬盘文件占用，找到适合删掉的文件\n3. 如果是只想删掉大文件，可以使用 find . -maxdepth 1 -size +100M\n```sh\n$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/vda1        30G   12G   17G  40% /\ndevtmpfs        7.8G     0  7.8G   0% /dev\n/dev/vdb         99G   55G   39G  59% /opt\n\n\n$ du --max-depth=1 -h\n272K ./.gconf \n32K ./.mcop \n16K ./.redhat \n1.7M ./.thumbnails \n8.0K ./.gconfd \n7.5M . \n\n$ find . -maxdepth 1 -size +100M\n./.gconf \n./.mcop \n./.redhat \n./.thumbnails \n./.gconfd \n```","tags":["运维"]},{"title":"MySQL索引结构和优化","url":"/posts/1528513470/","content":"## B-Tree 索引\nInnoDB 使用的是B+Tree，即每一个叶子结点都包含指向下一个叶子节点的指针，从而方便叶子节点的范围遍历。B-Tree通常意味着所有的值都是按**顺序**存储在叶子节点的，并且每一个叶子页到根的距离相同。\n\n假设有如下数据表：\n```sql\nCREATE TABLE People (\n    last_name varchar(50)    not null,\n    first_name varchar(50)   not null,\n    dob date                 not null,\n    gender enum('m', 'f')  not null,\n    key(last_name, first_name, dob)\n);\n```\n可以使用B-Tree索引的查询类型。B-Tree索引适用于全键值、键值范围或键前缀查找。**其中键前缀查找只适用于根据最左前缀的查找**。此索引对如下类型的查询有效。\n\n- 全值匹配  \n  全值匹配指的是和索引中的所有列进行匹配，例如前面提到的索引可用于查找 last_name 为 Allen, first_name 为 Cuba 、出生于1960-01-01的人。\n- 匹配最左前缀  \n  索引可用于查找所有 lat_name 为Allen的人，即只使用索引的第一列。\n- 匹配列前缀  \n也可以只匹配某一列的值的开头部分。例如前面提到的索引可用于查找所有以J开头的姓的人。这里也只使用了索引的第一列。\n- 匹配范围值  \n例如前面提到的索引可用于查找姓在Allen和Barrymore之间的人。这里也只使用了索引的第一列。\n- 精确匹配某一列并范围匹配另外一列  \n前面提到的索引也可用于查找所有姓为Allen，并且名字是字母K开头（比如Kim、Karl等）的人。即第一列last_name全匹配，第二列frst_name范围匹配。\n\n### B-Tree索引的限制：\n- 如果不是按照索引的最左列开始查找，则无法使用索引。例如上面例子中的索引无法用于查找名字为Bill的人，也无法查找某个特定生日的人，因为这两列都不是最左数据列。类似地，也无法查找姓氏以某个字母结尾的人。\n- 不能跳过索引中的列。也就是说，前面所述的索引无法用于查找姓为Smith并且在某个特定日期出生的人。如果不指定名（first_name），则MySQL只能使用索引的第一列。\n- 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。例如有查询WHERE last_name='Smith' AND frst_name LIKE 'J％' AND dob='1976-12-23'，这个查询只能使用索引的前两列，因为这里LIKE是一个范围条件（但是服务器可以把其余列用于其他目的）。如果范围查询列值的数量有限，那么可以通过使用多个等于条件来代替范围条件。在本章的索引案例学习部分，我们将演示一个详细的案例。\n\n到这里读者应该可以明白，前面提到的索引列的顺序是多么的重要：这些限制都和索引列的顺序有关。在优化性能的时候，可能需要使用相同的列但顺序不同的索引来满足不同类型的查询需求。\n\n## 高性能索引策略\n### 独立的列\n**索引列不能是表达式的一部分，也不能是函数的参数。** 以下是失败例子：\n```\nmysql> SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;\nmysql> SELECT ... WHERE TO_DAYS(CURRENT_DATE) - TO_DAYS(date_col) <= 10;\n```\n\n### 前缀索引和索引选择性\n有时候需要索引很长的字符列，这会让索引变得大且慢。\b诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长。  \n现在我们有如下数据集\n```\nmysql>SELECT COUNT(*) AS cnt, city FROM city GROUP BY city ORDER BY cnt DESC LIMIT 10;\n-------------------------------------\n| cnt | city|\n+-----+-----+\n| 65 | London |\n| 49 | Hiroshima |\n| 48 | Teboksary |\n| 48 | Pak Kret |\n| 48 | Yaound |\n| 47 | Tel Aviv-Jaffa |\n| 47 | Shimoga |\n| 45 | Cabuyao |\n| 45 | Callao |\n| 45 | Bislig |\n```\n注意到，上面每个值都出现了45～65次。现在查找到最频繁出现的城市前缀，先从3个前缀字母开始：\n```\nmysql>SELECT COUNT(*) AS cnt, LEFT(city, 3) AS pref FROM city GROUP BY pref ORDER BY cnt DESC LIMIT 10;\n| cnt | pref |\n+-----+------+\n| 483 | San |\n| 195 | Cha |\n| 177 | Tan |\n| 167 | Sou |\n| 163 | al- |\n| 163 | Sal |\n| 146 | Shi |\n| 136 | Hal |\n| 130 | Val |\n| 129 | Bat |\n```\n每个前缀都比原来的城市出现的次数更多，因此唯一前缀比唯一城市要少得多。然后我们增加前缀长度，直到这个前缀的选择性接近完整列的选择性。经过实验后发现前缀长度为7时比较合适：\n```\nmysql>SELECT COUNT(*) AS cnt, LEFT(city, 3) AS pref FROM city GROUP BY pref ORDER BY cnt DESC LIMIT 10;\n| cnt | pref |\n+-----+------+\n| 70 | Santiag |\n| 68 | San Fel |\n| 65 | London |\n| 61 | Valle d |\n| 49 | Hiroshi |\n| 48 | Teboksa |\n| 48 | Pak Kre |\n| 48 | Yaound |\n| 47 | Tel Avi |\n| 47 | Shimoga |\n```\n计算合适的前缀长度的另外一个办法就是计算完整列的选择性，并使前缀的选择性接近于完整列的选择性。下面显示如何计算完整列的选择性：\n```\nmysql> SELECT COUNT(DISTINCT LEFT(city, 7))/COUNT(*) FROM city;\n| COUNT(DISTINCT city)/COUNT(*) |\n+-------------------------------+\n| 0.0310 |\n```\n通常来说（尽管也有例外情况），这个例子中如果前缀的选择性能够接近0.031，基本上就可用了。\n\n在上面的示例中，已经找到了合适的前缀长度，下面演示一下如何创建前缀索引：\n```\nmysql> ALTER TABLE sakila.city_demo ADD KEY (city(7));\n```\n前缀索引是一种能使索引更小、更快的有效办法，但另一方面也有其缺点：MySQL无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。\n\n\n--------------------------\n参考资料：《高性能MySQL》","tags":["mysql"]},{"title":"JVM 垃圾处理的一些总结","url":"/posts/1528196487/","content":"## 内存管理\n### 程序计数器\n程序计数器（Program Counter Register），用来记录程序已经执行到的行号，当虚拟机在多个线程轮流切换时，靠它回到正确的执行位置。\n\n### 堆和栈\nJava 内存可以大致分为：分为虚拟机栈，本地方法栈，Java 堆，方法区，运行时常量池，直接内存。各自用来存储虚拟机和用户程序的代码、变量和其他一些信息。其中，Java 堆是所有线程共享的一块内存区域，唯一目的时存放对象实例。因此也成为垃圾管理的主要区域。\n\n## 垃圾收集\n### 判断对象是否需要被清理\n判断对象是否需要被清理可以分为引用计数算法和可达性分析算法。\n\n引用计数算法的原理是这样的：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器就加1；当饮用失效时，计数器就减1；任何时刻计数器为0的对象就是不可能再被使用的。\n\n可达性分析算法通过树来保存对象的引用链，如果对象和根（GC Roots）不再有引用链时，就被判断判断为不可达。此时对象不会被立即回收，而是要经历一个 finalize() 方法的回收过程，在此过程中对象可以自救。\n\n\n### 垃圾收集算法\n#### 标记-清除算法\n最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n\n#### 复制算法\n为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。\n\n#### 标记-整理算法\n复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。\n\n根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n\n#### 分代收集算法\n当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。\n\n--------------------------\n参考资料：《深入理解Java虚拟机：JVM高级特性与最佳实践》","tags":["java"]},{"title":"通过例子理解mysql事务的4种隔离级别","url":"/posts/1528164495/","content":"SQL标准定义了4种隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。\n\n低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。\n\n首先，我们使用 test 数据库，新建 tx 表。\n\n### 第1级别：Read Uncommitted(读取未提交内容)\n(1)所有事务都可以看到其他未提交事务的执行结果  \n(2)本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少  \n(3)该级别引发的问题是——脏读(**Dirty Read**)：读取到了未提交的数据\n```sh\n#首先，修改隔离级别\nset tx_isolation='READ-UNCOMMITTED';\nselect @@tx_isolation;\n+------------------+\n| @@tx_isolation   |\n+------------------+\n| READ-UNCOMMITTED |\n+------------------+\n\n#事务A：启动一个事务\nstart transaction;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |    1 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务B：也启动一个事务(那么两个事务交叉了)在事务B中执行更新语句，且不提交\nstart transaction;\nupdate tx set num=10 where id=1;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |   10 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务A：那么这时候事务A能看到这个更新了的数据吗?\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |   10 |   --->可以看到！说明我们读到了事务B还没有提交的数据\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务B：事务B回滚,仍然未提交\nrollback;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |    1 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务A：在事务A里面看到的也是B没有提交的数据\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |    1 |      --->脏读意味着我在这个事务中(A中)，事务B虽然没有提交，但它任何一条数据变化，我都可以看到！\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n```\n-------------------------------------\n### 第2级别：Read Committed(读取提交内容)\n(1)这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）  \n(2)它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变  \n(3)这种隔离级别出现的问题是——不可重复读(Nonrepeatable Read)：不可重复读意味着我们在同一个事务中执行完全相同的select语句时可能看到不一样的结果。  \n|——>导致这种情况的原因可能有：\n1. 有一个交叉的事务有新的commit，导致了数据的改变  \n2. 一个数据库被多个实例操作时,同一事务的其他实例在该实例处理其间可能会有新的commit\n```sh\n#首先修改隔离级别\nset tx_isolation='read-committed';\nselect @@tx_isolation;\n+----------------+\n| @@tx_isolation |\n+----------------+\n| READ-COMMITTED |\n+----------------+\n\n#事务A：启动一个事务\nstart transaction;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |    1 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务B：也启动一个事务(那么两个事务交叉了)在这事务中更新数据，且未提交\nstart transaction;\nupdate tx set num=10 where id=1;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |   10 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务A：这个时候我们在事务A中能看到数据的变化吗?\nselect * from tx; --------------->\n+------+------+                |\n| id   | num  |                |\n+------+------+                |\n|    1 |    1 |--->并不能看到！  |\n|    2 |    2 |                |\n|    3 |    3 |                |\n+------+------+                |——>相同的select语句，结果却不一样\n                               |\n#事务B：如果提交了事务B呢?         |\ncommit;                        |\n                               |\n#事务A:                         |\nselect * from tx; --------------->\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |   10 |--->因为事务B已经提交了，所以在A中我们看到了数据变化\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n```\n-------------------------------------\n### 第3级别：Repeatable Read(可重读)\n(1)这是MySQL的默认事务隔离级别  \n(2)它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行  \n(3)此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行  \n(4)InnoDB和Falcon存储引擎通过多版本并发控制(MVCC，Multiversion Concurrency Control)机制解决了该问题\n```sh\n#首先，更改隔离级别\nset tx_isolation='repeatable-read';\nselect @@tx_isolation;\n+-----------------+\n| @@tx_isolation  |\n+-----------------+\n| REPEATABLE-READ |\n+-----------------+\n\n#事务A：启动一个事务\nstart transaction;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |    1 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务B：开启一个新事务(那么这两个事务交叉了)在事务B中更新数据，并提交\nstart transaction;\nupdate tx set num=10 where id=1;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |   10 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\ncommit;\n\n#事务A：这时候即使事务B已经提交了,但A能不能看到数据变化？\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |    1 | --->还是看不到的！(这个级别2不一样，也说明级别3解决了不可重复读问题)\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n\n#事务A：只有当事务A也提交了，它才能够看到数据变化\ncommit;\nselect * from tx;\n+------+------+\n| id   | num  |\n+------+------+\n|    1 |   10 |\n|    2 |    2 |\n|    3 |    3 |\n+------+------+\n```\n-------------------------------------\n### 第4级别：Serializable(可串行化)\n(1)这是最高的隔离级别  \n(2)它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。  \n(3)在这个级别，可能导致大量的超时现象和锁竞争\n```sh\n#首先修改隔离界别\nset tx_isolation='serializable';\nselect @@tx_isolation;\n+----------------+\n| @@tx_isolation |\n+----------------+\n| SERIALIZABLE   |\n+----------------+\n\n#事务A：开启一个新事务\nstart transaction;\n\n#事务B：在A没有commit之前，这个交叉事务是不能更改数据的\nstart transaction;\ninsert tx values('4','4');\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nupdate tx set num=10 where id=1;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n```\n-------------------------------------\n| 隔离级别                      | 脏读 | 不可重复读 | 幻读 |\n| - | :-: | :-: | :-: |\n| 读未提交 ( Read uncommitted ) | ✓ | ✓ | ✓ |\n| 读已提交 ( Read committed )   | × | ✓ | ✓ |\n| 可重复读 ( Repeatable read )  | × | × | ✓ |\n| 可串行化 ( Serializable )     | × | × | × |\n\n参考文章\nhttp://xm-king.iteye.com/blog/770721\n\n转自：http://www.cnblogs.com/snsdzjlz320/p/5761387.html","tags":["mysql"]},{"title":"线上代码和rpc debug哪家强","url":"/posts/1528164505/","content":"标题两种情况，除了看日志外，还有一种做法是做一种转发器，把断点输出转发到程序员这边。这篇文章安利下我做的转发器 [rebugger](https://github.com/questionlin/rebugger)。\n\nrebugger 的原理是用 WorkerMan 做一个中转站，服务器通过 http 请求向中发出消息，中转站提取出内容，转发到程序员这边的 telnet \b客户端。例如 PHP 服务器，程序只要执行 file_get_contents() 就能把消息发出去了。\n\n使用 rebugger \b的优点是 file_get_contents() 一个函数就把消息发出去了，轻便无依赖。缺点是 get 请求不能有特殊字符，特殊情况需要转义一下。更重的做法是做一个插件，程序引入后可以有一个接口，直接发送 socket 请求给telnet 客户端。不过 rebugger 应该已经能满足大部分 php 程序员的需求了。","tags":["php","安利"]},{"title":"select poll epoll 之间的区别","url":"/posts/1528164527/","content":"select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\n\n今天对这三种IO多路复用进行对比，参考网上和书上面的资料，整理如下：\n\n### 1. select 实现\nselect 的调用过程如下所示：  \n![过程图](http://wx4.sinaimg.cn/large/726f09bbgy1frycff5ubgj20hk0a8q34.jpg)\n1. 使用 copy_from_user 从用户控件拷贝 fd_set 到内核空间\n2. 注册回调函数 __pollwait\n3. 遍历所有 fd，调用其对应的 poll 方法（对于 socket， 这个 poll 方法是 sock_poll， sock_poll \b根据情况会调用到 tcp_poll, udp_poll 或者 datagram_poll)\n4. 以 tcp_poll 为例，其核心时间就是 __pollwait，也就是上面注册的回调函数。\n5. __pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk->sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。\n6. poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。\n7. 如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。\n8. 把fd_set从内核空间拷贝到用户空间。\n\n### 总结\nselect的几大缺点：\n\n（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大\n\n（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大\n\n（3）select支持的文件描述符数量太小了，默认是1024\n\n（4）你不能在等待的时候修改描述符集\n\n### 2. poll 实现\npoll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，没有大小限制，其他的都差不多。\n\n关于select和poll的实现分析，可以参考下面几篇博文：\n\nhttp://blog.csdn.net/lizhiguo0532/article/details/6568964#comments\n\nhttp://blog.csdn.net/lizhiguo0532/article/details/6568968\n\nhttp://blog.csdn.net/lizhiguo0532/article/details/6568969\n\nhttp://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/index.html?ca=drs-\n\nhttp://linux.chinaunix.net/techdoc/net/2009/05/03/1109887.shtml\n\n### 3. epoll\nepoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。\n\n对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。\n\n对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。\n\n对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。\n\n### 总结：\n\n（1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。\n\n（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。\n\n（3）即使一个线程处在 epoll_wait \b函数中，你也可以随时修改列表。\b\n\n（4）可以通过 epoll_wait() 使多个线程在同一个 epoll 队列中等待，这是 select / poll 无法做到的。\n\n### libevent\nlibevent 是一个库，将以上的方法封装在一套 API 中，使得\b同一套代码可以在不同系统中使用（\bFreeBSD 使用 kqueue)。\n\n参考资料：\n**https://www.cnblogs.com/Anker/p/3265058.html**\n\n**https://www.ulduzsoft.com/2014/01/select-poll-epoll-practical-difference-for-system-architects/**\n\nhttp://www.cnblogs.com/apprentice89/archive/2013/05/09/3070051.html\n\nhttp://www.linuxidc.com/Linux/2012-05/59873p3.htm\n\nhttp://xingyunbaijunwei.blog.163.com/blog/static/76538067201241685556302/\n\nhttp://blog.csdn.net/kkxgx/article/details/7717125\n\nhttps://banu.com/blog/2/how-to-use-epoll-a-complete-example-in-c/epoll-example.c\n\n三种方式的用法：\n\nselect: http://www.cnblogs.com/Anker/archive/2013/08/14/3258674.html\n\npoll: http://www.cnblogs.com/Anker/archive/2013/08/15/3261006.html\n\nepoll: http://www.cnblogs.com/Anker/archive/2013/08/17/3263780.html\n"},{"title":"mysql配置主从分离","url":"/posts/1528164516/","content":"原理：主服务器（Master）负责网站NonQuery操作，从服务器负责Query操作，用户可以根据网站功能模特性块固定访问Slave服务器，或者自己写个池或队列，自由为请求分配从服务器连接。主从服务器利用MySQL的二进制日志文件，实现数据同步。二进制日志由主服务器产生，从服务器响应获取同步数据库。\n\n具体实现：\n1. 配置 Master 主服务器\n    1. 在 Master MySQL 上创建用户'repl'，并允许其他 Slave 服务可以通过远程访问 Master，通过该用户读取二进制日志，\b实现数据同步。\n\n    ```\n    1 mysql>create user repl; //创建新用户\n    2 //repl用户必须具有REPLICATION SLAVE权限，除此之外没有必要添加不必要的权限，密码为mysql。说明一下192.168.0.%，这个配置是指明repl用户所在服务器，这里%是通配符，表示192.168.0.0-192.168.0.255的Server都可以以repl用户登陆主服务器。当然你也可以指定固定Ip。\n    3 mysql> GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.0.%' IDENTIFIED BY 'mysql';\n    ```\n\n    2. 找到MySQL安装文件夹修改my.Ini文件。mysql中有好几种日志方式，这不是今天的重点。我们只要启动二进制日志log-bin就ok。\n    在[mysqld]下面增加下面几行代码\n\n    ```\n    1 server-id=1   //给数据库服务的唯一标识，一般为大家设置服务器Ip的末尾号\n    2 log-bin=master-bin\n    3 log-bin-index=master-bin.index\n    ```\n\n    3. 查看日志\n    ```\n    mysql> SHOW MASTER STATUS;\n    +-------------------+----------+--------------+------------------+\n    | File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n    +-------------------+----------+--------------+------------------+\n    | master-bin.000001 | 1285 | | |\n    +-------------------+----------+--------------+------------------+\n    1 row in set (0.00 sec)\n    ```\n    重启 MySQL 服务\n\n2. \b配置 Slave 从服务器 (windows)\n    1. 找到MySQL安装文件夹修改my.ini文件，在[mysqld]下面增加下面几行代码\n    ```\n    1 [mysqld]\n    2 server-id=2\n    3 relay-log-index=slave-relay-bin.index\n    4 relay-log=slave-relay-bin \n    ```\n    重启 MySQL 服务\n\n    2. 连接 Master\n    ```\n    change master to master_host='192.168.0.104', //Master 服务器Ip\n    master_port=3306,\n    master_user='repl',\n    master_password='mysql', \n    master_log_file='master-bin.000001',//Master服务器产生的日志\n    master_log_pos=0;\n    ```\n\n    3. 启动 Slave\n    ```\n    start slave;\n    ```\n\n3. Slave 从服务器 (Ubuntu)\n    1. 找到 MySQL 安装文件夹修改 my.cnf 文件， vim my.cnf\n    ```\n    [mysqld]\n    basedir =/usr/local/mysql\n    datadir =/usr/local/mysql/data\n    port = 3306\n    server_id = 3\n    relay_log_index=slave-relay-bin.index\n    relay_log=slave-relay-bin\n    ```\n\n    2. ./support-files/myql.server restart 重启MySQL服务  ,  ./bin/mysql 进入MySQL命令窗口 \n\n    3. 连接 Master\n    ```\n    change master to master_host='192.168.0.104', //Master 服务器Ip\n    master_port=3306,\n    master_user='repl',\n    master_password='mysql', \n    master_log_file='master-bin.000001',//Master服务器产生的日志\n    master_log_pos=0;\n    ```\n\n    4. 启动 Slave\n    ```\n    start slave;\n    ```\n\n转自：http://www.cnblogs.com/alvin_xp/p/4162249.html","tags":["mysql","分布式"]},{"title":"最佳安全实践","url":"/posts/1528164481/","content":"对于需要自行或外包开发信息系统的商户来说，有一些安全的注意事项，我们从 需求、设计、编码、测试、部署&运维 五个方面来展开。  \n1. 需求  \n     a、商户自建营销活动需设计防刷机制。  \n2. 设计  \n     a、数据采集  \n◆ 法律禁止企业记录和存储的数据（如磁道信息、信用卡CVV码等）不能收集。  \n◆ 客户端敏感数据必须先进行加密处理。  \n     b、数据传输  \n◆ 使用HTTPS确保网络传输安全性。  \n◆ 禁用SSL等不安全协议和算法，建议使用TLS1.2。  \n◆ 不要轻易的尝试设计和实现自己的加密传输算法，几乎都会存在问题。  \n     c、数据保存  \n◆ 敏感信息禁止出现在日志中，如确实需要，需进行脱敏处理。  \n◆ 缓存和DB中的敏感数据需进行加密或者虚化（Hash）。  \n◆ 密码等关键认证必须采用加盐Hash方式保存。  \n     d、数据访问  \n◆ 外部请求数据访问必须进行鉴权操作。  \n◆ 对于内部的数据访问要严加控制，降低用户信息泄漏风险。  \n     e、审计日志  \n◆ 记录的操作日志要包括5W信息（Who、When、Why、How、What）。  \n     f、资金处理  \n◆ 建立对账机制，每天对系统收支数据与微信支付数据进行对账，避免资金出现问题。  \n◆ DB或者KV需要设计数据防篡改机制。  \n3. 编码  \n     a、防止参数处理不当导致的常见漏洞  \n◆ 参考 [Web漏洞检测及修复](http://wiki.open.qq.com/wiki/Web漏洞检测及修复)  \n     b、防止逻辑处理不当导致的漏洞  \n◆ 支付成功回调通知必须验证微信支付签名，避免被恶意攻击。  \n◆ 在后台进行商户价格的判断逻辑，避免客户端篡改价格导致商户损失。  \n◆ 避免在App或者网站页面里面出现商户APIkey或API证书等信息，防止泄漏。  \n     c、APP开发安全注意事项  \n◆ IOS应用安全开发参考 [Apple NextPrevious Security Development Checklists](https://developer.apple.com/library/content/documentation/Security/Conceptual/SecureCodingGuide/SecurityDevelopmentChecklists/SecurityDevelopmentChecklists.html)  \n◆ andriod应用安全开发参考 [Andriod Security Tips](https://developer.android.com/training/articles/security-tips.html)\n4. 测试  \n     a、对输入输出参数进行专项安全测试。  \n     b、通过众测或自建、第三方的安全扫描机制对系统进行安全扫描并对问题进行修复。\n5. 部署&运维\n     a、确保系统所使用商业和开源组件的版本是最新稳定版。  \n     b、参考此份checklist进行安全配置 [系统漏洞检测及修复](http://wiki.open.qq.com/wiki/系统漏洞检测及修复)  \n     c、考虑系统和数据服务容灾，至少有主备机制，建议多机房多地部署。  \n     d、建议采用各大云系统，并且启用相关的云安全防控机制。  \n     e、如有条件，建议自建或者购买一些安全监控服务或设备。  \n     f、设定关键指标项，进行实时数据上报和监控  \n     g、有专门的人员来跟进安全事件的处置。  \n     h、关注信息系统所使用框架及组件的安全信息情况。  \n     i、按时打补丁，定期检查系统升级。  \n     j、服务端口开启最小化原则。  \n     k、服务器登录操作可审计。  \n     m、内部管理运营系统必须认证登录做操作日志记录以供审计。  \n     n、建立业务下线机制，不再使用的业务做下线操作减少被攻击面。  \n\n\n转自 https://pay.weixin.qq.com/wiki/doc/api/micropay.php?chapter=23_3#menu1","tags":["最佳实践","安全"]},{"title":"javascript阻止网页操作完成后自动跳转","url":"/posts/1528164457/","content":"阻止跳转的代码：\n```js\n$(window).on('beforeunload', () => { console.log('leave'); return false; });\n```\n```js\nwindow.addEventListener('beforeunload', function(){console.log('leave');return false;});\n```\n\n参考来源：https://jingyan.baidu.com/article/574c52190bc5ac6c8d9dc196.html","tags":["javascript"]},{"title":"打包网页完整内容的一个方法","url":"/posts/1528164446/","content":"用 safari 保存网站为归档，格式为 webarchive ，用 WebArchive Extractor 解压缩。\n\n这样不但能保存完整的 html, javascript, css，而且\b每个文件分开，非常直观。"},{"title":"redis sentinel主从模式","url":"/posts/1528164430/","content":"# 什么是 sentinel 模式\nsentinel 的中文意思是哨兵，即有一个守护进程，时刻检查主服务的状态，如果挂了，就把从服务改成主服务。而客户端都从 sentinel 给的 ip 读写，不用理会服务有没有挂。\n\n一般我们会设置主-从-从，即第二个从服务从第一个从服务同步数据。这样的结构，即保证了主挂掉后还有一个从分担压力，又不会因为一主二从，增加主服务的同步压力。\n\n# 配置服务\n## 配置 redis\n```sh\n$ redis-server --port 30001 --cluster-node-timeout 2000 --appendonly yes --appendfilename appendonly-30001.aof --dbfilename dump-30001.rdb --logfile 30001.log --daemonize yes\n$ redis-server --port 30002 --cluster-node-timeout 2000 --appendonly yes --appendfilename appendonly-30002.aof --dbfilename dump-30002.rdb --logfile 30002.log --daemonize yes --slaveof 127.0.0.1:30001\n```\n\n## 配置 sentinal\n```sh\n# Sentinel节点的端口\nport 30007\nlogfile \"30007.log\"\n\n# 当前Sentinel节点监控 127.0.0.1:30001 这个主节点\n# 2代表判断主节点失败至少需要2个Sentinel节点节点同意\n# mymaster是主节点的别名\nsentinel monitor mymaster 127.0.0.1 30001 2\n\n# 每个Sentinel节点都要定期PING命令来判断Redis数据节点和其余Sentinel节点是否可达，如果超过30000毫秒且没有回复，则判定不可达\nsentinel down-after-milliseconds mymaster 30000\n\n# 当Sentinel节点集合对主节点故障判定达成一致时，Sentinel领导者节点会做故障转移操作，选出新的主节点，原来的从节点会向新的主节点发起复制操作，限制每次向新的主节点发起复制操作的从节点个数为1\nsentinel parallel-syncs mymaster 1\n\n# 故障转移超时时间为180000毫秒\nsentinel failover-timeout mymaster 180000\n```\n\n## 启动\n有两种方法\n```sh\nredis-sentinel sentinel-30007.conf\nredis-server sentinel-30007.conf\n```\n改一下端口，其他不变启动 30008, 30009 两台，sentinel 彼此会自动发现对方\n\n## 确认\n```sh\n$ redis-cli -p 30007 info sentinel\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=127.0.0.1:30001,slaves=1,sentinels=3 # sentinel=3 表示 sentinel 已经彼此发现\n```\n\n现在杀死主\n```sh\n$ ps aux | grep redis\nsimon            56248   0.3  0.0  4309624   2028   ??  Ss    8:50下午   0:00.56 ../../src/redis-sentinel *:30008 [sentinel]\nsimon            56250   0.3  0.0  4309624   2068   ??  Ss    8:50下午   0:00.56 ../../src/redis-sentinel *:30009 [sentinel]\nsimon            56203   0.2  0.0  4309624   2004   ??  Ss    8:46下午   0:01.04 ../../src/redis-sentinel *:30007 [sentinel]\nsimon            55341   0.1  0.0  4310648    988   ??  Ss    4:23下午   0:08.04 ../../src/redis-server *:30001\nsimon            55344   0.1  0.0  4310648   1008   ??  Ss    4:24下午   0:08.10 ../../src/redis-server *:30002\n\n$ kill 55341\n\n$ redis-cli -p 30007 info sentinel\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=127.0.0.1:30002,slaves=1,sentinels=3\n```\n此时的 master 地址已经变为 127.0.0.1:30002。\n\n## 查看主从状态\nredis 客户端连上 sentinel 后有\n```sh\ninfo sentinel\nsentinel masters\nsentinel slaves mymaster\n```\n三个常用的命令查看主从状态\n\n# 我踩到的坑\n昨天配置了 redis sentinel 的主从切换，无论如何都无法成功，网上也都不到原因。\n\n后来观察 sentinel 是正常工作的，可是服务器之间只传递 sdown 没有传递 odown，于是用这个搜到了。原来 sentinel 有 protected mode，要在配置里添加 bind 0.0.0.0。改完了之后终于切换成功了。\n\n这个东西弄了我有10小时吧，配置模版里提都没提，真是大坑。\n\n\n-----------------------------\n参考资料：  \n官方文档 https://redis.io/topics/sentinel  \nRedis Sentinel 介绍与部署 https://blog.csdn.net/men_wen/article/details/72724406","tags":["redis"]},{"title":"用人话教你设计模式","url":"/posts/1528164421/","content":"![Design Patterns For Humans](https://cloud.githubusercontent.com/assets/11269635/23065273/1b7e5938-f515-11e6-8dd3-d0d58de6bb9a.png)\n\n***\n<p align=\"center\">\n🎉 对设计模式的极简说明！🎉\n</p>\n<p align=\"center\">\n这个话题可以轻易让任何人糊涂。现在我尝试通过用<i>最简单</i>的方式说明它们，来让你（和我）把他们吃透。\n</p>\n***\n\n🚀 简介\n=================\n\n设计模式用来解决重复的问题；**是解决特定问题的指导方针**。它们不是类(class)，包(packages)，或者库(libraries)，你不能引入它们，然后等待奇迹发生。它们是针对解决特定环境下特定问题的指导方针。\n\n> 设计模式用来解决重复的问题；是解决特定问题的指导方针\n\n维基百科的解释\n\n> In software engineering, a software design pattern is a general reusable solution to a commonly occurring problem within a given context in software design. It is not a finished design that can be transformed directly into source or machine code. It is a description or template for how to solve a problem that can be used in many different situations.\n\n⚠️ 请注意\n-----------------\n- 设计模式不是解决你所有问题的银弹。\n- 不要尝试强行使用它们；如果做了，不好的事情可能发生。请记住设计模式是**解决**问题的方案，不是**发现**问题；所以不要过度思考。\n- 如果在正确的地方以正确的方式使用，它们被证明是有帮助的；否则结果可能是一堆可怕混乱的代码。\n\n> 下面的代码示例使用 PHP-7 书写，但你不应止步于此，因为理念是相通的。再加上,**对其他语言的支持正在路上**。\n\n设计模式的种类\n-----------------\n\n* [创建型](#创建型模式)\n* [结构型](#结构型模式)\n* [行为型](#行为型模式)\n\n创建型模式\n==========================\n\n白话\n> 创建型模式侧重如何实例化一个对象或一组相关对象。\n\n维基百科\n> In software engineering, creational design patterns are design patterns that deal with object creation mechanisms, trying to create objects in a manner suitable to the situation. The basic form of object creation could result in design problems or added complexity to the design. Creational design patterns solve this problem by somehow controlling this object creation.\n \n * [简单工厂模式 Simple Factory](#-简单工厂模式)\n * [工厂方法模式 Factory Method](#-工厂方法模式)\n * [抽象工厂模式 Abstract Factory](#-抽象工厂模式)\n * [建造者模式 Builder](#-建造者模式)\n * [原型模式 Prototype](#-原型模式)\n * [单例模式 Singleton](#-单例模式)\n \n🏠 简单工厂模式\n--------------\n现实例子\n> 假设，你正在建造一所房子，你需要门。如果每次你需要一扇门你都要穿上木工服开始在房子里造扇门，将会是一团乱。取而代之的是让工厂造好。\n\n白话\n> 简单工厂模式在不暴露生成逻辑的前提下生成一个实例。\n\n维基百科\n> In object-oriented programming (OOP), a factory is an object for creating other objects – formally a factory is a function or method that returns objects of a varying prototype or class from some method call, which is assumed to be \"new\".\n\n**代码例子**\n\n首先，我们有一个门的接口和实现\n```php\ninterface Door {\n    public function getWidth() : float;\n    public function getHeight() : float;\n}\n\nclass WoodenDoor implements Door {\n    protected $width;\n    protected $height;\n\n    public function __construct(float $width, float $height) {\n        $this->width = $width;\n        $this->height = $height;\n    }\n    \n    public function getWidth() : float {\n        return $this->width;\n    }\n    \n    public function getHeight() : float {\n        return $this->height;\n    }\n}\n```\n然后，我们有了工厂来制造和返回门\n```php\nclass DoorFactory {\n   public static function makeDoor($width, $height) : Door {\n       return new WoodenDoor($width, $height);\n   }\n}\n```\n然后这样使用\n```php\n$door = DoorFactory::makeDoor(100, 200);\necho 'Width: ' . $door->getWidth();\necho 'Height: ' . $door->getHeight();\n```\n\n**什么时候使用？**\n\n当创建一个对象不只是几个赋值和逻辑计算，把这件工作交给一个工厂而不是到处重复相同的代码就比较合适了。\n\n🏭 工厂方法模式\n--------------\n\n现实例子\n> 设想一个人事经理。一个人是不可能面试所有职位的。基于职位空缺，她必须把面试委托给不同的人。\n\n白话\n> 它提供了一个把生成逻辑移交给子类的方法。\n\n维基百科\n> In class-based programming, the factory method pattern is a creational pattern that uses factory methods to deal with the problem of creating objects without having to specify the exact class of the object that will be created. This is done by creating objects by calling a factory method—either specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classes—rather than by calling a constructor.\n \n **代码例子**\n \n以上面的人事经理为例。首先我们有一个面试官接口和一些实现\n\n```php\ninterface Interviewer {\n    public function askQuestions();\n}\n\nclass Developer implements Interviewer {\n    public function askQuestions() {\n        echo 'Asking about design patterns!';\n    }\n}\n\nclass CommunityExecutive implements Interviewer {\n    public function askQuestions() {\n        echo 'Asking about community building';\n    }\n}\n```\n\n现在我们新建我们的人事经理 `HiringManager`\n\n```php\nabstract class HiringManager {\n    \n    // Factory method\n    abstract public function makeInterviewer() : Interviewer;\n    \n    public function takeInterview() {\n        $interviewer = $this->makeInterviewer();\n        $interviewer->askQuestions();\n    }\n}\n```\n现在任何一个都可以继承它，并且生成需要的面试官\n```php\nclass DevelopmentManager extends HiringManager {\n    public function makeInterviewer() : Interviewer {\n        return new Developer();\n    }\n}\n\nclass MarketingManager extends HiringManager {\n    public function makeInterviewer() : Interviewer {\n        return new CommunityExecutive();\n    }\n}\n```\n然后可以这样使用\n\n```php\n$devManager = new DevelopmentManager();\n$devManager->takeInterview(); // Output: Asking about design patterns\n\n$marketingManager = new MarketingManager();\n$marketingManager->takeInterview(); // Output: Asking about community building.\n```\n\n**何时使用？**\n\n当一个类里有普遍性的处理过程，但是子类要在运行时才确定。或者换句话说，调用者不知道它需要哪个子类。\n\n🔨 抽象工厂模式\n----------------\n\n现实例子\n> 扩展我们简单工厂模式的例子。基于你的需求，你可以从木门店得到一扇木门，从铁门店得到一扇铁门，或者从塑料门店得到一扇塑料门。而且你需要一个有不同专长的人来安装这扇门，比如一个木匠来安木门，焊工来安铁门等。正如你看的，门和安装工有依赖性，木门需要木匠，铁门需要焊工等。\n\n白话\n> 一个制造工厂的工厂；一个工厂把独立但是相关／有依赖性的工厂进行分类，但是不需要给出具体的类。\n  \n维基百科\n> The abstract factory pattern provides a way to encapsulate a group of individual factories that have a common theme without specifying their concrete classes\n\n**代码例子**\n\n翻译上面门的例子。首先我们有了门 `Door` 的接口和一些实现\n\n```php\ninterface Door {\n    public function getDescription();\n}\n\nclass WoodenDoor implements Door {\n    public function getDescription() {\n        echo 'I am a wooden door';\n    }\n}\n\nclass IronDoor implements Door {\n    public function getDescription() {\n        echo 'I am an iron door';\n    }\n}\n```\n然后我们有了每种门的安装专家\n\n```php\ninterface DoorFittingExpert {\n    public function getDescription();\n}\n\nclass Welder implements DoorFittingExpert {\n    public function getDescription() {\n        echo 'I can only fit iron doors';\n    }\n}\n\nclass Carpenter implements DoorFittingExpert {\n    public function getDescription() {\n        echo 'I can only fit wooden doors';\n    }\n}\n```\n\n现在我们有了抽象工厂来创建全部相关的对象，即木门工厂制造木门和木门安装专家，铁门工厂制造铁门和铁门安装专家\n```php\ninterface DoorFactory {\n    public function makeDoor() : Door;\n    public function makeFittingExpert() : DoorFittingExpert;\n}\n\n// 木头工厂返回木门和木匠\nclass WoodenDoorFactory implements DoorFactory {\n    public function makeDoor() : Door {\n        return new WoodenDoor();\n    }\n\n    public function makeFittingExpert() : DoorFittingExpert{\n        return new Carpenter();\n    }\n}\n\n// 铁门工厂返回铁门和对应安装专家\nclass IronDoorFactory implements DoorFactory {\n    public function makeDoor() : Door {\n        return new IronDoor();\n    }\n\n    public function makeFittingExpert() : DoorFittingExpert{\n        return new Welder();\n    }\n}\n```\n然后可以这样使用\n```php\n$woodenFactory = new WoodenDoorFactory();\n\n$door = $woodenFactory->makeDoor();\n$expert = $woodenFactory->makeFittingExpert();\n\n$door->getDescription();  // 输出: I am a wooden door\n$expert->getDescription(); // 输出: I can only fit wooden doors\n\n// 铁门工厂也一样\n$ironFactory = new IronDoorFactory();\n\n$door = $ironFactory->makeDoor();\n$expert = $ironFactory->makeFittingExpert();\n\n$door->getDescription();  // 输出: I am an iron door\n$expert->getDescription(); // 输出: I can only fit iron doors\n```\n\n如你所见，木门工厂包含了木匠 `carpenter` 和木门 `wooden door` 而铁门工厂包含了铁门 `iron door` 和焊工 `welder`。因此我们可以确保每扇制造出来的门不会带上错误的安装工。\n\n**何时使用？**\n\n当创建逻辑不那么简单，而且相互之间有依赖时\n\n👷 建造者模式\n--------------------------------------------\n现实例子\n> 想象你在麦当劳，你要一个“巨无霸”，他们马上就给你了，没有疑问，这是简单工厂的逻辑。但如果创建逻辑包含更多步骤。比如你想要一个自定义赛百味套餐，你有多种选择来制作汉堡，例如你要哪种面包？你要哪种调味酱？你要哪种奶酪？等。这种情况就需要建造者模式来处理。\n\n白话\n> 让你能创建不同特点的对象而避免构造函数污染。当一个对象都多种特点的时候比较实用。或者在创造逻辑里有许多步骤的时候。\n \n维基百科\n> The builder pattern is an object creation software design pattern with the intentions of finding a solution to the telescoping constructor anti-pattern.\n\n话虽如此，让我写一点关于伸缩构造函数反面模式。在某些时候，我们都看过下面这样的构造函数\n \n```php\npublic function __construct($size, $cheese = true, $pepperoni = true, $tomato = false, $lettuce = true) {\n}\n```\n\n如你所见；构造函数参数的数量马上就要失去控制，而且梳理参数也会变得困难。而且如果你将来想要增加更多选项，参数也会继续增加。这就叫做伸缩构造函数反面模式。\n\n**代码例子**\n\n正常的做法是使用创建者模式。首先我们有了要做的汉堡\n\n```php\nclass Burger {\n    protected $size;\n\n    protected $cheese = false;\n    protected $pepperoni = false;\n    protected $lettuce = false;\n    protected $tomato = false;\n    \n    public function __construct(BurgerBuilder $builder) {\n        $this->size = $builder->size;\n        $this->cheese = $builder->cheese;\n        $this->pepperoni = $builder->pepperoni;\n        $this->lettuce = $builder->lettuce;\n        $this->tomato = $builder->tomato;\n    }\n}\n```\n\n然后我们有了制作者\n\n```php\nclass BurgerBuilder {\n    public $size;\n\n    public $cheese = false;\n    public $pepperoni = false;\n    public $lettuce = false;\n    public $tomato = false;\n\n    public function __construct(int $size) {\n        $this->size = $size;\n    }\n    \n    public function addPepperoni() {\n        $this->pepperoni = true;\n        return $this;\n    }\n    \n    public function addLettuce() {\n        $this->lettuce = true;\n        return $this;\n    }\n    \n    public function addCheese() {\n        $this->cheese = true;\n        return $this;\n    }\n    \n    public function addTomato() {\n        $this->tomato = true;\n        return $this;\n    }\n    \n    public function build() : Burger {\n        return new Burger($this);\n    }\n}\n```\n然后可以这样使用\n\n```php\n$burger = (new BurgerBuilder(14))\n                    ->addPepperoni()\n                    ->addLettuce()\n                    ->addTomato()\n                    ->build();\n```\n\n**何时使用？**\n\n当对象有多种特性而要避免构造函数变长。和工厂模式的核心区别是；当创建过程只有一个步骤的时候使用工厂模式，而当创建过程有多个步骤的时候使用创造者模式。\n\n🐑 原型模式\n------------\n现实例子\n> 记得多利吗？那只克隆羊！不要在意细节，现在的重点是克隆\n\n白话\n> 通过克隆已有的对象来创建新对象。\n\n维基百科\n> The prototype pattern is a creational design pattern in software development. It is used when the type of objects to create is determined by a prototypical instance, which is cloned to produce new objects.\n\n长话短说，它让你创建已有对象的拷贝，然后修改到你要的样子，而不是从头开始建造。\n\n**代码例子**\n\n在 PHP 里，简单的使用 `clone` 就可以了\n  \n```php\nclass Sheep {\n    protected $name;\n    protected $category;\n\n    public function __construct(string $name, string $category = 'Mountain Sheep') {\n        $this->name = $name;\n        $this->category = $category;\n    }\n    \n    public function setName(string $name) {\n        $this->name = $name;\n    }\n\n    public function getName() {\n        return $this->name;\n    }\n\n    public function setCategory(string $category) {\n        $this->category = $category;\n    }\n\n    public function getCategory() {\n        return $this->category;\n    }\n}\n```\n然后它可以被这样克隆\n```php\n$original = new Sheep('Jolly');\necho $original->getName(); // Jolly\necho $original->getCategory(); // Mountain Sheep\n\n// Clone and modify what is required\n$cloned = clone $original;\n$cloned->setName('Dolly');\necho $cloned->getName(); // Dolly\necho $cloned->getCategory(); // Mountain sheep\n```\n\n你也可以使用魔法方法 `__clone` 来改变克隆逻辑。\n\n**何时使用？**\n\n当一个对象需要跟已有的对象相似，或者当创造过程比起克隆来太昂贵时。\n\n💍 单例模式\n------------\n现实例子\n> 一个国家同一时间只能有一个总统。当使命召唤的时候，这个总统要采取行动。这里的总统就是单例的。\n\n白话\n> 确保指定的类只生成一个对象。\n\n维基百科\n> In software engineering, the singleton pattern is a software design pattern that restricts the instantiation of a class to one object. This is useful when exactly one object is needed to coordinate actions across the system.\n\n单例模式其实被看作一种反面模式，应该避免过度使用。它不一定不好，而且确有一些有效的用例，但是应该谨慎使用，因为它在你的应用里引入了全局状态，在一个地方改变，会影响其他地方。而且很难 debug 。另一个坏处是它让你的代码紧耦合，而且很难仿制单例。\n\n**代码例子**\n\n要创建一个单例，先让构造函数私有，不能克隆，不能继承，然后创造一个静态变量来保存这个实例\n```php\nfinal class President {\n    private static $instance;\n\n    private function __construct() {\n        // Hide the constructor\n    }\n    \n    public static function getInstance() : President {\n        if (!self::$instance) {\n            self::$instance = new self();\n        }\n        \n        return self::$instance;\n    }\n    \n    private function __clone() {\n        // Disable cloning\n    }\n    \n    private function __wakeup() {\n        // Disable unserialize\n    }\n}\n```\n然后要使用的话\n```php\n$president1 = President::getInstance();\n$president2 = President::getInstance();\n\nvar_dump($president1 === $president2); // true\n```\n\n结构型模式\n==========================\n白话\n> 结构型模式更关注对象的组合，换句话说，实体如何彼此使用。或者说，它们帮助解答“如何建造软件组件？”\n\n维基百科\n> In software engineering, structural design patterns are design patterns that ease the design by identifying a simple way to realize relationships between entities.\n  \n * [适配器模式 Adapter](#-适配器模式)\n * [桥接模式 Bridge](#-桥接模式)\n * [组合模式 Composite](#-组合模式)\n * [装饰器模式 Decorator](#-装饰器模式)\n * [门面模式 Facade](#-门面模式)\n * [享元模式 Flyweight](#-享元模式)\n * [代理模式 Proxy](#-代理模式)\n\n🔌 适配器模式\n-------\n现实例子\n> 假设在你的存储卡里有一些照片，你要把它们传到电脑。为了传输，你需要一个兼容电脑端口的适配器来连接存储卡和电脑。在这里，读卡器就是一个适配器。\n> 另一个例子是电源转换器；一个三脚的插口不能插到两口的插座上，它需要一个电源转换器来兼容两口的插座。\n> 还有一个例子是翻译将一个人说的话翻译给另一个人。\n\n白话\n> 适配器模式让你封装一个不兼容的对象到一个适配器，来兼容其他类。\n\n维基百科\n> In software engineering, the adapter pattern is a software design pattern that allows the interface of an existing class to be used as another interface. It is often used to make existing classes work with others without modifying their source code.\n\n**代码例子**\n\n假设一个猎人狩猎狮子的游戏。\n\n首先我们有了一个接口狮子 `Lion` 来实现所有种类的狮子\n\n```php\ninterface Lion {\n    public function roar();\n}\n\nclass AfricanLion implements Lion {\n    public function roar() {}\n}\n\nclass AsianLion implements Lion {\n    public function roar() {}\n}\n```\n以及猎人需要狩猎任何狮子 `Lion` 接口的实现。\n```php\nclass Hunter {\n    public function hunt(Lion $lion) {\n    }\n}\n```\n\n现在我们不得不在游戏里加一个野狗 `WildDog` ，猎人也能狩猎它。但是我们不能直接这么做，因为狗有不同的接口。为了兼容我们的猎人，我们不得不创建一个兼容的适配器\n \n```php\n// This needs to be added to the game\nclass WildDog {\n    public function bark() {}\n}\n\n// Adapter around wild dog to make it compatible with our game\nclass WildDogAdapter implements Lion {\n    protected $dog;\n\n    public function __construct(WildDog $dog) {\n        $this->dog = $dog;\n    }\n    \n    public function roar() {\n        $this->dog->bark();\n    }\n}\n```\n现在野狗 `WildDog` 可以在游戏里使用了，通过野狗适配器 `WildDogAdapter`.\n\n```php\n$wildDog = new WildDog();\n$wildDogAdapter = new WildDogAdapter($wildDog);\n\n$hunter = new Hunter();\n$hunter->hunt($wildDogAdapter);\n```\n\n🚡 桥接模式\n------\n现实例子\n> 假设你有一个包含很多网页的网站，你想要用户可以改变主题。你会怎么做？创建每个页面对应每个主题的拷备，还是只是创建不同的主题，然后根据用户的喜好来加载它们？桥接模式让你能做到后者。\n\n![With and without the bridge pattern](https://cloud.githubusercontent.com/assets/11269635/23065293/33b7aea0-f515-11e6-983f-98823c9845ee.png)\n\n白话\n> 桥接模式倾向构造而非继承。实现细节被从一个层推送到另一个对象的另一层。\n\n维基百科\n> The bridge pattern is a design pattern used in software engineering that is meant to \"decouple an abstraction from its implementation so that the two can vary independently\"\n\n**代码例子**\n\n翻译我们上面的网页例子。这里是网页 `WebPage` 层\n\n```php\ninterface WebPage {\n    public function __construct(Theme $theme);\n    public function getContent();\n}\n\nclass About implements WebPage {\n    protected $theme;\n    \n    public function __construct(Theme $theme) {\n        $this->theme = $theme;\n    }\n    \n    public function getContent() {\n        return \"About page in \" . $this->theme->getColor();\n    }\n}\n\nclass Careers implements WebPage {\n   protected $theme;\n   \n   public function __construct(Theme $theme) {\n       $this->theme = $theme;\n   }\n   \n   public function getContent() {\n       return \"Careers page in \" . $this->theme->getColor();\n   } \n}\n```\n以及主题层\n```php\ninterface Theme {\n    public function getColor();\n}\n\nclass DarkTheme implements Theme {\n    public function getColor() {\n        return 'Dark Black';\n    }\n}\nclass LightTheme implements Theme {\n    public function getColor() {\n        return 'Off white';\n    }\n}\nclass AquaTheme implements Theme {\n    public function getColor() {\n        return 'Light blue';\n    }\n}\n```\n两个层的互动\n```php\n$darkTheme = new DarkTheme();\n\n$about = new About($darkTheme);\n$careers = new Careers($darkTheme);\n\necho $about->getContent(); // \"About page in Dark Black\";\necho $careers->getContent(); // \"Careers page in Dark Black\";\n```\n\n🌿 组合模式\n-----------------\n\n现实例子\n> 任何组织都是由员工组成。每个员工都有相同的特征，即一笔薪水，一些责任，可能需要向别人汇报，可能有一些下属等。\n\n白话\n> 组合模式让调用者可以用统一的模式对待不同的对象。\n\n维基百科\n> In software engineering, the composite pattern is a partitioning design pattern. The composite pattern describes that a group of objects is to be treated in the same way as a single instance of an object. The intent of a composite is to \"compose\" objects into tree structures to represent part-whole hierarchies. Implementing the composite pattern lets clients treat individual objects and compositions uniformly.\n\n**代码例子**\n\n拿上面的员工为例。下面是不同的员工类型\n\n```php\n\ninterface Employee {\n    public function __construct(string $name, float $salary);\n    public function getName() : string;\n    public function setSalary(float $salary);\n    public function getSalary() : float;\n    public function getRoles()  : array;\n}\n\nclass Developer implements Employee {\n\n    protected $salary;\n    protected $name;\n\n    public function __construct(string $name, float $salary) {\n        $this->name = $name;\n        $this->salary = $salary;\n    }\n\n    public function getName() : string {\n        return $this->name;\n    }\n\n    public function setSalary(float $salary) {\n        $this->salary = $salary;\n    }\n\n    public function getSalary() : float {\n        return $this->salary;\n    }\n\n    public function getRoles() : array {\n        return $this->roles;\n    }\n}\n\nclass Designer implements Employee {\n\n    protected $salary;\n    protected $name;\n\n    public function __construct(string $name, float $salary) {\n        $this->name = $name;\n        $this->salary = $salary;\n    }\n\n    public function getName() : string {\n        return $this->name;\n    }\n\n    public function setSalary(float $salary) {\n        $this->salary = $salary;\n    }\n\n    public function getSalary() : float {\n        return $this->salary;\n    }\n\n    public function getRoles() : array {\n        return $this->roles;\n    }\n}\n```\n\n下面是一个由不同类型员工组成的组织\n\n```php\nclass Organization {\n    \n    protected $employees;\n\n    public function addEmployee(Employee $employee) {\n        $this->employees[] = $employee;\n    }\n\n    public function getNetSalaries() : float {\n        $netSalary = 0;\n\n        foreach ($this->employees as $employee) {\n            $netSalary += $employee->getSalary();\n        }\n\n        return $netSalary;\n    }\n}\n```\n\n然后可以这样使用\n\n```php\n// 准备员工\n$john = new Developer('John Doe', 12000);\n$jane = new Designer('Jane', 10000);\n\n// 把他们加到组织里去\n$organization = new Organization();\n$organization->addEmployee($john);\n$organization->addEmployee($jane);\n\necho \"Net salaries: \" . $organization->getNetSalaries(); // Net Salaries: 22000\n```\n\n☕ 装饰器模式\n-------------\n\n现实例子\n\n> 想象你开一家汽车服务店，提供各种服务。现在你怎么计算收费？你选择一个服务，然后不断把价格加到已选服务的价格里，直到得到总价。这里，每种服务就是一个装饰器。\n\n白话\n> 装饰器模式让你能在运行时动态地改变一个对象的表现，通过把它们封装到一个装饰器类。\n\n维基百科\n> In object-oriented programming, the decorator pattern is a design pattern that allows behavior to be added to an individual object, either statically or dynamically, without affecting the behavior of other objects from the same class. The decorator pattern is often useful for adhering to the Single Responsibility Principle, as it allows functionality to be divided between classes with unique areas of concern.\n\n**代码例子**\n\n让我们以咖啡为例。首先我们有一个咖啡接口的简单实现\n\n```php\ninterface Coffee {\n    public function getCost();\n    public function getDescription();\n}\n\nclass SimpleCoffee implements Coffee {\n\n    public function getCost() {\n        return 10;\n    }\n\n    public function getDescription() {\n        return 'Simple coffee';\n    }\n}\n```\n我们想要让代码可扩展，以在需要的时候改变选项。让我们增加一些扩展（装饰器）\n```php\nclass MilkCoffee implements Coffee {\n    \n    protected $coffee;\n\n    public function __construct(Coffee $coffee) {\n        $this->coffee = $coffee;\n    }\n\n    public function getCost() {\n        return $this->coffee->getCost() + 2;\n    }\n\n    public function getDescription() {\n        return $this->coffee->getDescription() . ', milk';\n    }\n}\n\nclass WhipCoffee implements Coffee {\n\n    protected $coffee;\n\n    public function __construct(Coffee $coffee) {\n        $this->coffee = $coffee;\n    }\n\n    public function getCost() {\n        return $this->coffee->getCost() + 5;\n    }\n\n    public function getDescription() {\n        return $this->coffee->getDescription() . ', whip';\n    }\n}\n\nclass VanillaCoffee implements Coffee {\n\n    protected $coffee;\n\n    public function __construct(Coffee $coffee) {\n        $this->coffee = $coffee;\n    }\n\n    public function getCost() {\n        return $this->coffee->getCost() + 3;\n    }\n\n    public function getDescription() {\n        return $this->coffee->getDescription() . ', vanilla';\n    }\n}\n\n```\n\n现在让我们生成咖啡\n\n```php\n$someCoffee = new SimpleCoffee();\necho $someCoffee->getCost(); // 10\necho $someCoffee->getDescription(); // Simple Coffee\n\n$someCoffee = new MilkCoffee($someCoffee);\necho $someCoffee->getCost(); // 12\necho $someCoffee->getDescription(); // Simple Coffee, milk\n\n$someCoffee = new WhipCoffee($someCoffee);\necho $someCoffee->getCost(); // 17\necho $someCoffee->getDescription(); // Simple Coffee, milk, whip\n\n$someCoffee = new VanillaCoffee($someCoffee);\necho $someCoffee->getCost(); // 20\necho $someCoffee->getDescription(); // Simple Coffee, milk, whip, vanilla\n```\n\n📦 门面模式\n----------------\n\n现实例子\n> 你怎么打开电脑？你会说“按电源键”！你这么认为是因为你在用电脑外部提供的简单接口，而在内部，它必须做很做工作来实现这件事。这个复杂子系统的简单接口就是一个门面。\n\n白话\n> 门面模式提供了一个复杂子系统的简单接口。\n\n维基百科\n> A facade is an object that provides a simplified interface to a larger body of code, such as a class library.\n\n**代码例子**\n\n拿上面电脑为例。下面是电脑类\n\n```php\nclass Computer {\n\n    public function getElectricShock() {\n        echo \"Ouch!\";\n    }\n\n    public function makeSound() {\n        echo \"Beep beep!\";\n    }\n\n    public function showLoadingScreen() {\n        echo \"Loading..\";\n    }\n\n    public function bam() {\n        echo \"Ready to be used!\";\n    }\n\n    public function closeEverything() {\n        echo \"Bup bup bup buzzzz!\";\n    }\n\n    public function sooth() {\n        echo \"Zzzzz\";\n    }\n\n    public function pullCurrent() {\n        echo \"Haaah!\";\n    }\n}\n```\n下面是门面\n```php\nclass ComputerFacade\n{\n    protected $computer;\n\n    public function __construct(Computer $computer) {\n        $this->computer = $computer;\n    }\n\n    public function turnOn() {\n        $this->computer->getElectricShock();\n        $this->computer->makeSound();\n        $this->computer->showLoadingScreen();\n        $this->computer->bam();\n    }\n\n    public function turnOff() {\n        $this->computer->closeEverything();\n        $this->computer->pullCurrent();\n        $this->computer->sooth();\n    }\n}\n```\n如何使用门面\n```php\n$computer = new ComputerFacade(new Computer());\n$computer->turnOn(); // Ouch! Beep beep! Loading.. Ready to be used!\n$computer->turnOff(); // Bup bup buzzz! Haah! Zzzzz\n```\n\n🍃 享元模式\n---------\n\n现实例子\n> 你在小店里喝过茶吗？他们经常比你要的多做几杯，把剩下的留给别的客人，以此来省资源，比如煤气。享元模式就是以上的体现，即分享。\n\n白话\n> 通过尽可能分享相似的对象，来将内存使用或计算开销降到最低。\n\n维基百科\n> In computer programming, flyweight is a software design pattern. A flyweight is an object that minimizes memory use by sharing as much data as possible with other similar objects; it is a way to use objects in large numbers when a simple repeated representation would use an unacceptable amount of memory.\n\n**代码例子**\n\n翻译上面的茶的例子。首先我们有了茶的类型和生成器\n\n```php\n// 任何被缓存的东西都被叫做享元。 \n// 这里茶的类型就是享元。\nclass KarakTea {\n}\n\n// 像工厂一样工作，保存茶\nclass TeaMaker {\n    protected $availableTea = [];\n\n    public function make($preference) {\n        if (empty($this->availableTea[$preference])) {\n            $this->availableTea[$preference] = new KarakTea();\n        }\n\n        return $this->availableTea[$preference];\n    }\n}\n```\n\n下面是我们的茶吧 `TeaShop` ，接单和提供服务\n\n```php\nclass TeaShop {\n    \n    protected $orders;\n    protected $teaMaker;\n\n    public function __construct(TeaMaker $teaMaker) {\n        $this->teaMaker = $teaMaker;\n    }\n\n    public function takeOrder(string $teaType, int $table) {\n        $this->orders[$table] = $this->teaMaker->make($teaType);\n    }\n\n    public function serve() {\n        foreach($this->orders as $table => $tea) {\n            echo \"Serving tea to table# \" . $table;\n        }\n    }\n}\n```\n然后可以这样使用\n\n```php\n$teaMaker = new TeaMaker();\n$shop = new TeaShop($teaMaker);\n\n$shop->takeOrder('less sugar', 1);\n$shop->takeOrder('more milk', 2);\n$shop->takeOrder('without sugar', 5);\n\n$shop->serve();\n// Serving tea to table# 1\n// Serving tea to table# 2\n// Serving tea to table# 5\n```\n\n🎱 代理模式\n-------------------\n现实例子\n> 你有没有用过门卡来通过一扇门？有多种方式来打开那扇门，即它可以被门卡打开，或者按开门按钮打开。这扇门的主要功能是开关，但在顶层增加了一个代理来增加其他功能。下面的例子能更好的说明。\n\n白话\n> 使用代理模式，一个类表现出了另一个类的功能。\n\n维基百科\n> A proxy, in its most general form, is a class functioning as an interface to something else. A proxy is a wrapper or agent object that is being called by the client to access the real serving object behind the scenes. Use of the proxy can simply be forwarding to the real object, or can provide additional logic. In the proxy extra functionality can be provided, for example caching when operations on the real object are resource intensive, or checking preconditions before operations on the real object are invoked.\n\n**代码例子**\n\n拿上面安全门为例。首先我们有了门的接口和实现\n\n```php\ninterface Door {\n    public function open();\n    public function close();\n}\n\nclass LabDoor implements Door {\n    public function open() {\n        echo \"Opening lab door\";\n    }\n\n    public function close() {\n        echo \"Closing the lab door\";\n    }\n}\n```\n然后下面是一个代理来安保任何我们要的门\n```php\nclass Security {\n    protected $door;\n\n    public function __construct(Door $door) {\n        $this->door = $door;\n    }\n\n    public function open($password) {\n        if ($this->authenticate($password)) {\n            $this->door->open();\n        } else {\n        \techo \"Big no! It ain't possible.\";\n        }\n    }\n\n    public function authenticate($password) {\n        return $password === '$ecr@t';\n    }\n\n    public function close() {\n        $this->door->close();\n    }\n}\n```\n然后可以这样使用\n```php\n$door = new Security(new LabDoor());\n$door->open('invalid'); // Big no! It ain't possible.\n\n$door->open('$ecr@t'); // Opening lab door\n$door->close(); // Closing lab door\n```\n另一个例子是一些数据映射的实现。比如，我最近用这个模式给 MongoDB 做了一个数据映射器 ODM (Object Data Mapper)，我用魔术方法 `__call()` 给 mongo 类做了一个代理。所有执行的方法都被代理到原始的 mongo 类，返回收到的结果。但是在 `find` 或 `findOne` 的情况，数据被映射到对应的对象，这个对象会被返回，而不是 `Cursor`。\n\n行为型模式\n==========================\n\n白话\n> 它关注对象间的责任分配。它们和结构型模式的区别是它们不止明确指明结构，而且指出了它们之间传递/交流的信息的形式。或者换句或说，它们帮助回答了“如何确定软件组件的行为？”\n\n维基百科\n> In software engineering, behavioral design patterns are design patterns that identify common communication patterns between objects and realize these patterns. By doing so, these patterns increase flexibility in carrying out this communication.\n\n* [责任链模式 Chain of Responsibility](#-责任链模式)\n* [命令模式 Command](#-命令模式)\n* [迭代器模式 Iterator](#-迭代器模式)\n* [中介模式 Mediator](#-中介模式)\n* [备忘录模式 Memento](#-备忘录模式)\n* [观察者模式 Observer](#-观察者模式)\n* [访问者模式 Visitor](#-访问者模式)\n* [策略模式 Strategy](#-策略模式)\n* [状态模式 State](#-状态模式)\n* [模板模式 Template Method](#-模板模式)\n\n🔗 责任链模式\n-----------------------\n\n现实例子\n> 比如，有三个支付方式 (`A`, `B` 和 `C`) 安装在你的账户里；每种方式都有不同额度。`A` 有 100 元， `B` 有 300 元，以及 `C` 有 1000 元，选择支付方式的顺序是 `A` 然后 `B` 然后 `C`。你要买一些价值 210 元的东西。使用责任链模式，首先账户 `A` 会被检查是否能够支付，如果是，支付会被执行而链子终止。如果否，请求会转移到账户 `B`，检查额度，如果是，链子终止，否则请求继续转移直到找到合适的执行者。这里 `A`，`B` 和 `C` 是链接里的环节，它们合起来就是责任链。\n\n白话\n> 它构造了一个对象的链。请求进入一端，然后从一个对象到另一个对象直到找到合适的执行者。\n\n维基百科\n> In object-oriented design, the chain-of-responsibility pattern is a design pattern consisting of a source of command objects and a series of processing objects. Each processing object contains logic that defines the types of command objects that it can handle; the rest are passed to the next processing object in the chain.\n\n**代码例子**\n\n翻译上面的账户例子。首先我们有了一个基本账户，包含把账户连接起来的逻辑。以及一些账户\n\n```php\nabstract class Account {\n    protected $successor;\n    protected $balance;\n\n    public function setNext(Account $account) {\n        $this->successor = $account;\n    }\n    \n    public function pay(float $amountToPay) {\n        if ($this->canPay($amountToPay)) {\n            echo sprintf('Paid %s using %s' . PHP_EOL, $amountToPay, get_called_class());\n        } else if ($this->successor) {\n            echo sprintf('Cannot pay using %s. Proceeding ..' . PHP_EOL, get_called_class());\n            $this->successor->pay($amountToPay);\n        } else {\n            throw Exception('None of the accounts have enough balance');\n        }\n    }\n    \n    public function canPay($amount) : bool {\n        return $this->balance >= $amount;\n    }\n}\n\nclass Bank extends Account {\n    protected $balance;\n\n    public function __construct(float $balance) {\n        $this->balance = $balance;\n    }\n}\n\nclass Paypal extends Account {\n    protected $balance;\n\n    public function __construct(float $balance) {\n        $this->balance = $balance;\n    }\n}\n\nclass Bitcoin extends Account {\n    protected $balance;\n\n    public function __construct(float $balance) {\n        $this->balance = $balance;\n    }\n}\n```\n\n现在我们用上面定义的环节（即银行 Bank，贝宝 Paypal，比特币 Bitcoin）准备链\n\n```php\n// 我们准备下面这样的链\n//      $bank->$paypal->$bitcoin\n//\n// 首选银行 bank\n//      如果银行 bank 不能支付则选择贝宝 paypal\n//      如果贝宝 paypal 不能支付则选择比特币 bit coin\n\n$bank = new Bank(100);          // 银行 Bank 有余额 100\n$paypal = new Paypal(200);      // 贝宝 Paypal 有余额 200\n$bitcoin = new Bitcoin(300);    // 比特币 Bitcoin 有余额 300\n\n$bank->setNext($paypal);\n$paypal->setNext($bitcoin);\n\n// 我们尝试用首选项支付，即银行 bank\n$bank->pay(259);\n\n// 输出将会是\n// ==============\n// Cannot pay using bank. Proceeding ..\n// Cannot pay using paypal. Proceeding ..: \n// Paid 259 using Bitcoin!\n```\n\n👮 命令模式\n-------\n\n现实例子\n> 一个普遍的例子是你在餐馆点餐。你 (即调用者 `Client`) 要求服务员 (即调用器 `Invoker`) 端来一些食物 (即命令 `Command`)，而服务员只是简单的把命令传达给知道怎么做菜的厨师 (即接收者 `Receiver`)。另一个例子是你 (即调用者 `Client`) 打开 (即命令 `Command`) 电视 (即接收者 `Receiver`)，通过使用遥控 (调用器 `Invoker`).\n\n白话\n> 允许你封装对象的功能。此模式的核心思想是分离调用者和接收者。\n\n维基百科\n> In object-oriented programming, the command pattern is a behavioral design pattern in which an object is used to encapsulate all information needed to perform an action or trigger an event at a later time. This information includes the method name, the object that owns the method and values for the method parameters.\n\n**代码例子**\n\n首先我们有一个接收者，包含了每一个可执行的功能的实现\n```php\n// Receiver\nclass Bulb {\n    public function turnOn() {\n        echo \"Bulb has been lit\";\n    }\n    \n    public function turnOff() {\n        echo \"Darkness!\";\n    }\n}\n```\n然后下面是每个命令执行的接口，之后我们就有了一个命令的集合\n```php\ninterface Command {\n    public function execute();\n    public function undo();\n    public function redo();\n}\n\n// Command\nclass TurnOn implements Command {\n    protected $bulb;\n    \n    public function __construct(Bulb $bulb) {\n        $this->bulb = $bulb;\n    }\n    \n    public function execute() {\n        $this->bulb->turnOn();\n    }\n    \n    public function undo() {\n        $this->bulb->turnOff();\n    }\n    \n    public function redo() {\n        $this->execute();\n    }\n}\n\nclass TurnOff implements Command {\n    protected $bulb;\n    \n    public function __construct(Bulb $bulb) {\n        $this->bulb = $bulb;\n    }\n    \n    public function execute() {\n        $this->bulb->turnOff();\n    }\n    \n    public function undo() {\n        $this->bulb->turnOn();\n    }\n    \n    public function redo() {\n        $this->execute();\n    }\n}\n```\n然后我们有了一个执行器 `Invoker`，调用者可以通过它执行命令\n```php\n// Invoker\nclass RemoteControl {\n    \n    public function submit(Command $command) {\n        $command->execute();\n    }\n}\n```\n最后我们看看可以如何使用\n```php\n$bulb = new Bulb();\n\n$turnOn = new TurnOn($bulb);\n$turnOff = new TurnOff($bulb);\n\n$remote = new RemoteControl();\n$remote->submit($turnOn); // Bulb has been lit!\n$remote->submit($turnOff); // Darkness!\n```\n\n命令模式也可以用来实现一个基础系统的事务。当你要一直在执行命令后马上维护日志。如果命令被正确执行，一切正常，否则沿日志迭代，一直对每个已执行的命令执行撤销 `undo` 。\n\n➿ 迭代器模式\n--------\n\n现实例子\n> 老式调频收音机是迭代器的好例子，用户可以在一些频道开始，然后使用前进或后退按钮来浏览每个频道。或者以 MP3 播放器或电视机为例，你可以按前进或后退按钮来浏览连续的频道。或者说，它们都提供了迭代连续的频道，歌曲或广播的接口。  \n\n白话\n> 它提供了一种方式来获得对象的元素，而不必暴露底层实现。\n\n维基百科\n> In object-oriented programming, the iterator pattern is a design pattern in which an iterator is used to traverse a container and access the container's elements. The iterator pattern decouples algorithms from containers; in some cases, algorithms are necessarily container-specific and thus cannot be decoupled.\n\n**代码例子**\n\n在 PHP 里，用 SPL (标准 PHP 库) 实现非常简单。翻译上面的广播例子。首先我们有了广播台 `RadioStation`\n\n```php\nclass RadioStation {\n    protected $frequency;\n\n    public function __construct(float $frequency) {\n        $this->frequency = $frequency;    \n    }\n    \n    public function getFrequency() : float {\n        return $this->frequency;\n    }\n}\n```\n下面是我们的迭代器\n\n```php\nuse Countable;\nuse Iterator;\n\nclass StationList implements Countable, Iterator {\n    /** @var RadioStation[] $stations */\n    protected $stations = [];\n    \n    /** @var int $counter */\n    protected $counter;\n    \n    public function addStation(RadioStation $station) {\n        $this->stations[] = $station;\n    }\n    \n    public function removeStation(RadioStation $toRemove) {\n        $toRemoveFrequency = $toRemove->getFrequency();\n        $this->stations = array_filter($this->stations, function (RadioStation $station) use ($toRemoveFrequency) {\n            return $station->getFrequency() !== $toRemoveFrequency;\n        });\n    }\n    \n    public function count() : int {\n        return count($this->stations);\n    }\n    \n    public function current() : RadioStation {\n        return $this->stations[$this->counter];\n    }\n    \n    public function key() {\n        return $this->counter;\n    }\n    \n    public function next() {\n        $this->counter++;\n    }\n    \n    public function rewind() {\n        $this->counter = 0;\n    }\n    \n    public function valid(): bool\n    {\n        return isset($this->stations[$this->counter]);\n    }\n}\n```\n然后可以这样使用\n```php\n$stationList = new StationList();\n\n$stationList->addStation(new Station(89));\n$stationList->addStation(new Station(101));\n$stationList->addStation(new Station(102));\n$stationList->addStation(new Station(103.2));\n\nforeach($stationList as $station) {\n    echo $station->getFrequency() . PHP_EOL;\n}\n\n$stationList->removeStation(new Station(89)); // Will remove station 89\n```\n\n👽 中介模式\n========\n\n现实例子\n> 一个普遍的例子是当你用手机和别人谈话，你和别人中间隔了一个电信网，你的声音穿过它而不是直接发出去。在这里，电信网就是一个中介。\n\n白话\n> 中介模式增加了一个第三方对象（叫做中介）来控制两个对象（叫做同事）间的交互。它帮助减少类彼此之间交流的耦合度。因为它们现在不需要知道彼此的实现。 \n\n维基百科\n> In software engineering, the mediator pattern defines an object that encapsulates how a set of objects interact. This pattern is considered to be a behavioral pattern due to the way it can alter the program's running behavior.\n\n**代码例子**\n\n下面是一个最简单的聊天室（即中介）的例子，用户（即同事）彼此发送信息。\n\n首先，我们有一个中介，即聊天室\n\n```php\n// 中介\nclass ChatRoom implements ChatRoomMediator {\n    public function showMessage(User $user, string $message) {\n        $time = date('M d, y H:i');\n        $sender = $user->getName();\n\n        echo $time . '[' . $sender . ']:' . $message;\n    }\n}\n```\n\n然后我们有用户，即同事\n```php\nclass User {\n    protected $name;\n    protected $chatMediator;\n\n    public function __construct(string $name, ChatRoomMediator $chatMediator) {\n        $this->name = $name;\n        $this->chatMediator = $chatMediator;\n    }\n    \n    public function getName() {\n        return $this->name;\n    }\n    \n    public function send($message) {\n        $this->chatMediator->showMessage($this, $message);\n    }\n}\n```\n然后是使用\n```php\n$mediator = new ChatRoom();\n\n$john = new User('John Doe', $mediator);\n$jane = new User('Jane Doe', $mediator);\n\n$john->send('Hi there!');\n$jane->send('Hey!');\n\n// 输出将会是\n// Feb 14, 10:58 [John]: Hi there!\n// Feb 14, 10:58 [Jane]: Hey!\n```\n\n💾 备忘录模式\n-------\n现实例子\n> 以计算器（即发起人）为例，无论什么时候你执行一些计算，最后的计算都会保存在内存（即备忘）里，这样你就能返回到这里，并且用一些按钮（即守护者）恢复。 \n\n白话\n> 备忘录模式捕捉和保存当前对象的状态，然后用一种平滑的方式恢复。\n\n维基百科\n> The memento pattern is a software design pattern that provides the ability to restore an object to its previous state (undo via rollback).\n\n当你要提供撤销方法时异常实用。\n\n**代码例子**\n\n让我们那编辑器为例，编辑器一直保存状态，在你需要的时候可以恢复。\n\n首先下面是我们的备忘录对象，可以保存编辑器状态\n\n```php\nclass EditorMemento {\n    protected $content;\n    \n    public function __construct(string $content) {\n        $this->content = $content;\n    }\n    \n    public function getContent() {\n        return $this->content;\n    }\n}\n```\n\n然后是我们的编辑器，即发起者，来使用备忘录对象\n\n```php\nclass Editor {\n    protected $content = '';\n    \n    public function type(string $words) {\n        $this->content = $this->content . ' ' . $words;\n    }\n    \n    public function getContent() {\n        return $this->content;\n    }\n    \n    public function save() {\n        return new EditorMemento($this->content);\n    }\n    \n    public function restore(EditorMemento $memento) {\n        $this->content = $memento->getContent();\n    }\n}\n```\n\n然后可以这样使用\n\n```php\n$editor = new Editor();\n\n// 输入一些东西\n$editor->type('This is the first sentence.');\n$editor->type('This is second.');\n\n// 保存状态到：This is the first sentence. This is second.\n$saved = $editor->save();\n\n// 输入些别的东西\n$editor->type('And this is third.');\n\n// 输出: Content before Saving\necho $editor->getContent(); // This is the first sentence. This is second. And this is third.\n\n// 恢复到上次保存状态\n$editor->restore($saved);\n\n$editor->getContent(); // This is the first sentence. This is second.\n```\n\n😎 观察者模式\n--------\n现实例子\n> 一个好的例子是求职者，他们订阅了一些工作发布网站，当有合适的工作机会时，他们会收到提醒。   \n\n白话\n> 定义了一个对象间的依赖，这样无论何时一个对象改变了状态，其他所有依赖者会收到提醒。\n\n维基百科\n> The observer pattern is a software design pattern in which an object, called the subject, maintains a list of its dependents, called observers, and notifies them automatically of any state changes, usually by calling one of their methods.\n\n**代码例子**\n\n翻译上面的例子。首先我们有需要收到工作发布提醒的求职者\n```php\nclass JobPost {\n    protected $title;\n    \n    public function __construct(string $title) {\n        $this->title = $title;\n    }\n    \n    public function getTitle() {\n        return $this->title;\n    }\n}\n\nclass JobSeeker implements Observer {\n    protected $name;\n\n    public function __construct(string $name) {\n        $this->name = $name;\n    }\n\n    public function onJobPosted(JobPost $job) {\n        // Do something with the job posting\n        echo 'Hi ' . $this->name . '! New job posted: '. $job->getTitle();\n    }\n}\n```\n下面是求职者订阅的工作信息\n```php\nclass JobPostings implements Observable {\n    protected $observers = [];\n    \n    protected function notify(JobPost $jobPosting) {\n        foreach ($this->observers as $observer) {\n            $observer->onJobPosted($jobPosting);\n        }\n    }\n    \n    public function attach(Observer $observer) {\n        $this->observers[] = $observer;\n    }\n    \n    public function addJob(JobPost $jobPosting) {\n        $this->notify($jobPosting);\n    }\n}\n```\n然后可以这样使用\n```php\n// 创建订阅者\n$johnDoe = new JobSeeker('John Doe');\n$janeDoe = new JobSeeker('Jane Doe');\n\n// 创建发布者，绑定订阅者\n$jobPostings = new JobPostings();\n$jobPostings->attach($johnDoe);\n$jobPostings->attach($janeDoe);\n\n// 添加一个工作，看订阅者是否收到通知\n$jobPostings->addJob(new JobPost('Software Engineer'));\n\n// 输出\n// Hi John Doe! New job posted: Software Engineer\n// Hi Jane Doe! New job posted: Software Engineer\n```\n\n🏃 访问者模式\n-------\n现实例子\n> 假设一些人访问迪拜。他们需要一些方式（即签证）来进入迪拜。抵达后，他们可以去迪拜的任何地方，而不用申请许可或者跑腿；他们知道的地方都可以去。访问者模式可以让你这样做，它帮你添加可以访问的地方，然后他们可以访问尽可能多的地方而不用到处跑腿。\n\n白话\n> 访问者模式可以让你添加更多的操作到对象，而不用改变他们。\n    \n维基百科\n> In object-oriented programming and software engineering, the visitor design pattern is a way of separating an algorithm from an object structure on which it operates. A practical result of this separation is the ability to add new operations to existing object structures without modifying those structures. It is one way to follow the open/closed principle.\n\n**代码例子**\n\n让我们以动物园模拟器为例，在里面我们有一些动物，我们必须让他们叫。让我们用访问者模式来翻译\n\n```php\n// 被访者\ninterface Animal {\n    public function accept(AnimalOperation $operation);\n}\n\n// 访问者\ninterface AnimalOperation {\n    public function visitMonkey(Monkey $monkey);\n    public function visitLion(Lion $lion);\n    public function visitDolphin(Dolphin $dolphin);\n}\n```\nThen we have our implementations for the animals\n```php\nclass Monkey implements Animal {\n    \n    public function shout() {\n        echo 'Ooh oo aa aa!';\n    }\n\n    public function accept(AnimalOperation $operation) {\n        $operation->visitMonkey($this);\n    }\n}\n\nclass Lion implements Animal {\n    public function roar() {\n        echo 'Roaaar!';\n    }\n    \n    public function accept(AnimalOperation $operation) {\n        $operation->visitLion($this);\n    }\n}\n\nclass Dolphin implements Animal {\n    public function speak() {\n        echo 'Tuut tuttu tuutt!';\n    }\n    \n    public function accept(AnimalOperation $operation) {\n        $operation->visitDolphin($this);\n    }\n}\n```\n实现我们的访问者\n```php\nclass Speak implements AnimalOperation {\n    public function visitMonkey(Monkey $monkey) {\n        $monkey->shout();\n    }\n    \n    public function visitLion(Lion $lion) {\n        $lion->roar();\n    }\n    \n    public function visitDolphin(Dolphin $dolphin) {\n        $dolphin->speak();\n    }\n}\n```\n\n然后可以这样使用\n```php\n$monkey = new Monkey();\n$lion = new Lion();\n$dolphin = new Dolphin();\n\n$speak = new Speak();\n\n$monkey->accept($speak);    // Ooh oo aa aa!    \n$lion->accept($speak);      // Roaaar!\n$dolphin->accept($speak);   // Tuut tutt tuutt!\n```\n我们本可以简单地给动物加一个继承层来做到这点，但是这样每当我们要给动物增加新功能的时候，我们就不得不改变动物。但是现在我们不用改变他们。比如，我们要给动物增加一个跳的行为，我们可以通过简单地增加一个新的访问者\n\n```php\nclass Jump implements AnimalOperation {\n    public function visitMonkey(Monkey $monkey) {\n        echo 'Jumped 20 feet high! on to the tree!';\n    }\n    \n    public function visitLion(Lion $lion) {\n        echo 'Jumped 7 feet! Back on the ground!';\n    }\n    \n    public function visitDolphin(Dolphin $dolphin) {\n        echo 'Walked on water a little and disappeared';\n    }\n}\n```\n然后这样用\n```php\n$jump = new Jump();\n\n$monkey->accept($speak);   // Ooh oo aa aa!\n$monkey->accept($jump);    // Jumped 20 feet high! on to the tree!\n\n$lion->accept($speak);     // Roaaar!\n$lion->accept($jump);      // Jumped 7 feet! Back on the ground! \n\n$dolphin->accept($speak);  // Tuut tutt tuutt! \n$dolphin->accept($jump);   // Walked on water a little and disappeared\n```\n\n💡 策略模式\n--------\n\n现实例子\n> 考虑排序的例子，我们实现了冒泡排序，但是数据开始增长，冒泡排序变得很慢。为了应对这个，我们实现了快速排序。但现在尽管快速排序算法对大数据集表现更好，小数据集却很慢。为了应对这一点，我们实现一个策略，冒泡排序处理小数据集，快速排序处理大数据集。\n\n白话\n> 策略模式允许你基于情况选择算法或策略。\n\n维基百科\n> In computer programming, the strategy pattern (also known as the policy pattern) is a behavioural software design pattern that enables an algorithm's behavior to be selected at runtime.\n \n**代码例子**\n\n翻译我们上面的例子。首先我们有了策略接口和不同的策略实现\n\n```php\ninterface SortStrategy {\n    public function sort(array $dataset) : array; \n}\n\nclass BubbleSortStrategy implements SortStrategy {\n    public function sort(array $dataset) : array {\n        echo \"Sorting using bubble sort\";\n         \n        // Do sorting\n        return $dataset;\n    }\n} \n\nclass QuickSortStrategy implements SortStrategy {\n    public function sort(array $dataset) : array {\n        echo \"Sorting using quick sort\";\n        \n        // Do sorting\n        return $dataset;\n    }\n}\n```\n \n然后是实用策略的调用者\n```php\nclass Sorter {\n    protected $sorter;\n    \n    public function __construct(SortStrategy $sorter) {\n        $this->sorter = $sorter;\n    }\n    \n    public function sort(array $dataset) : array {\n        return $this->sorter->sort($dataset);\n    }\n}\n```\n然后可以这样使用\n```php\n$dataset = [1, 5, 4, 3, 2, 8];\n\n$sorter = new Sorter(new BubbleSortStrategy());\n$sorter->sort($dataset); // 输出 : Sorting using bubble sort\n\n$sorter = new Sorter(new QuickSortStrategy());\n$sorter->sort($dataset); // 输出 : Sorting using quick sort\n```\n\n💢 状态模式\n-----\n现实例子\n> 想象你在使用画图程序，你选择笔刷来画。现在笔刷根据选择的颜色改变自己的行为。即如果你选择红色，它就用红色画，如果是蓝色它就用蓝色等等。  \n\n白话\n> 他让你能类的状态改变时，改变其行为。\n\n维基百科\n> The state pattern is a behavioral software design pattern that implements a state machine in an object-oriented way. With the state pattern, a state machine is implemented by implementing each individual state as a derived class of the state pattern interface, and implementing state transitions by invoking methods defined by the pattern's superclass.\n> The state pattern can be interpreted as a strategy pattern which is able to switch the current strategy through invocations of methods defined in the pattern's interface.\n\n**代码例子**\n\n让我们以编辑器作为例子，它能让你改变文本的状态，比如你选择了加粗，它开始以加粗字体书写，如果选择倾斜，就以倾斜字体等等。\n\n首先，我们有状态接口和一些状态实现\n\n```php\ninterface WritingState {\n    public function write(string $words);\n}\n\nclass UpperCase implements WritingState {\n    public function write(string $words) {\n        echo strtoupper($words); \n    }\n} \n\nclass LowerCase implements WritingState {\n    public function write(string $words) {\n        echo strtolower($words); \n    }\n}\n\nclass Default implements WritingState {\n    public function write(string $words) {\n        echo $words;\n    }\n}\n```\n下面是我们的编辑器\n```php\nclass TextEditor {\n    protected $state;\n    \n    public function __construct(WritingState $state) {\n        $this->state = $state;\n    }\n    \n    public function setState(WritingState $state) {\n        $this->state = $state;\n    }\n    \n    public function type(string $words) {\n        $this->state->write($words);\n    }\n}\n```\n然后可以这样使用\n```php\n$editor = new TextEditor(new Default());\n\n$editor->type('First line');\n\n$editor->setState(new UpperCaseState());\n\n$editor->type('Second line');\n$editor->type('Third line');\n\n$editor->setState(new LowerCaseState());\n\n$editor->type('Fourth line');\n$editor->type('Fifth line');\n\n// 输出:\n// First line\n// SECOND LINE\n// THIRD LINE\n// fourth line\n// fifth line\n```\n\n📒 模板模式\n---------------\n\n现实例子\n> 假设我们要建房子。建造的步骤类似这样 \n> - 准备房子的地基\n> - 建造墙\n> - 建造房顶\n> - 然后是地板\n> 这些步骤步骤的顺序永远不会变，即你不能在建墙之前建屋顶，当时每个步骤都可以改变，比如墙可以是木头可以是聚酯或者石头。\n  \n白话\n> 模板模式定义了一个算法会如何执行的骨架，但把这些步骤的实现移交给子类。\n \n维基百科\n> In software engineering, the template method pattern is a behavioral design pattern that defines the program skeleton of an algorithm in an operation, deferring some steps to subclasses. It lets one redefine certain steps of an algorithm without changing the algorithm's structure.\n\n**代码例子**\n\n想象我们有一个构建工具帮我们测试，纠错，构建，生成构建报告（即代码报告，查错报告），然后把应用发布到测试服务器。\n\n首先是我们的基础类，它描述了构建算法的骨架\n```php\nabstract class Builder {\n    \n    // Template method \n    public final function build() {\n        $this->test();\n        $this->lint();\n        $this->assemble();\n        $this->deploy();\n    }\n    \n    public abstract function test();\n    public abstract function lint();\n    public abstract function assemble();\n    public abstract function deploy();\n}\n```\n\n以下是实现\n\n```php\nclass AndroidBuilder extends Builder {\n    public function test() {\n        echo 'Running android tests';\n    }\n    \n    public function lint() {\n        echo 'Linting the android code';\n    }\n    \n    public function assemble() {\n        echo 'Assembling the android build';\n    }\n    \n    public function deploy() {\n        echo 'Deploying android build to server';\n    }\n}\n\nclass IosBuilder extends Builder {\n    public function test() {\n        echo 'Running ios tests';\n    }\n    \n    public function lint() {\n        echo 'Linting the ios code';\n    }\n    \n    public function assemble() {\n        echo 'Assembling the ios build';\n    }\n    \n    public function deploy() {\n        echo 'Deploying ios build to server';\n    }\n}\n```\n然后可以这样使用\n\n```php\n$androidBuilder = new AndroidBuilder();\n$androidBuilder->build();\n\n// 输出:\n// Running android tests\n// Linting the android code\n// Assembling the android build\n// Deploying android build to server\n\n$iosBuilder = new IosBuilder();\n$iosBuilder->build();\n\n// 输出:\n// Running ios tests\n// Linting the ios code\n// Assembling the ios build\n// Deploying ios build to server\n```\n\n## 🚦 收尾了同志们\n\n终于收尾了。我会继续改进这篇文档，所以你或许需要 watch/star 这个仓库，先码后看。\n\n## 👬 Contribution\n\n- Report issues\n- Open pull request with improvements\n- Spread the word\n\n## 翻译\n[月球人](https://github.com/questionlin)\n\n## License\nMIT © [Kamran Ahmed](http://kamranahmed.info)\n","tags":["php"]},{"title":"hexo+github搭建博客最佳实践","url":"/posts/1528164408/","content":"\b在考察了多种方案后最终使用 hexo 搭起了博客，这篇文章写写我是怎么\b使用 hexo 和 github 来搭博客的。\n\n在官网主题那里选一个喜欢的主题，我找了一个有搜索引擎配置教学的。下载后放到 themes 文件夹。然后按照官方说明配置。\n\nhexo 不提供 markdown 编辑器，我使用 vscode，快捷键 command + k 再按 v 后可以打开一个实时预览标签页。\n\n我有一个特殊的需求，希望可以省略部署( hexo deploy) 这个步骤。这就要求博客源文件和生成文件放在一起。github pages 提供给用户专门建\b博客的项目只能放生成后的文件，这个方案否定。我的做法是：\n1. 把 _config.yml 里面的 public_dir 改为 docs\n2. 然后建一个普通的项目仓库，在 settings 里的 github pages Source 选为 master branch/docs folder。这里顺便把 Custom domain 改为自己的域名。\n3. 在域名 dns 设置里面添加 cname 指向 question.github.io\n4. 在文章顶部增加 id，值为 unix 时间戳，以优化 url\n5. 图床我用的是微博相册\n\n用到的插件：\n- hexo-generator-search 用来支持\b搜索\n- hexo-generator-feed 用来生成 feed\n\n置顶标签：\n\nhexo-generator-index 插件已经原生支持了置顶标签，只要使用 sticky 标签，值越高越靠前\n```\ntitle: Hello World\ndate: 2013/7/13 20:46:25\nsticky: 100\n```\n\n\n\n到此我的 hexo 博客就建好了，\b[项目仓库在这里](https://github.com/questionlin/blog)。比官方的方法少了一步。","tags":["最佳实践","hexo"]}]